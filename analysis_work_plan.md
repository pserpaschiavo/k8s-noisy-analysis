# Plano de Trabalho para An√°lise de S√©ries Temporais Multi-Tenant

O objetivo √© investigar a co-varia√ß√£o, rela√ß√µes causais e flutua√ß√µes temporais das m√©tricas entre diferentes tenants e fases experimentais (baseline, ataque, recupera√ß√£o), utilizando ferramentas estat√≠sticas b√°sicas, interpret√°veis e confi√°veis.

## Status do Projeto (Atualizado em Junho/2025)

- ‚úÖ **Conclu√≠do**: Estrutura principal do projeto implementada, ingest√£o de dados, segmenta√ß√£o, persist√™ncia, componentes de an√°lise descritiva, correla√ß√£o e causalidade b√°sicos.
- üîÑ **Em andamento**: Refinamento do m√≥dulo de Causalidade com Transfer Entropy, testes unit√°rios completos.
- ‚ùå **Pendente**: Consolida√ß√£o da metodologia de an√°lise inter-tenant, relat√≥rios comparativos entre fases experimentais, documenta√ß√£o detalhada das escolhas metodol√≥gicas, an√°lises com janelas m√≥veis.

## Diretrizes Gerais para o Desenvolvimento do Pipeline

- O DataFrame consolidado em formato "long" deve ser a √∫nica fonte de verdade para todas as an√°lises. Todas as transforma√ß√µes e segmenta√ß√µes devem partir dele.
- Todas as fun√ß√µes de carregamento, transforma√ß√£o e exporta√ß√£o de dados devem ser modulares, test√°veis e possuir logging detalhado de etapas e erros.
- O pipeline deve ser desenvolvido de forma incremental: comece com um subconjunto pequeno de dados/m√©tricas, garanta testes e outputs corretos, depois expanda.
- O c√≥digo deve ser escrito em ingl√™s (nomes, docstrings, coment√°rios). Documenta√ß√£o geral pode ser em portugu√™s.
- Toda l√≥gica de ingest√£o, valida√ß√£o e transforma√ß√£o de dados deve ser separada da l√≥gica de an√°lise e visualiza√ß√£o.
- Recomenda-se a cria√ß√£o de um m√≥dulo central de ingest√£o de dados (ex: `data_ingestion.py`) respons√°vel por:
    - Navegar na estrutura de diret√≥rios.
    - Carregar arquivos CSV.
    - Validar e padronizar colunas e tipos.
    - Gerar logs de inconsist√™ncias e erros.
    - Retornar o DataFrame "long" padronizado.
- Implementar testes unit√°rios para cada etapa cr√≠tica (carregamento, transforma√ß√£o, an√°lise, visualiza√ß√£o).
- Utilizar um arquivo de configura√ß√£o central (ex: `config.yaml` ou `.py`) para caminhos, m√©tricas, par√¢metros de an√°lise e exporta√ß√£o.
- Outputs (plots, tabelas, arquivos) devem ser versionados e organizados por experimento, round e fase.
- Documentar todas as decis√µes metodol√≥gicas e par√¢metros relevantes em arquivos Markdown.

## Diretrizes para Estrutura√ß√£o e Persist√™ncia de DataFrames

- O DataFrame consolidado em formato "long" √© o padr√£o e fonte √∫nica de verdade para todo o pipeline. Todas as opera√ß√µes de ingest√£o, valida√ß√£o, limpeza e transforma√ß√£o devem resultar nesse formato.
- Subdatasets no formato "wide" podem ser gerados sob demanda, a partir do DataFrame long, para an√°lises espec√≠ficas (correla√ß√£o, causalidade, visualiza√ß√µes comparativas), mas nunca devem substituir o long como fonte principal.
- Recomenda-se fortemente a persist√™ncia dos DataFrames processados (long e, se necess√°rio, wide) em formatos eficientes e port√°veis (Parquet preferencialmente, ou CSV/Feather), organizados por experimento, round e fase. Isso facilita reuso, integra√ß√£o com notebooks (Jupyter) e compartilhamento com outros times ou ferramentas.
- O pipeline deve prover fun√ß√µes utilit√°rias para salvar e carregar datasets processados, garantindo reprodutibilidade e agilidade no desenvolvimento.

## Fase 1: Prepara√ß√£o e Estrat√©gia de Dados

1.  **Defini√ß√£o da Estrutura dos Dados de Entrada:**
    *   1.1. ‚úÖ Confirmar e documentar as colunas essenciais no DataFrame de entrada (ex: `timestamp`, `tenant_id`, `metric_name`, `metric_value`, `experimental_phase`). 
    *   1.2. ‚úÖ Validar os tipos de dados e a consist√™ncia dos identificadores (tenants, m√©tricas, fases). 

2.  **Estrat√©gia de Carregamento, Formatos de DataFrame e Segmenta√ß√£o de Dados:**
    *   2.1. ‚úÖ Implementar ou refinar a l√≥gica para carregar os dados brutos e consolid√°-los em um DataFrame principal em **formato "long"**. 
        *   Este DataFrame conter√° colunas como: `timestamp`, `metric_value`, `metric_name`, `tenant_id`, `experimental_phase`, `round_id`, `experiment_id`. 
    *   2.2. ‚úÖ Desenvolver fun√ß√µes para segmentar o DataFrame principal (formato "long") por: 
        *   Fase experimental (Baseline, Ataque, Recupera√ß√£o).
        *   Tenant individual.
        *   M√©trica espec√≠fica.
        *   Combina√ß√µes destes (ex: dados de uma m√©trica espec√≠fica para um tenant em uma fase).
    *   2.3. ‚úÖ **Estrat√©gia para DataFrames em formato \"wide\":**
        *   Ser√£o gerados em mem√≥ria, dinamicamente, a partir do DataFrame \"long\", conforme a necessidade de cada m√≥dulo de an√°lise (ex: para c√°lculo de correla√ß√µes ou causalidade entre m√∫ltiplas s√©ries temporais).
        *   Estes DataFrames \\\"wide\\\" tamb√©m ser√£o considerados para exporta√ß√£o, permitindo an√°lises futuras ou o uso por parsers espec√≠ficos.
        *   ‚úÖ **Implementar `get_wide_format_for_analysis` para transformar dados longos em largos para uma m√©trica, fase e round espec√≠ficos. 
    *   2.4. ‚úÖ **Exporta√ß√£o dos DataFrames Processados:**
        *   Implementar a funcionalidade para exportar o DataFrame consolidado em formato "long" (ap√≥s carregamento e pr√©-processamento inicial) para um formato de arquivo eficiente (ex: Parquet). 
            *   Objetivo: otimizar o desempenho em an√°lises subsequentes e facilitar a interoperabilidade com outras ferramentas ou processos.
        *   Implementar a funcionalidade para exportar os DataFrames em formato "wide" gerados para formatos de arquivo eficientes (ex: Parquet ou CSV, a ser definido). 
            *   Objetivo: permitir an√°lises futuras ou o uso por parsers espec√≠ficos que possam necessitar deste formato.

3.  **Configura√ß√£o e Aplica√ß√£o de Otimiza√ß√£o de Dados:**
    *   3.1. üîÑ Revisar e ajustar otimiza√ß√£o para an√°lise descritiva. 
    *   3.2. üîÑ Revisar e ajustar otimiza√ß√£o para an√°lise de correla√ß√£o. 
    *   3.3. üîÑ Revisar e ajustar otimiza√ß√£o para an√°lise de causalidade. 
4.  **Defini√ß√£o do Processo de Sele√ß√£o de Vari√°veis e Pares para An√°lise:**
    *   4.1. ‚úÖ Estabelecer crit√©rios para selecionar as m√©tricas de interesse (ex: CPU, mem√≥ria, lat√™ncia). 
    *   4.2. ‚úÖ Definir como os pares de tenants ser√£o selecionados para an√°lises comparativas (inter-tenant). 

# Sequ√™ncia Recomendada para o Desenvolvimento do Pipeline

## 1. Estrutura√ß√£o Inicial e Organiza√ß√£o do Projeto

1. **Defini√ß√£o e Cria√ß√£o da Estrutura de Diret√≥rios:**
    - `data/raw/` ‚Äî Dados brutos extra√≠dos (ex: CSVs originais).
    - `data/processed/` ‚Äî DataFrames processados (long/wide) em Parquet/CSV.
    - `outputs/plots/` ‚Äî Gr√°ficos gerados por fase, experimento, round.
    - `outputs/tables/` ‚Äî Tabelas e resumos exportados.
    - `notebooks/` ‚Äî Jupyter Notebooks para explora√ß√£o e valida√ß√£o.
    - `config/` ‚Äî Arquivos de configura√ß√£o (YAML, JSON, etc).
    - `logs/` ‚Äî Logs de execu√ß√£o e valida√ß√£o.
    - `src/` ‚Äî C√≥digo-fonte do pipeline (m√≥dulos de ingest√£o, an√°lise, visualiza√ß√£o, etc).

## 2. Desenvolvimento Incremental do Pipeline

### 2.1. Funcionalidades Fundamentais

1. **Configura√ß√£o Centralizada:**
    - Criar arquivo de configura√ß√£o (ex: `config.yaml`) para caminhos, m√©tricas, par√¢metros globais.
2. **Ingest√£o e Valida√ß√£o de Dados:**
    - Implementar m√≥dulo/fun√ß√£o para navegar na estrutura de diret√≥rios, carregar CSVs, validar e padronizar colunas/tipos.
    - Gerar logs de inconsist√™ncias e erros.
    - Consolidar tudo em um DataFrame long padronizado.
3. **Persist√™ncia de DataFrames:**
    - Implementar fun√ß√µes utilit√°rias para salvar/carregar DataFrames long (e wide, se necess√°rio) em Parquet/CSV.
    - Organizar arquivos por experimento, round e fase.
4. **Testes Unit√°rios B√°sicos:**
    - Testar ingest√£o, valida√ß√£o e persist√™ncia.

### 2.2. Segmenta√ß√£o e Exporta√ß√£o

1. **Fun√ß√µes de Segmenta√ß√£o:**
    - Permitir filtragem do DataFrame long por fase, tenant, m√©trica, etc.
2. **Gera√ß√£o de DataFrames Wide sob Demanda:**
    - Implementar fun√ß√£o para converter long‚Üíwide para an√°lises espec√≠ficas.
3. **Exporta√ß√£o de Subdatasets:**
    - Exportar subconjuntos relevantes para uso em notebooks ou outras ferramentas.

### 2.3. An√°lise Descritiva

1. **M√≥dulo Descritivo:**
    - Calcular estat√≠sticas b√°sicas (m√©dia, desvio padr√£o, skewness, kurtosis) por s√©rie temporal.
    - Gerar plots simples (s√©ries temporais, histogramas, ACF).
    - Exportar tabelas resumo.
2. **Testes Unit√°rios:**
    - Testar c√°lculos e gera√ß√£o de plots/tabelas.

### 2.4. M√≥dulos Avan√ßados

1. **Correla√ß√£o e Covari√¢ncia:**
    - Implementar c√°lculos e visualiza√ß√µes de correla√ß√£o/covari√¢ncia entre tenants/m√©tricas.
2. **Causalidade:**
    - Implementar testes de Granger e Transfer Entropy, visualiza√ß√µes e tabelas.
3. **Compara√ß√£o entre Fases:**
    - L√≥gica para comparar resultados entre baseline, ataque e recupera√ß√£o.
4. **Janelas M√≥veis (Opcional):**
    - Adapta√ß√£o dos m√≥dulos para an√°lises com janelas m√≥veis.

### 2.5. Consolida√ß√£o, Relat√≥rios e Itera√ß√£o

1. **Agrega√ß√£o de Insights:**
    - Combinar resultados dos m√≥dulos para formar narrativa coesa.
2. **Tabela Final Comparativa:**
    - Gerar ranking e m√©tricas de influ√™ncia inter-tenant.
3. **Documenta√ß√£o e Justificativas:**
    - Registrar par√¢metros, decis√µes e m√©todos.
4. **Execu√ß√£o, Debugging e Itera√ß√£o:**
    - Rodar pipeline completo, refinar e iterar conforme resultados.

## Fase 2: Implementa√ß√£o Detalhada dos M√≥dulos de An√°lise

Cada m√≥dulo seguir√° a arquitetura `BaseModule`, `BaseAnalyzer`, `BaseVisualizer`.

**2.1. M√≥dulo de An√°lise Descritiva (em `src/analysis_descriptive.py`)**
    *   2.1.1. **Estrutura do M√≥dulo:**
        *   ‚úÖ Implementar fun√ß√µes de an√°lise descritiva.
        *   ‚úÖ Implementar fun√ß√µes de visualiza√ß√£o.
    *   2.1.2. **C√°lculos de Estat√≠sticas Descritivas:** 
        *   ‚úÖ Implementar fun√ß√£o para calcular estat√≠sticas descritivas (m√©dia, desvio padr√£o, etc.) por s√©rie temporal (tenant, m√©trica, fase).
    *   2.1.3. **Visualiza√ß√µes:** 
        *   ‚úÖ Implementar fun√ß√£o para gerar plots de s√©ries temporais individuais. 
        *   ‚úÖ Implementar fun√ß√£o para gerar plots de autocorrela√ß√£o (ACF) para cada m√©trica/tenant. 
    *   2.1.4. **Tabelas de Resultados:** 
        *   ‚úÖ Implementar fun√ß√£o para gerar tabela resumo das estat√≠sticas descritivas.
    *   2.1.5. **Testes Unit√°rios:** 
        *   üîÑ Implementados arquivos b√°sicos de teste `test_analysis_descriptive.py`.
        *   üîÑ Expandir cobertura de testes para casos edge.

**2.2. M√≥dulo de An√°lise de Correla√ß√£o e Covari√¢ncia (em `src/analysis_correlation.py`)**
    *   2.2.1. **Estrutura do M√≥dulo:**
        *   ‚úÖ Implementar fun√ß√µes de an√°lise de correla√ß√£o.
        *   ‚úÖ Implementar fun√ß√µes de visualiza√ß√£o para correla√ß√£o.
    *   2.2.2. **C√°lculos de Correla√ß√£o (por fase experimental):**
        *   ‚úÖ Implementar fun√ß√£o para calcular matrizes de correla√ß√£o (Pearson, Kendall, Spearman) entre m√©tricas de tenants distintos.
        *   ‚úÖ Implementar fun√ß√£o para calcular matriz de covari√¢ncia (com dados padronizados).
        *   üîÑ Implementar fun√ß√£o para calcular Correla√ß√£o Cruzada com Defasagem (CCF) entre pares de s√©ries.
    *   2.2.3. **Visualiza√ß√µes (por fase experimental):**
        *   ‚úÖ Implementar fun√ß√£o para gerar heatmaps das matrizes de correla√ß√£o.
        *   ‚úÖ Implementar fun√ß√£o para gerar heatmap da matriz de covari√¢ncia padronizada.
        *   üîÑ Implementar fun√ß√£o para gerar gr√°ficos de CCF.
        *   üîÑ Implementar fun√ß√£o para gerar lag plots.
    *   2.2.4. **Tabelas de Resultados:**
        *   ‚úÖ Implementar fun√ß√£o para gerar tabelas das matrizes de correla√ß√£o e covari√¢ncia.
    *   2.2.5. **Testes Unit√°rios:**
        *   üîÑ Implementados arquivos b√°sicos de teste `test_analysis_correlation.py`.
        *   üîÑ Expandir cobertura de testes para casos edge.

**2.3. M√≥dulo de An√°lise de Causalidade (em `src/analysis_causality.py`)**
    *   2.3.1. **Estrutura do M√≥dulo (Reconstru√ß√£o/Cria√ß√£o):**
        *   ‚úÖ Implementar fun√ß√µes para an√°lise de causalidade abrangendo Granger e Transfer Entropy.
        *   ‚úÖ Implementar fun√ß√µes de visualiza√ß√£o para causalidade.
        *   ‚úÖ Integra√ß√£o com outras funcionalidades do pipeline.
    *   2.3.2. **Implementa√ß√£o da An√°lise de Causalidade de Granger:**
        *   ‚úÖ Implementar fun√ß√£o para aplicar testes de Causalidade de Granger para pares de s√©ries temporais.
        *   ‚úÖ Integrar l√≥gica para determinar `max_lags` (pode usar CCF do m√≥dulo de correla√ß√£o ou crit√©rios como AIC/BIC).
        *   ‚úÖ Assegurar a coleta e o armazenamento adequado dos p-values e estat√≠sticas do teste.
    *   2.3.3. **Implementa√ß√£o da An√°lise de Transfer Entropy:**
        *   üîÑ Selecionar e integrar a biblioteca Python para Transfer Entropy (ex: `pyinform`, ou outra). Adicionar ao `requirements.txt`.
        *   üîÑ Implementar fun√ß√£o para calcular Transfer Entropy para pares de s√©ries temporais.
        *   üîÑ Assegurar a coleta e o armazenamento adequado dos valores de TE.
    *   2.3.4. **Implementa√ß√£o das Visualiza√ß√µes:**
        *   ‚úÖ Implementar fun√ß√£o para gerar plots dos resultados da Causalidade de Granger (ex: heatmap de p-values).
        *   üîÑ Implementar fun√ß√£o para gerar plots dos resultados da Transfer Entropy (ex: heatmap de valores TE).
        *   ‚úÖ Implementar fun√ß√£o para gerar visualiza√ß√£o em grafo (usando NetworkX) para ilustrar rela√ß√µes de influ√™ncia.
        *   üîÑ Garantir que a legenda dos grafos multi-m√©trica seja contextual e autom√°tica: priorizar p-valor (Granger real) se dispon√≠vel, sen√£o TE, para m√°xima clareza interpretativa.
        *   ‚úÖ Outputs organizados e reprodut√≠veis, com legendas e t√≠tulos informativos.
    *   2.3.5. **Gera√ß√£o de Tabelas de Resultados:**
        *   ‚úÖ Implementar fun√ß√£o para criar tabela consolidada de scores de causalidade (p-values Granger).
        *   üîÑ Implementar fun√ß√£o para criar uma matriz de influ√™ncia cruzada resumida com scores de TE.
    *   2.3.6. **Testes Unit√°rios e Integra√ß√£o:**
        *   üîÑ Implementados arquivos b√°sicos de teste `test_analysis_causality.py`.
        *   ‚ùå Falta testar fun√ß√µes de c√°lculo de TE com dados sint√©ticos ou subconjuntos.
        *   üîÑ Testar gera√ß√£o de plots e tabelas para TE.

## Fase 3: Consolida√ß√£o, Interpreta√ß√£o e Gera√ß√£o de Relat√≥rios

1.  **Desenvolvimento da Metodologia de Agrega√ß√£o de Insights:**
    *   3.1.1. ‚ùå Definir como os resultados das an√°lises descritiva, de correla√ß√£o/covari√¢ncia e de causalidade ser√£o combinados para formar uma narrativa coesa.
    *   3.1.2. ‚ùå Estabelecer crit√©rios para identificar o "tenant barulhento" e quantificar sua influ√™ncia.
2.  **Implementa√ß√£o da Gera√ß√£o da Tabela Final de Comparativo Inter-Tenant:**
    *   3.2.1. ‚ùå Projetar a estrutura da tabela final, incluindo as m√©tricas de influ√™ncia e ranking.
    *   3.2.2. ‚ùå Implementar a l√≥gica para popular esta tabela, utilizando os resultados armazenados pelos Analyzers.
3.  **Documenta√ß√£o Detalhada das Escolhas Metodol√≥gicas:**
    *   3.3.1. üîÑ Registrar todos os par√¢metros utilizados (ex: `max_lags` para Granger, limiares de signific√¢ncia, janelas de CCF).
    *   3.3.2. ‚ùå Justificar as escolhas de bibliotecas e m√©todos.
4.  **An√°lise Comparativa dos Resultados Entre Fases Experimentais:**
    *   3.4.1. ‚ùå Implementar l√≥gica para comparar os resultados (correla√ß√µes, causalidade, etc.) entre as fases de baseline, ataque e recupera√ß√£o.
    *   3.4.2. ‚ùå Preparar visualiza√ß√µes que destaquem essas mudan√ßas.
5.  **Avalia√ß√£o e Implementa√ß√£o (Opcional) de An√°lises com Janelas M√≥veis:**
    *   3.5.1. ‚ùå Se decidido, adaptar os m√≥dulos de Correla√ß√£o e Causalidade para operar com janelas m√≥veis.
    *   3.5.2. ‚ùå Definir o tamanho da janela e o passo (step).
    *   3.5.3. ‚ùå Implementar visualiza√ß√µes para os resultados de janelas m√≥veis (ex: evolu√ß√£o da correla√ß√£o/causalidade ao longo do tempo).
    *   3.5.4. ‚ùå Realizar testes espec√≠ficos para as funcionalidades de janelas m√≥veis.

## Fase 4: Execu√ß√£o, Debugging e Itera√ß√£o

1.  **Configura√ß√£o do Script Principal de An√°lise:**
    *   4.1.1. ‚úÖ Garantir que o script (`main.py`) possa carregar os dados, instanciar os m√≥dulos de an√°lise e executar as an√°lises em sequ√™ncia.
    *   4.1.2. ‚úÖ Implementar a l√≥gica para salvar todos os outputs (plots, tabelas) de forma organizada.
2.  **Execu√ß√£o com Dados de Demonstra√ß√£o (`demo-data`):**
    *   4.2.1. ‚úÖ Rodar o pipeline completo com os dados de demonstra√ß√£o.
    *   4.2.2. üîÑ Verificar a corretude dos resultados parciais e finais.
3.  **Debugging e Refinamento dos M√≥dulos:**
    *   4.3.1. üîÑ Corrigir bugs identificados durante a execu√ß√£o.
    *   4.3.2. üîÑ Refinar par√¢metros e l√≥gicas com base nos resultados observados.
4.  **An√°lise dos Resultados Iniciais e Itera√ß√£o:**
    *   4.4.1. üîÑ Interpretar os primeiros resultados completos.
    *   4.4.2. üîÑ Com base na interpreta√ß√£o, decidir sobre ajustes nos m√©todos, par√¢metros ou visualiza√ß√µes.
    *   4.4.3. üîÑ Repetir etapas de execu√ß√£o e an√°lise conforme necess√°rio.

## Observa√ß√µes e Filosofia da An√°lise Inter-Tenant

- A identifica√ß√£o de tenants que causam conten√ß√£o de recursos ou degrada√ß√£o ser√° feita exclusivamente de forma data-driven, a partir dos resultados das t√©cnicas estat√≠sticas e de causalidade implementadas (correla√ß√£o, causalidade, influ√™ncia cruzada, etc.).
- N√£o h√° pr√©-julgamento sobre quem √© o "tenant barulhento" ou malicioso: a descoberta ser√° imparcial e baseada em evid√™ncias extra√≠das dos dados.
- A aus√™ncia de determinados tenants em certas fases (baseline, ataque, recupera√ß√£o) √© esperada e deve ser tratada naturalmente pelo pipeline, sem gerar erro ou vi√©s. Todas as an√°lises devem considerar apenas os tenants presentes em cada contexto/fase.
- O pipeline deve ser robusto para lidar com a presen√ßa/aus√™ncia de tenants e arquivos de m√©tricas em cada fase, e as fun√ß√µes de ingest√£o devem registrar (logar) essas aus√™ncias para rastreabilidade.

## Sugest√£o para o Desenvolvimento do Pipeline

- Desenvolva o pipeline de forma incremental, come√ßando pela ingest√£o e valida√ß√£o dos dados, garantindo que o DataFrame long seja corretamente consolidado mesmo com aus√™ncias de tenants/fases.
- Implemente fun√ß√µes utilit√°rias para:
    - Listar todos os tenants presentes em cada fase/round/experimento.
    - Registrar aus√™ncias de tenants ou m√©tricas esperadas (logging).
    - Gerar DataFrames segmentados por fase, tenant, m√©trica, etc.
- Priorize a modularidade: separe claramente ingest√£o, transforma√ß√£o, an√°lise e visualiza√ß√£o.
- Implemente testes unit√°rios para garantir que a ingest√£o lida corretamente com casos de aus√™ncia de dados.
- Considere criar um notebook de explora√ß√£o inicial para validar a consolida√ß√£o dos dados e a robustez do pipeline antes de avan√ßar para an√°lises mais complexas.

## Estrutura de Dados de Entrada (Alinhada ao Experimento Original)

- Os dados de entrada devem ser organizados conforme exporta√ß√£o do experimento original, seguindo a estrutura de diret√≥rios encontrada em `demo-data/`.
- Cada experimento pode conter um ou m√∫ltiplos rounds (ex: `demo-experiment-1-round/`, `demo-experiment-3-rounds/`).
- Dentro de cada round (`round-1/`, `round-2/`, etc.), existem tr√™s fases sequenciais: `1 - Baseline/`, `2 - Attack/`, `3 - Recovery/`.
- Dentro de cada fase, os subdiret√≥rios representam os tenants (ex: `tenant-a/`, `tenant-b/`, ...), al√©m de poss√≠veis diret√≥rios auxiliares (ex: `ingress-nginx/`, `active/`, etc.).
- Cada diret√≥rio de tenant cont√©m arquivos CSV de m√©tricas, cada um com duas colunas: `timestamp,value`.
- O pipeline deve:
    - Navegar recursivamente por todos os experimentos, rounds e fases.
    - Identificar corretamente o experimento, round, fase e tenant para cada arquivo de m√©trica.
    - Ignorar diret√≥rios que n√£o seguem o padr√£o de tenant (ex: `ingress-nginx/`, `active/`, etc.), conforme crit√©rios definidos no contexto do projeto.
    - Consolidar todos os dados em um DataFrame long padronizado, adicionando as colunas: `timestamp`, `metric_value`, `metric_name`, `tenant_id`, `experimental_phase`, `round_id`, `experiment_id`.
    - Garantir a consist√™ncia dos tipos e valores categ√≥ricos durante a ingest√£o.
- Essa l√≥gica deve ser implementada no m√≥dulo central de ingest√£o de dados, garantindo flexibilidade para diferentes estruturas de experimentos e rounds.

## Lacunas e Oportunidades de Melhoria (Adicionado em Junho/2025)

Ap√≥s an√°lise da implementa√ß√£o atual e compara√ß√£o com o plano original, foram identificadas as seguintes lacunas e oportunidades de melhoria:

1. **Implementa√ß√£o do Transfer Entropy**:
   - ‚úÖ Estrutura base implementada no m√≥dulo `analysis_causality.py`
   - üîÑ A aplica√ß√£o do Transfer Entropy est√° em andamento, conforme evidenciado pelo arquivo `debug_te_attack.out` 
   - ‚ùå Falta integrar plenamente a biblioteca para c√°lculos de TE (ex: `pyinform`) com documenta√ß√£o adequada
   - ‚ùå Necessidade de refinamento da visualiza√ß√£o contextual dos grafos de causalidade

2. **Completude dos Testes**:
   - üîÑ Arquivos de teste criados (`test_analysis_causality.py`, `test_analysis_correlation.py`, etc.)
   - ‚ùå Cobertura de testes insuficiente para garantir robustez do pipeline
   - ‚ùå Falta testes para casos extremos (aus√™ncia de dados, inconsist√™ncias)

3. **An√°lises Comparativas entre Fases**:
   - ‚úÖ Pipeline gera visualiza√ß√µes separadas por fase experimental
   - ‚ùå Falta implementa√ß√£o da l√≥gica para comparar resultados entre fases
   - ‚ùå Aus√™ncia de visualiza√ß√µes espec√≠ficas para compara√ß√£o de baseline/ataque/recupera√ß√£o

4. **Documenta√ß√£o das Escolhas Metodol√≥gicas**:
   - üîÑ Estrutura b√°sica de arquivos Markdown criada
   - ‚ùå Falta registro detalhado de par√¢metros estat√≠sticos utilizados
   - ‚ùå Aus√™ncia de justificativas para escolhas metodol√≥gicas

5. **Relat√≥rios e Consolida√ß√£o de Insights**:
   - ‚ùå Falta implementa√ß√£o da metodologia de agrega√ß√£o de insights
   - ‚ùå Aus√™ncia de tabela final comparativa inter-tenant
   - ‚ùå Necessidade de estruturar relat√≥rios automatizados

6. **Janelas M√≥veis**:
   - ‚ùå Fase avan√ßada n√£o iniciada
   - ‚ùå Adapta√ß√£o para an√°lises temporais din√¢micas

7. **Depend√™ncias e Integra√ß√£o**:
   - ‚ùå `NetworkX` n√£o est√° no `requirements.txt` mas √© usado para visualiza√ß√µes em grafo
   - ‚ùå Biblioteca para Transfer Entropy n√£o especificada no `requirements.txt`

## Prioridades para Pr√≥ximos Passos (Junho/2025)

As seguintes prioridades foram identificadas para concluir o projeto com sucesso:

### Prioridade Alta (Imediata) ‚úÖ
1. **Completar Implementa√ß√£o do Transfer Entropy** ‚úÖ:
   - ‚úÖ Finalizar integra√ß√£o da biblioteca de TE
   - ‚úÖ Garantir armazenamento adequado dos valores
   - ‚úÖ Completar testes unit√°rios espec√≠ficos para TE

2. **Atualizar `requirements.txt`** ‚úÖ:
   - ‚úÖ Adicionar `networkx` e biblioteca para TE (ex: `pyinform`)
   - ‚úÖ Especificar vers√µes compat√≠veis

3. **Consolidar Testes Unit√°rios Cr√≠ticos** ‚úÖ:
   - ‚úÖ Focar em testes para ingest√£o de dados, causalidade e exporta√ß√£o
   - ‚úÖ Garantir cobertura para casos edge de aus√™ncia de dados

### Prioridade M√©dia (Pr√≥ximas 2-3 semanas) ‚úÖ
1. **Implementar Compara√ß√£o entre Fases Experimentais** ‚úÖ:
   - ‚úÖ Desenvolver l√≥gica para comparar m√©tricas entre baseline/ataque/recovery
   - ‚úÖ Criar visualiza√ß√µes espec√≠ficas para destacar mudan√ßas

2. **Desenvolver Metodologia de Agrega√ß√£o de Insights** ‚úÖ:
   - ‚úÖ Definir e implementar crit√©rios para identifica√ß√£o de "tenant barulhento"
   - ‚úÖ Estruturar tabela final comparativa

3. **Documentar Escolhas Metodol√≥gicas** ‚úÖ:
   - ‚úÖ Registrar par√¢metros utilizados (ex: `max_lags`, thresholds)
   - ‚úÖ Justificar escolhas de bibliotecas e m√©todos

### Prioridade Baixa (Ap√≥s concluir anteriores) üîÑ
1. **An√°lises com Janelas M√≥veis** ‚úÖ:
   - ‚úÖ Adaptar m√≥dulos para an√°lise temporal din√¢mica
   - ‚úÖ Implementar visualiza√ß√µes espec√≠ficas
   - ‚úÖ Testar e validar a execu√ß√£o completa do pipeline com janelas m√≥veis

2. **Refinamentos Est√©ticos e Usabilidade** üîÑ:
   - ‚úÖ Melhorar formata√ß√£o de gr√°ficos (estilo tableau-colorblind10)
   - üîÑ Adicionar op√ß√µes de personaliza√ß√£o de visualiza√ß√µes
   - ‚úÖ Aprimorar mensagens de log e feedback

3. **Documenta√ß√£o para Usu√°rios Finais** üîÑ:
   - üîÑ Tutorial de uso do pipeline
   - üîÑ Guia de interpreta√ß√£o dos resultados

