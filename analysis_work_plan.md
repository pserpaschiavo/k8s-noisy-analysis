# Plano de Trabalho para An√°lise de S√©ries Temporais Multi-Tenant

O objetivo √© investigar a co-varia√ß√£o, rela√ß√µes causais e flutua√ß√µes temporais das m√©tricas entre diferentes tenants e fases experimentais (baseline, ataque, recupera√ß√£o), utilizando ferramentas estat√≠sticas b√°sicas, interpret√°veis e confi√°veis.

## Status do Projeto (Atualizado em Junho/2025)

- ‚úÖ **Conclu√≠do**: Estrutura principal do projeto implementada, ingest√£o de dados, segmenta√ß√£o, persist√™ncia, componentes de an√°lise descritiva, correla√ß√£o e causalidade b√°sicos, agrega√ß√£o de insights, an√°lise multi-round.
- üîÑ **Em andamento**: Refinamento do m√≥dulo de Causalidade com Transfer Entropy, testes unit√°rios completos, an√°lises com janelas m√≥veis, documenta√ß√£o detalhada.
- ‚ùå **Pendente**: Relat√≥rios comparativos entre fases experimentais, integra√ß√£o completa de todos os componentes, documenta√ß√£o para usu√°rios finais.

## Diretrizes Gerais para o Desenvolvimento do Pipeline

- O DataFrame consolidado em formato "long" deve ser a √∫nica fonte de verdade para todas as an√°lises. Todas as transforma√ß√µes e segmenta√ß√µes devem partir dele.
- Todas as fun√ß√µes de carregamento, transforma√ß√£o e exporta√ß√£o de dados devem ser modulares, test√°veis e possuir logging detalhado de etapas e erros.
- O pipeline deve ser desenvolvido de forma incremental: comece com um subconjunto pequeno de dados/m√©tricas, garanta testes e outputs corretos, depois expanda.
- O c√≥digo deve ser escrito em ingl√™s (nomes, docstrings, coment√°rios). Documenta√ß√£o geral pode ser em portugu√™s.
- Toda l√≥gica de ingest√£o, valida√ß√£o e transforma√ß√£o de dados deve ser separada da l√≥gica de an√°lise e visualiza√ß√£o.
- Recomenda-se a cria√ß√£o de um m√≥dulo central de ingest√£o de dados (ex: `data_ingestion.py`) respons√°vel por:
    - Navegar na estrutura de diret√≥rios.
    - Carregar arquivos CSV.
    - Validar e padronizar colunas e tipos.
    - Gerar logs de inconsist√™ncias e erros.
    - Retornar o DataFrame "long" padronizado.
- Implementar testes unit√°rios para cada etapa cr√≠tica (carregamento, transforma√ß√£o, an√°lise, visualiza√ß√£o).
- Utilizar um arquivo de configura√ß√£o central (ex: `config.yaml` ou `.py`) para caminhos, m√©tricas, par√¢metros de an√°lise e exporta√ß√£o.
- Outputs (plots, tabelas, arquivos) devem ser versionados e organizados por experimento, round e fase.
- Documentar todas as decis√µes metodol√≥gicas e par√¢metros relevantes em arquivos Markdown.

## Diretrizes para Estrutura√ß√£o e Persist√™ncia de DataFrames

- O DataFrame consolidado em formato "long" √© o padr√£o e fonte √∫nica de verdade para todo o pipeline. Todas as opera√ß√µes de ingest√£o, valida√ß√£o, limpeza e transforma√ß√£o devem resultar nesse formato.
- Subdatasets no formato "wide" podem ser gerados sob demanda, a partir do DataFrame long, para an√°lises espec√≠ficas (correla√ß√£o, causalidade, visualiza√ß√µes comparativas), mas nunca devem substituir o long como fonte principal.
- Recomenda-se fortemente a persist√™ncia dos DataFrames processados (long e, se necess√°rio, wide) em formatos eficientes e port√°veis (Parquet preferencialmente, ou CSV/Feather), organizados por experimento, round e fase. Isso facilita reuso, integra√ß√£o com notebooks (Jupyter) e compartilhamento com outros times ou ferramentas.
- O pipeline deve prover fun√ß√µes utilit√°rias para salvar e carregar datasets processados, garantindo reprodutibilidade e agilidade no desenvolvimento.

## Fase 1: Prepara√ß√£o e Estrat√©gia de Dados

1.  **Defini√ß√£o da Estrutura dos Dados de Entrada:**
    *   1.1. ‚úÖ Confirmar e documentar as colunas essenciais no DataFrame de entrada (ex: `timestamp`, `tenant_id`, `metric_name`, `metric_value`, `experimental_phase`). 
    *   1.2. ‚úÖ Validar os tipos de dados e a consist√™ncia dos identificadores (tenants, m√©tricas, fases). 

2.  **Estrat√©gia de Carregamento, Formatos de DataFrame e Segmenta√ß√£o de Dados:**
    *   2.1. ‚úÖ Implementar ou refinar a l√≥gica para carregar os dados brutos e consolid√°-los em um DataFrame principal em **formato "long"**. 
        *   Este DataFrame conter√° colunas como: `timestamp`, `metric_value`, `metric_name`, `tenant_id`, `experimental_phase`, `round_id`, `experiment_id`. 
    *   2.2. ‚úÖ Desenvolver fun√ß√µes para segmentar o DataFrame principal (formato "long") por: 
        *   Fase experimental (Baseline, Ataque, Recupera√ß√£o).
        *   Tenant individual.
        *   M√©trica espec√≠fica.
        *   Combina√ß√µes destes (ex: dados de uma m√©trica espec√≠fica para um tenant em uma fase).
    *   2.3. ‚úÖ **Estrat√©gia para DataFrames em formato \"wide\":**
        *   Ser√£o gerados em mem√≥ria, dinamicamente, a partir do DataFrame \"long\", conforme a necessidade de cada m√≥dulo de an√°lise (ex: para c√°lculo de correla√ß√µes ou causalidade entre m√∫ltiplas s√©ries temporais).
        *   Estes DataFrames \\\"wide\\\" tamb√©m ser√£o considerados para exporta√ß√£o, permitindo an√°lises futuras ou o uso por parsers espec√≠ficos.
        *   ‚úÖ **Implementar `get_wide_format_for_analysis` para transformar dados longos em largos para uma m√©trica, fase e round espec√≠ficos. 
    *   2.4. ‚úÖ **Exporta√ß√£o dos DataFrames Processados:**
        *   Implementar a funcionalidade para exportar o DataFrame consolidado em formato "long" (ap√≥s carregamento e pr√©-processamento inicial) para um formato de arquivo eficiente (ex: Parquet). 
            *   Objetivo: otimizar o desempenho em an√°lises subsequentes e facilitar a interoperabilidade com outras ferramentas ou processos.
        *   Implementar a funcionalidade para exportar os DataFrames em formato "wide" gerados para formatos de arquivo eficientes (ex: Parquet ou CSV, a ser definido). 
            *   Objetivo: permitir an√°lises futuras ou o uso por parsers espec√≠ficos que possam necessitar deste formato.

3.  **Configura√ß√£o e Aplica√ß√£o de Otimiza√ß√£o de Dados:**
    *   3.1. ‚úÖ Revisar e ajustar otimiza√ß√£o para an√°lise descritiva. 
    *   3.2. ‚úÖ Revisar e ajustar otimiza√ß√£o para an√°lise de correla√ß√£o. 
    *   3.3. ‚úÖ Revisar e ajustar otimiza√ß√£o para an√°lise de causalidade. 
4.  **Defini√ß√£o do Processo de Sele√ß√£o de Vari√°veis e Pares para An√°lise:**
    *   4.1. ‚úÖ Estabelecer crit√©rios para selecionar as m√©tricas de interesse (ex: CPU, mem√≥ria, lat√™ncia). 
    *   4.2. ‚úÖ Definir como os pares de tenants ser√£o selecionados para an√°lises comparativas (inter-tenant). 

## Fase 2: Implementa√ß√£o Detalhada dos M√≥dulos de An√°lise

Cada m√≥dulo seguir√° a arquitetura `BaseModule`, `BaseAnalyzer`, `BaseVisualizer`.

**2.1. M√≥dulo de An√°lise Descritiva (em `src/analysis_descriptive.py`)**
    *   2.1.1. **Estrutura do M√≥dulo:**
        *   ‚úÖ Implementar fun√ß√µes de an√°lise descritiva.
        *   ‚úÖ Implementar fun√ß√µes de visualiza√ß√£o.
    *   2.1.2. **C√°lculos de Estat√≠sticas Descritivas:** 
        *   ‚úÖ Implementar fun√ß√£o para calcular estat√≠sticas descritivas (m√©dia, desvio padr√£o, etc.) por s√©rie temporal (tenant, m√©trica, fase).
    *   2.1.3. **Visualiza√ß√µes:** 
        *   ‚úÖ Implementar fun√ß√£o para gerar plots de s√©ries temporais individuais. 
        *   ‚úÖ Implementar fun√ß√£o para gerar plots de autocorrela√ß√£o (ACF) para cada m√©trica/tenant. 
    *   2.1.4. **Tabelas de Resultados:** 
        *   ‚úÖ Implementar fun√ß√£o para gerar tabela resumo das estat√≠sticas descritivas.
    *   2.1.5. **Testes Unit√°rios:** 
        *   üîÑ Implementados arquivos b√°sicos de teste `test_analysis_descriptive.py`.
        *   üîÑ Expandir cobertura de testes para casos edge.

**2.2. M√≥dulo de An√°lise de Correla√ß√£o e Covari√¢ncia (em `src/analysis_correlation.py`)**
    *   2.2.1. **Estrutura do M√≥dulo:**
        *   ‚úÖ Implementar fun√ß√µes de an√°lise de correla√ß√£o.
        *   ‚úÖ Implementar fun√ß√µes de visualiza√ß√£o para correla√ß√£o.
    *   2.2.2. **C√°lculos de Correla√ß√£o (por fase experimental):**
        *   ‚úÖ Implementar fun√ß√£o para calcular matrizes de correla√ß√£o (Pearson, Kendall, Spearman) entre m√©tricas de tenants distintos.
        *   ‚úÖ Implementar fun√ß√£o para calcular matriz de covari√¢ncia (com dados padronizados).
        *   ‚úÖ Implementar fun√ß√£o para calcular Correla√ß√£o Cruzada com Defasagem (CCF) entre pares de s√©ries.
    *   2.2.3. **Visualiza√ß√µes (por fase experimental):**
        *   ‚úÖ Implementar fun√ß√£o para gerar heatmaps das matrizes de correla√ß√£o.
        *   ‚úÖ Implementar fun√ß√£o para gerar heatmap da matriz de covari√¢ncia padronizada.
        *   ‚úÖ Implementar fun√ß√£o para gerar gr√°ficos de CCF.
        *   ‚úÖ Implementar fun√ß√£o para gerar lag plots.
    *   2.2.4. **Tabelas de Resultados:**
        *   ‚úÖ Implementar fun√ß√£o para gerar tabelas das matrizes de correla√ß√£o e covari√¢ncia.
    *   2.2.5. **Testes Unit√°rios:**
        *   üîÑ Implementados arquivos b√°sicos de teste `test_analysis_correlation.py`.
        *   üîÑ Expandir cobertura de testes para casos edge.

**2.3. M√≥dulo de An√°lise de Causalidade (em `src/analysis_causality.py`)**
    *   2.3.1. **Estrutura do M√≥dulo (Reconstru√ß√£o/Cria√ß√£o):**
        *   ‚úÖ Implementar fun√ß√µes para an√°lise de causalidade abrangendo Granger e Transfer Entropy.
        *   ‚úÖ Implementar fun√ß√µes de visualiza√ß√£o para causalidade.
        *   ‚úÖ Integra√ß√£o com outras funcionalidades do pipeline.
    *   2.3.2. **Implementa√ß√£o da An√°lise de Causalidade de Granger:**
        *   ‚úÖ Implementar fun√ß√£o para aplicar testes de Causalidade de Granger para pares de s√©ries temporais.
        *   ‚úÖ Integrar l√≥gica para determinar `max_lags` (pode usar CCF do m√≥dulo de correla√ß√£o ou crit√©rios como AIC/BIC).
        *   ‚úÖ Assegurar a coleta e o armazenamento adequado dos p-values e estat√≠sticas do teste.
    *   2.3.3. **Implementa√ß√£o da An√°lise de Transfer Entropy:**
        *   ‚úÖ Selecionar e integrar a biblioteca Python para Transfer Entropy (ex: `pyinform`, ou outra). Adicionar ao `requirements.txt`.
        *   ‚úÖ Implementar fun√ß√£o para calcular Transfer Entropy para pares de s√©ries temporais.
        *   ‚úÖ Assegurar a coleta e o armazenamento adequado dos valores de TE.
    *   2.3.4. **Implementa√ß√£o das Visualiza√ß√µes:**
        *   ‚úÖ Implementar fun√ß√£o para gerar plots dos resultados da Causalidade de Granger (ex: heatmap de p-values).
        *   ‚úÖ Implementar fun√ß√£o para gerar plots dos resultados da Transfer Entropy (ex: heatmap de valores TE).
        *   ‚úÖ Implementar fun√ß√£o para gerar visualiza√ß√£o em grafo (usando NetworkX) para ilustrar rela√ß√µes de influ√™ncia.
        *   ‚úÖ Garantir que a legenda dos grafos multi-m√©trica seja contextual e autom√°tica: priorizar p-valor (Granger real) se dispon√≠vel, sen√£o TE, para m√°xima clareza interpretativa.
        *   ‚úÖ Outputs organizados e reprodut√≠veis, com legendas e t√≠tulos informativos.
    *   2.3.5. **Gera√ß√£o de Tabelas de Resultados:**
        *   ‚úÖ Implementar fun√ß√£o para criar tabela consolidada de scores de causalidade (p-values Granger).
        *   ‚úÖ Implementar fun√ß√£o para criar uma matriz de influ√™ncia cruzada resumida com scores de TE.
    *   2.3.6. **Testes Unit√°rios e Integra√ß√£o:**
        *   üîÑ Implementados arquivos b√°sicos de teste `test_analysis_causality.py`.
        *   ‚ùå Falta testar fun√ß√µes de c√°lculo de TE com dados sint√©ticos ou subconjuntos.
        *   üîÑ Testar gera√ß√£o de plots e tabelas para TE.

## Fase 3: Consolida√ß√£o, Interpreta√ß√£o e Gera√ß√£o de Relat√≥rios

1.  **Desenvolvimento da Metodologia de Agrega√ß√£o de Insights:**
    *   3.1.1. ‚úÖ Definir como os resultados das an√°lises descritiva, de correla√ß√£o/covari√¢ncia e de causalidade ser√£o combinados para formar uma narrativa coesa.
    *   3.1.2. ‚úÖ Estabelecer crit√©rios para identificar o "tenant barulhento" e quantificar sua influ√™ncia.
2.  **Implementa√ß√£o da Gera√ß√£o da Tabela Final de Comparativo Inter-Tenant:**
    *   3.2.1. ‚úÖ Projetar a estrutura da tabela final, incluindo as m√©tricas de influ√™ncia e ranking.
    *   3.2.2. ‚úÖ Implementar a l√≥gica para popular esta tabela, utilizando os resultados armazenados pelos Analyzers.
3.  **Documenta√ß√£o Detalhada das Escolhas Metodol√≥gicas:**
    *   3.3.1. üîÑ Registrar todos os par√¢metros utilizados (ex: `max_lags` para Granger, limiares de signific√¢ncia, janelas de CCF).
    *   3.3.2. ‚ùå Justificar as escolhas de bibliotecas e m√©todos.
4.  **An√°lise Comparativa dos Resultados Entre Fases Experimentais:**
    *   3.4.1. ‚ùå Implementar l√≥gica para comparar os resultados (correla√ß√µes, causalidade, etc.) entre as fases de baseline, ataque e recupera√ß√£o.
    *   3.4.2. ‚ùå Preparar visualiza√ß√µes que destaquem essas mudan√ßas.
5.  **Avalia√ß√£o e Implementa√ß√£o (Opcional) de An√°lises com Janelas M√≥veis:**
    *   3.5.1. ‚ùå Se decidido, adaptar os m√≥dulos de Correla√ß√£o e Causalidade para operar com janelas m√≥veis.
    *   3.5.2. ‚ùå Definir o tamanho da janela e o passo (step).
    *   3.5.3. ‚ùå Implementar visualiza√ß√µes para os resultados de janelas m√≥veis (ex: evolu√ß√£o da correla√ß√£o/causalidade ao longo do tempo).
    *   3.5.4. ‚ùå Realizar testes espec√≠ficos para as funcionalidades de janelas m√≥veis.
6.  **An√°lise Consolidada para Experimentos Multi-Round:**
    *   3.6.1. üîÑ Implementar metodologia de an√°lise de consist√™ncia entre rounds para identificar padr√µes persistentes vs. pontuais.
    *   3.6.2. üîÑ Desenvolver an√°lise de robustez de causalidade para distinguir rela√ß√µes causais robustas de correla√ß√µes esp√∫rias.
    *   3.6.3. üîÑ Criar sistema de an√°lise de diverg√™ncia de comportamento para identificar rounds an√¥malos.
    *   3.6.4. üîÑ Implementar agrega√ß√£o de consenso para produzir veredictos consolidados sobre o comportamento do sistema.
    *   3.6.5. üîÑ Desenvolver visualiza√ß√µes de consist√™ncia entre rounds (gr√°ficos com intervalos de confian√ßa, heatmaps, dendrogramas).

## Fase 4: Execu√ß√£o, Debugging e Itera√ß√£o

1.  **Configura√ß√£o do Script Principal de An√°lise:**
    *   4.1.1. ‚úÖ Garantir que o script (`main.py`) possa carregar os dados, instanciar os m√≥dulos de an√°lise e executar as an√°lises em sequ√™ncia.
    *   4.1.2. ‚úÖ Implementar a l√≥gica para salvar todos os outputs (plots, tabelas) de forma organizada.
2.  **Execu√ß√£o com Dados de Demonstra√ß√£o (`demo-data`):**
    *   4.2.1. ‚úÖ Rodar o pipeline completo com os dados de demonstra√ß√£o.
    *   4.2.2. üîÑ Verificar a corretude dos resultados parciais e finais.
3.  **Debugging e Refinamento dos M√≥dulos:**
    *   4.3.1. üîÑ Corrigir bugs identificados durante a execu√ß√£o.
    *   4.3.2. üîÑ Refinar par√¢metros e l√≥gicas com base nos resultados observados.
4.  **An√°lise dos Resultados Iniciais e Itera√ß√£o:**
    *   4.4.1. üîÑ Interpretar os primeiros resultados completos.
    *   4.4.2. üîÑ Com base na interpreta√ß√£o, decidir sobre ajustes nos m√©todos, par√¢metros ou visualiza√ß√µes.
    *   4.4.3. üîÑ Repetir etapas de execu√ß√£o e an√°lise conforme necess√°rio.

## Observa√ß√µes e Filosofia da An√°lise Inter-Tenant

- A identifica√ß√£o de tenants que causam conten√ß√£o de recursos ou degrada√ß√£o ser√° feita exclusivamente de forma data-driven, a partir dos resultados das t√©cnicas estat√≠sticas e de causalidade implementadas (correla√ß√£o, causalidade, influ√™ncia cruzada, etc.).
- N√£o h√° pr√©-julgamento sobre quem √© o "tenant barulhento" ou malicioso: a descoberta ser√° imparcial e baseada em evid√™ncias extra√≠das dos dados.
- A aus√™ncia de determinados tenants em certas fases (baseline, ataque, recupera√ß√£o) √© esperada e deve ser tratada naturalmente pelo pipeline, sem gerar erro ou vi√©s. Todas as an√°lises devem considerar apenas os tenants presentes em cada contexto/fase.
- O pipeline deve ser robusto para lidar com a presen√ßa/aus√™ncia de tenants e arquivos de m√©tricas em cada fase, e as fun√ß√µes de ingest√£o devem registrar (logar) essas aus√™ncias para rastreabilidade.

## Sugest√£o para o Desenvolvimento do Pipeline

- Desenvolva o pipeline de forma incremental, come√ßando pela ingest√£o e valida√ß√£o dos dados, garantindo que o DataFrame long seja corretamente consolidado mesmo com aus√™ncias de tenants/fases.
- Implemente fun√ß√µes utilit√°rias para:
    - Listar todos os tenants presentes em cada fase/round/experimento.
    - Registrar aus√™ncias de tenants ou m√©tricas esperadas (logging).
    - Gerar DataFrames segmentados por fase, tenant, m√©trica, etc.
- Priorize a modularidade: separe claramente ingest√£o, transforma√ß√£o, an√°lise e visualiza√ß√£o.
- Implemente testes unit√°rios para garantir que a ingest√£o lida corretamente com casos de aus√™ncia de dados.
- Considere criar um notebook de explora√ß√£o inicial para validar a consolida√ß√£o dos dados e a robustez do pipeline antes de avan√ßar para an√°lises mais complexas.

## Estrutura de Dados de Entrada (Alinhada ao Experimento Original)

- Os dados de entrada devem ser organizados conforme exporta√ß√£o do experimento original, seguindo a estrutura de diret√≥rios encontrada em `demo-data/`.
- Cada experimento pode conter um ou m√∫ltiplos rounds (ex: `demo-experiment-1-round/`, `demo-experiment-3-rounds/`).
- Dentro de cada round (`round-1/`, `round-2/`, etc.), existem tr√™s fases sequenciais: `1 - Baseline/`, `2 - Attack/`, `3 - Recovery/`.
- Dentro de cada fase, os subdiret√≥rios representam os tenants (ex: `tenant-a/`, `tenant-b/`, ...), al√©m de poss√≠veis diret√≥rios auxiliares (ex: `ingress-nginx/`, `active/`, etc.).
- Cada diret√≥rio de tenant cont√©m arquivos CSV de m√©tricas, cada um com duas colunas: `timestamp,value`.
- O pipeline deve:
    - Navegar recursivamente por todos os experimentos, rounds e fases.
    - Identificar corretamente o experimento, round, fase e tenant para cada arquivo de m√©trica.
    - Ignorar diret√≥rios que n√£o seguem o padr√£o de tenant (ex: `ingress-nginx/`, `active/`, etc.), conforme crit√©rios definidos no contexto do projeto.
    - Consolidar todos os dados em um DataFrame long padronizado, adicionando as colunas: `timestamp`, `metric_value`, `metric_name`, `tenant_id`, `experimental_phase`, `round_id`, `experiment_id`.
    - Garantir a consist√™ncia dos tipos e valores categ√≥ricos durante a ingest√£o.
- Essa l√≥gica deve ser implementada no m√≥dulo central de ingest√£o de dados, garantindo flexibilidade para diferentes estruturas de experimentos e rounds.

## Lacunas e Oportunidades de Melhoria (Adicionado em Junho/2025)

Ap√≥s an√°lise da implementa√ß√£o atual e compara√ß√£o com o plano original, foram identificadas as seguintes lacunas e oportunidades de melhoria:

1. **Implementa√ß√£o do Transfer Entropy**:
   - ‚úÖ Estrutura base implementada no m√≥dulo `analysis_causality.py`
   - ‚ùå Necessidade de refinamento da visualiza√ß√£o contextual dos grafos de causalidade

2. **Completude dos Testes**:
   - üîÑ Arquivos de teste criados (`test_analysis_causality.py`, `test_analysis_correlation.py`, etc.)
   - ‚ùå Falta testes para casos extremos (aus√™ncia de dados, inconsist√™ncias)

3. **An√°lises Comparativas entre Fases**:
   - ‚úÖ Pipeline gera visualiza√ß√µes separadas por fase experimental
   - ‚ùå Aus√™ncia de visualiza√ß√µes espec√≠ficas para compara√ß√£o de baseline/ataque/recupera√ß√£o

4. **Documenta√ß√£o das Escolhas Metodol√≥gicas**:
   - üîÑ Estrutura b√°sica de arquivos Markdown criada
   - ‚ùå Aus√™ncia de justificativas para escolhas metodol√≥gicas

5. **Relat√≥rios e Consolida√ß√£o de Insights**:
   - ‚úÖ Implementa√ß√£o da metodologia de agrega√ß√£o de insights
   - ‚úÖ Estrutura√ß√£o de relat√≥rios automatizados

6. **Janelas M√≥veis**:
   - ‚úÖ M√≥dulo implementado em `analysis_sliding_window.py` com funcionalidades completas
   - ‚úÖ Dispon√≠vel via pipeline dedicado (`pipeline_with_sliding_window.py`)
   - ‚ùå N√£o executado no √∫ltimo teste do pipeline, visualiza√ß√µes ausentes

7. **An√°lise Consolidada para Experimentos Multi-Round**:
   - ‚úÖ Implementa√ß√£o de metodologias espec√≠ficas para an√°lise entre rounds
   - ‚úÖ Avalia√ß√£o de consist√™ncia entre diferentes execu√ß√µes do experimento
   - ‚úÖ M√©tricas de robustez para rela√ß√µes causais identificadas
   - ‚ùå Visualiza√ß√µes implementadas mas n√£o geradas na √∫ltima execu√ß√£o

8. **Depend√™ncias e Integra√ß√£o**:
   - ‚úÖ `NetworkX` adicionado ao `requirements.txt` para visualiza√ß√µes em grafo
   - ‚úÖ Biblioteca `pyinform` para Transfer Entropy especificada no `requirements.txt`
   
9. **Visualiza√ß√µes Ausentes/Incompletas**:
   - ‚ùå Plots de correla√ß√£o n√£o gerados (apenas covari√¢ncia est√° dispon√≠vel)
   - ‚ùå Visualiza√ß√µes de s√©ries temporais combinadas de todas as fases n√£o geradas
   - ‚ùå Plots de detec√ß√£o de anomalias implementados mas n√£o executados
   - ‚ùå Visualiza√ß√µes de janelas deslizantes n√£o geradas

10. **Arquitetura do Pipeline**:
    - ‚ùå M√∫ltiplas implementa√ß√µes de pipeline (`pipeline.py`, `pipeline_new.py`, `pipeline_with_sliding_window.py`)
    - ‚ùå Falta de sistema unificado para configura√ß√£o e execu√ß√£o
    - ‚ùå Aus√™ncia de mecanismos de cache para evitar rec√°lculos desnecess√°rios

## Prioridades para Pr√≥ximos Passos (Junho/2025 - Atualizado)

As seguintes prioridades foram identificadas para concluir o projeto com sucesso:

### Prioridade Alta (Imediata)
1. **Gerar Visualiza√ß√µes Faltantes** ‚ùå:
   - ‚ùå Executar pipeline com janelas deslizantes para gerar an√°lises de correla√ß√£o ao longo do tempo
   - ‚ùå Corrigir gera√ß√£o de plots de correla√ß√£o (atualmente apenas covari√¢ncia √© gerada)
   - ‚ùå Verificar e corrigir execu√ß√£o de plots de s√©ries temporais combinadas de todas as fases
   - ‚ùå Integrar detec√ß√£o de anomalias ao fluxo principal do pipeline

2. **Executar An√°lise Multi-Round Completa** ‚ùå:
   - ‚ùå Verificar e corrigir integra√ß√£o do m√≥dulo `analysis_multi_round.py`
   - ‚ùå Garantir gera√ß√£o de visualiza√ß√µes de consist√™ncia e robustez entre rounds
   - ‚ùå Documentar resultados e insights gerados por esta an√°lise

3. **Corre√ß√µes Cr√≠ticas no Pipeline** ‚úÖ‚ùå:
   - ‚úÖ Desenvolver script utilit√°rio para verifica√ß√£o da gera√ß√£o de todas as visualiza√ß√µes esperadas (`src/run_unified_pipeline.py`)
   - ‚ùå Corrigir chamadas para fun√ß√µes de visualiza√ß√£o ausentes no fluxo principal
   - ‚ùå Garantir que todas as depend√™ncias est√£o sendo instaladas corretamente

### Prioridade M√©dia (Semanas 2-3 de Junho/2025)
1. **Consolida√ß√£o da Arquitetura do Pipeline** ‚ùå:
   - ‚ùå Unificar os m√∫ltiplos arquivos de pipeline em uma implementa√ß√£o modular baseada em plugins
   - ‚ùå Implementar sistema de configura√ß√£o centralizado com valida√ß√£o
   - ‚ùå Desenvolver CLI unificada para controle granular da execu√ß√£o

2. **Documenta√ß√£o T√©cnica** ‚ùå:
   - ‚ùå Documentar detalhadamente todas as visualiza√ß√µes geradas pelo sistema
   - ‚ùå Criar guia t√©cnico sobre como adicionar novos tipos de an√°lise ao pipeline
   - ‚ùå Documentar configura√ß√µes e par√¢metros dispon√≠veis

3. **Refatora√ß√£o de C√≥digo** ‚ùå:
   - ‚ùå Padronizar interface dos diferentes m√≥dulos de an√°lise
   - ‚ùå Melhorar sistema de logging para facilitar depura√ß√£o
   - ‚ùå Remover c√≥digo duplicado entre as diferentes implementa√ß√µes do pipeline

### Prioridade Baixa (Julho-Agosto/2025)
1. **Otimiza√ß√µes de Desempenho** ‚ùå:
   - ‚ùå Implementar sistema de cache para resultados intermedi√°rios
   - ‚ùå Adicionar suporte para paraleliza√ß√£o em est√°gios computacionalmente intensivos
   - ‚ùå Otimizar uso de mem√≥ria para conjuntos de dados grandes

2. **Extensibilidade e Interface** ‚ùå:
   - ‚ùå Desenvolver sistema de plugins para facilitar adi√ß√£o de novas an√°lises
   - ‚ùå Considerar implementa√ß√£o de interface web simples para visualiza√ß√£o de resultados
   - ‚ùå Criar mecanismos para exporta√ß√£o de resultados em diferentes formatos

3. **Testes e CI/CD** ‚ùå:
   - ‚ùå Implementar testes unit√°rios e de integra√ß√£o
   - ‚ùå Configurar pipeline de CI/CD para valida√ß√£o autom√°tica
   - ‚ùå Desenvolver casos de teste com diferentes configura√ß√µes de experimentos
   - ‚úÖ Estruturar tabela final comparativa
   - ‚úÖ Implementar visualiza√ß√µes comparativas inter-tenant

3. **Documentar Escolhas Metodol√≥gicas** ‚úÖ:
   - ‚úÖ Registrar par√¢metros utilizados (ex: `max_lags`, thresholds)
   - ‚úÖ Justificar escolhas de bibliotecas e m√©todos

### Prioridade Baixa (Ap√≥s concluir anteriores) üîÑ
1. **An√°lises com Janelas M√≥veis** ‚úÖ:
   - ‚úÖ Adaptar m√≥dulos para an√°lise temporal din√¢mica
   - ‚úÖ Testar e validar a execu√ß√£o completa do pipeline com janelas m√≥veis

2. **An√°lise Consolidada para Experimentos Multi-Round** üîÑ:
   - üîÑ Implementar an√°lise de consist√™ncia entre rounds
   - üîÑ Desenvolver metodologia de robustez para causalidade
   - üîÑ Criar sistema de agrega√ß√£o de consenso entre rounds
   - üîÑ Implementar visualiza√ß√µes espec√≠ficas para compara√ß√£o entre rounds

3. **Refinamentos Est√©ticos e Usabilidade** üîÑ:
   - ‚úÖ Melhorar formata√ß√£o de gr√°ficos (estilo tableau-colorblind10)
   - ‚úÖ Aprimorar mensagens de log e feedback

4. **Documenta√ß√£o para Usu√°rios Finais** üîÑ:
   - üîÑ Tutorial de uso do pipeline
   - üîÑ Guia de interpreta√ß√£o dos resultados

## Otimiza√ß√µes do Pipeline e Corre√ß√µes de Visualiza√ß√µes (Adicionado em Junho/2025)

Com base na an√°lise do estado atual da implementa√ß√£o e no levantamento de plots n√£o gerados ou incompletos, identificamos as seguintes oportunidades de melhoria organizadas em fases progressivas:

### Fase 1: Corre√ß√£o e Integra√ß√£o de Visualiza√ß√µes Existentes (Prioridade Alta)

1. **Execu√ß√£o de Visualiza√ß√µes Implementadas mas N√£o Geradas:**
   - ‚ùå Executar o pipeline com janelas deslizantes para gerar plots de correla√ß√£o ao longo do tempo
   - ‚ùå Garantir a gera√ß√£o de plots de correla√ß√£o ausentes (apenas correla√ß√£o, j√° que covari√¢ncia est√° sendo gerada)
   - ‚ùå Executar m√≥dulo de an√°lise multi-round para gerar visualiza√ß√µes de consist√™ncia entre rounds
   - ‚ùå Verificar ambiente de execu√ß√£o para garantir que as depend√™ncias para Transfer Entropy est√£o dispon√≠veis

2. **Corre√ß√£o de Problemas na Gera√ß√£o de Visualiza√ß√µes:**
   - ‚ùå Investigar e corrigir problemas na gera√ß√£o de plots de s√©ries temporais combinadas de todas as fases
   - ‚ùå Adicionar chamadas para fun√ß√µes de detec√ß√£o e visualiza√ß√£o de anomalias no pipeline principal

### Fase 2: Unifica√ß√£o e Modulariza√ß√£o do Pipeline (Prioridade M√©dia)

1. **Consolida√ß√£o dos M√∫ltiplos Arquivos de Pipeline:**
   - ‚ùå Criar um framework de pipeline unificado que substitua os m√∫ltiplos arquivos atuais (`pipeline.py`, `pipeline_new.py`, `pipeline_with_sliding_window.py`)
   - ‚ùå Implementar sistema de est√°gios de pipeline como plugins carreg√°veis baseados em configura√ß√£o
   - ‚ùå Garantir compatibilidade com o pipeline existente durante a transi√ß√£o

2. **Centraliza√ß√£o de Configura√ß√µes:**
   - ‚ùå Criar um sistema de configura√ß√£o central baseado em YAML mais abrangente
   - ‚ùå Parametrizar todos os limiares, janelas e op√ß√µes atualmente hardcoded no c√≥digo
   - ‚ùå Adicionar documenta√ß√£o inline para todos os par√¢metros configur√°veis

3. **Interface de Linha de Comando (CLI) Unificada:**
   - ‚ùå Desenvolver CLI integrada para controlar todos os aspectos da execu√ß√£o do pipeline
   - ‚ùå Implementar op√ß√µes de execu√ß√£o espec√≠ficas (apenas descritiva, apenas correla√ß√£o, etc.)
   - ‚ùå Adicionar suporte para execu√ß√£o de est√°gios espec√≠ficos ou combina√ß√µes de est√°gios

### Fase 3: Otimiza√ß√µes de Desempenho e Usabilidade (Prioridade Baixa)

1. **Sistema de Cache Inteligente:**
   - ‚ùå Implementar sistema de cache baseado em hash para evitar rec√°lculos desnecess√°rios
   - ‚ùå Adicionar invalida√ß√£o seletiva de cache para recomputar apenas o necess√°rio
   - ‚ùå Persistir resultados intermedi√°rios em formatos eficientes

2. **Paraleliza√ß√£o de An√°lises Independentes:**
   - ‚ùå Identificar opera√ß√µes paraleliz√°veis (an√°lises entre diferentes m√©tricas, rounds, etc.)
   - ‚ùå Implementar paraleliza√ß√£o com multiprocessing ou threading onde aplic√°vel
   - ‚ùå Adicionar controle de concorr√™ncia e depend√™ncias entre tarefas do pipeline

3. **Interface Web Simples (Opcional):**
   - ‚ùå Criar interface web b√°sica para visualizar resultados e configurar execu√ß√µes
   - ‚ùå Implementar dashboard para monitoramento de execu√ß√µes longas
   - ‚ùå Adicionar capacidade de salvar e compartilhar configura√ß√µes

### Plano de Implementa√ß√£o Progressivo

Para garantir um progresso cont√≠nuo e tang√≠vel, recomendamos a seguinte abordagem:

1. **Sprint 1 (1 semana):**
   - Focar na Fase 1 para garantir que todas as visualiza√ß√µes implementadas est√£o funcionando corretamente
   - Executar `python -m src.pipeline_with_sliding_window` para gerar os plots de janelas deslizantes
   - Corrigir problemas imediatos de gera√ß√£o de plots
   
2. **Sprint 2 (2 semanas):**
   - Iniciar a consolida√ß√£o do pipeline conforme a Fase 2
   - Desenvolver o novo framework de est√°gios como plugins
   - Implementar configura√ß√£o central baseada em YAML
   
3. **Sprint 3 (2 semanas):**
   - Finalizar a transi√ß√£o para o pipeline unificado
   - Implementar CLI integrada
   - Testar e validar com diferentes configura√ß√µes
   
4. **Sprint 4 (conforme disponibilidade):**
   - Implementar otimiza√ß√µes da Fase 3
   - Focar em sistemas de cache e paraleliza√ß√£o
   - Considerar interface web se o tempo permitir

Este plano equilibra a necessidade de corre√ß√µes imediatas com melhorias arquiteturais de longo prazo, garantindo que o sistema continue funcionando enquanto √© progressivamente aprimorado.

## Otimiza√ß√µes do Pipeline e Corre√ß√µes de Visualiza√ß√µes (Junho/2025)

Com base no levantamento realizado em 03/06/2025, identificamos uma s√©rie de visualiza√ß√µes que est√£o implementadas no c√≥digo mas n√£o est√£o sendo geradas na √∫ltima execu√ß√£o do pipeline. Tamb√©m foram identificadas oportunidades de otimiza√ß√£o da arquitetura do pipeline para torn√°-lo mais modular, eficiente e f√°cil de manter.

### Visualiza√ß√µes Implementadas vs. Geradas

| Tipo de Visualiza√ß√£o | Status | Localiza√ß√£o da Implementa√ß√£o | Problema Identificado |
|----------------------|--------|------------------------------|------------------------|
| Plots de correla√ß√£o | ‚ùå N√£o Gerado | `analysis_correlation.py` | Apenas visualiza√ß√µes de covari√¢ncia est√£o sendo geradas |
| Plots de janela deslizante | ‚ùå N√£o Gerado | `analysis_sliding_window.py` | M√≥dulo implementado, mas pipeline dedicado n√£o executado |
| Visualiza√ß√£o de s√©ries temporais combinadas | ‚ùå N√£o Gerado | `analysis_descriptive.py` | Fun√ß√£o implementada mas n√£o chamada no pipeline principal |
| Plots de detec√ß√£o de anomalias | ‚ùå N√£o Gerado | `analysis_descriptive.py` | Fun√ß√£o implementada mas n√£o integrada ao pipeline |
| Visualiza√ß√µes de an√°lise multi-round | ‚ùå N√£o Gerado | `analysis_multi_round.py` | Est√°gio inclu√≠do no pipeline com janelas deslizantes, mas n√£o no principal |

### Plano de Otimiza√ß√£o do Pipeline

#### Fase 1: Corre√ß√£o Imediata das Visualiza√ß√µes (Junho/2025 - Semana 1)

1. **Execu√ß√£o do Pipeline Unificado**:
   - Um script unificado foi desenvolvido em `src/run_unified_pipeline.py` para executar todas as an√°lises
   - Executar: `python -m src.run_unified_pipeline --config config/pipeline_config.yaml`
   - O script verifica automaticamente quais visualiza√ß√µes foram geradas e quais est√£o faltando
   - Para desativar an√°lises espec√≠ficas: `--no-sliding-window` ou `--no-multi-round`

2. **Corre√ß√£o dos Plots de Correla√ß√£o**:
   - Modificar o est√°gio `CorrelationAnalysisStage` para chamar tanto `plot_correlation_heatmap` quanto `plot_covariance_heatmap`
   - Verificar se as visualiza√ß√µes de correla√ß√£o est√£o sendo geradas corretamente
   - Garantir que o diret√≥rio de sa√≠da existe e tem permiss√µes adequadas

3. **Integra√ß√£o da Detec√ß√£o de Anomalias**:
   - Modificar `DescriptiveAnalysisStage` para chamar as fun√ß√µes de detec√ß√£o de anomalias
   - Criar diret√≥rio espec√≠fico para salvar os plots de anomalias

#### Fase 2: Consolida√ß√£o da Arquitetura (Junho/2025 - Semanas 2-3)

1. **Unifica√ß√£o dos Arquivos de Pipeline**:
   - Consolidar `pipeline.py`, `pipeline_new.py` e `pipeline_with_sliding_window.py` em um √∫nico arquivo
   - Implementar sistema de plugins para diferentes est√°gios do pipeline
   - Criar configura√ß√£o baseada em YAML para ativar/desativar m√≥dulos espec√≠ficos

2. **Sistema de Configura√ß√£o Centralizado**:
   - Refatorar `parse_config.py` para um sistema mais robusto e extens√≠vel
   - Implementar valida√ß√£o de configura√ß√£o com schemas
   - Documentar todas as op√ß√µes de configura√ß√£o dispon√≠veis

3. **CLI Unificada**:
   - Desenvolver uma interface de linha de comando unificada usando `argparse` ou `click`
   - Oferecer op√ß√µes para executar apenas partes espec√≠ficas do pipeline
   - Implementar flags para controle de verbosidade e depura√ß√£o

#### Fase 3: Otimiza√ß√µes de Desempenho (Julho/2025)

1. **Sistema de Cache**:
   - Implementar sistema de cache para resultados intermedi√°rios do pipeline
   - Usar hashes de configura√ß√£o como chaves de cache
   - Adicionar op√ß√£o para for√ßar rec√°lculo ignorando o cache

2. **Paraleliza√ß√£o de Processamento**:
   - Identificar est√°gios independentes que podem ser executados em paralelo
   - Implementar processamento multiprocesso para an√°lises intensivas
   - Adicionar controle de concorr√™ncia para evitar uso excessivo de recursos

3. **Otimiza√ß√£o de Mem√≥ria**:
   - Implementar streaming de dados para processamento de grandes conjuntos
   - Utilizar formatos de arquivo mais eficientes para persist√™ncia
   - Implementar libera√ß√£o estrat√©gica de mem√≥ria durante o processamento

#### Fase 4: Extensibilidade e Manutenibilidade (Agosto/2025)

1. **Documenta√ß√£o Aprimorada**:
   - Gerar documenta√ß√£o autom√°tica usando Sphinx
   - Adicionar exemplos de uso para cada m√≥dulo e fun√ß√£o
   - Criar tutoriais para casos de uso comuns

2. **Testes Autom√°ticos**:
   - Implementar testes unit√°rios para componentes cr√≠ticos
   - Adicionar testes de integra√ß√£o para o pipeline completo
   - Configurar CI/CD para execu√ß√£o autom√°tica de testes

3. **M√©tricas de Qualidade**:
   - Implementar coleta de m√©tricas de desempenho do pipeline
   - Adicionar logging estruturado para an√°lise e depura√ß√£o
   - Criar dashboards para visualiza√ß√£o de m√©tricas de qualidade e desempenho

