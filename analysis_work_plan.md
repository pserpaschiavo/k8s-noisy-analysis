# Plano de Trabalho para AnÃ¡lise de SÃ©ries Temporais Multi-Tenant

O objetivo Ã© investigar a co-variaÃ§Ã£o, relaÃ§Ãµes causais e flutuaÃ§Ãµes temporais das mÃ©tricas entre diferentes tenants e fases experimentais (baseline, ataque, recuperaÃ§Ã£o), utilizando ferramentas estatÃ­sticas bÃ¡sicas, interpretÃ¡veis e confiÃ¡veis.

## Status do Projeto (Atualizado em Junho/2025)

- âœ… **ConcluÃ­do**: Estrutura principal do projeto implementada, ingestÃ£o de dados, segmentaÃ§Ã£o, persistÃªncia, componentes de anÃ¡lise descritiva, correlaÃ§Ã£o e causalidade bÃ¡sicos.
- ğŸ”„ **Em andamento**: Refinamento do mÃ³dulo de Causalidade com Transfer Entropy, testes unitÃ¡rios completos.
- âŒ **Pendente**: ConsolidaÃ§Ã£o da metodologia de anÃ¡lise inter-tenant, relatÃ³rios comparativos entre fases experimentais, documentaÃ§Ã£o detalhada das escolhas metodolÃ³gicas, anÃ¡lises com janelas mÃ³veis.

## Diretrizes Gerais para o Desenvolvimento do Pipeline

- O DataFrame consolidado em formato "long" deve ser a Ãºnica fonte de verdade para todas as anÃ¡lises. Todas as transformaÃ§Ãµes e segmentaÃ§Ãµes devem partir dele.
- Todas as funÃ§Ãµes de carregamento, transformaÃ§Ã£o e exportaÃ§Ã£o de dados devem ser modulares, testÃ¡veis e possuir logging detalhado de etapas e erros.
- O pipeline deve ser desenvolvido de forma incremental: comece com um subconjunto pequeno de dados/mÃ©tricas, garanta testes e outputs corretos, depois expanda.
- O cÃ³digo deve ser escrito em inglÃªs (nomes, docstrings, comentÃ¡rios). DocumentaÃ§Ã£o geral pode ser em portuguÃªs.
- Toda lÃ³gica de ingestÃ£o, validaÃ§Ã£o e transformaÃ§Ã£o de dados deve ser separada da lÃ³gica de anÃ¡lise e visualizaÃ§Ã£o.
- Recomenda-se a criaÃ§Ã£o de um mÃ³dulo central de ingestÃ£o de dados (ex: `data_ingestion.py`) responsÃ¡vel por:
    - Navegar na estrutura de diretÃ³rios.
    - Carregar arquivos CSV.
    - Validar e padronizar colunas e tipos.
    - Gerar logs de inconsistÃªncias e erros.
    - Retornar o DataFrame "long" padronizado.
- Implementar testes unitÃ¡rios para cada etapa crÃ­tica (carregamento, transformaÃ§Ã£o, anÃ¡lise, visualizaÃ§Ã£o).
- Utilizar um arquivo de configuraÃ§Ã£o central (ex: `config.yaml` ou `.py`) para caminhos, mÃ©tricas, parÃ¢metros de anÃ¡lise e exportaÃ§Ã£o.
- Outputs (plots, tabelas, arquivos) devem ser versionados e organizados por experimento, round e fase.
- Documentar todas as decisÃµes metodolÃ³gicas e parÃ¢metros relevantes em arquivos Markdown.

## Diretrizes para EstruturaÃ§Ã£o e PersistÃªncia de DataFrames

- O DataFrame consolidado em formato "long" Ã© o padrÃ£o e fonte Ãºnica de verdade para todo o pipeline. Todas as operaÃ§Ãµes de ingestÃ£o, validaÃ§Ã£o, limpeza e transformaÃ§Ã£o devem resultar nesse formato.
- Subdatasets no formato "wide" podem ser gerados sob demanda, a partir do DataFrame long, para anÃ¡lises especÃ­ficas (correlaÃ§Ã£o, causalidade, visualizaÃ§Ãµes comparativas), mas nunca devem substituir o long como fonte principal.
- Recomenda-se fortemente a persistÃªncia dos DataFrames processados (long e, se necessÃ¡rio, wide) em formatos eficientes e portÃ¡veis (Parquet preferencialmente, ou CSV/Feather), organizados por experimento, round e fase. Isso facilita reuso, integraÃ§Ã£o com notebooks (Jupyter) e compartilhamento com outros times ou ferramentas.
- O pipeline deve prover funÃ§Ãµes utilitÃ¡rias para salvar e carregar datasets processados, garantindo reprodutibilidade e agilidade no desenvolvimento.

## Fase 1: PreparaÃ§Ã£o e EstratÃ©gia de Dados

1.  **DefiniÃ§Ã£o da Estrutura dos Dados de Entrada:**
    *   1.1. âœ… Confirmar e documentar as colunas essenciais no DataFrame de entrada (ex: `timestamp`, `tenant_id`, `metric_name`, `metric_value`, `experimental_phase`). 
    *   1.2. âœ… Validar os tipos de dados e a consistÃªncia dos identificadores (tenants, mÃ©tricas, fases). 

2.  **EstratÃ©gia de Carregamento, Formatos de DataFrame e SegmentaÃ§Ã£o de Dados:**
    *   2.1. âœ… Implementar ou refinar a lÃ³gica para carregar os dados brutos e consolidÃ¡-los em um DataFrame principal em **formato "long"**. 
        *   Este DataFrame conterÃ¡ colunas como: `timestamp`, `metric_value`, `metric_name`, `tenant_id`, `experimental_phase`, `round_id`, `experiment_id`. 
    *   2.2. âœ… Desenvolver funÃ§Ãµes para segmentar o DataFrame principal (formato "long") por: 
        *   Fase experimental (Baseline, Ataque, RecuperaÃ§Ã£o).
        *   Tenant individual.
        *   MÃ©trica especÃ­fica.
        *   CombinaÃ§Ãµes destes (ex: dados de uma mÃ©trica especÃ­fica para um tenant em uma fase).
    *   2.3. âœ… **EstratÃ©gia para DataFrames em formato \"wide\":**
        *   SerÃ£o gerados em memÃ³ria, dinamicamente, a partir do DataFrame \"long\", conforme a necessidade de cada mÃ³dulo de anÃ¡lise (ex: para cÃ¡lculo de correlaÃ§Ãµes ou causalidade entre mÃºltiplas sÃ©ries temporais).
        *   Estes DataFrames \\\"wide\\\" tambÃ©m serÃ£o considerados para exportaÃ§Ã£o, permitindo anÃ¡lises futuras ou o uso por parsers especÃ­ficos.
        *   âœ… **Implementar `get_wide_format_for_analysis` para transformar dados longos em largos para uma mÃ©trica, fase e round especÃ­ficos. 
    *   2.4. âœ… **ExportaÃ§Ã£o dos DataFrames Processados:**
        *   Implementar a funcionalidade para exportar o DataFrame consolidado em formato "long" (apÃ³s carregamento e prÃ©-processamento inicial) para um formato de arquivo eficiente (ex: Parquet). 
            *   Objetivo: otimizar o desempenho em anÃ¡lises subsequentes e facilitar a interoperabilidade com outras ferramentas ou processos.
        *   Implementar a funcionalidade para exportar os DataFrames em formato "wide" gerados para formatos de arquivo eficientes (ex: Parquet ou CSV, a ser definido). 
            *   Objetivo: permitir anÃ¡lises futuras ou o uso por parsers especÃ­ficos que possam necessitar deste formato.

3.  **ConfiguraÃ§Ã£o e AplicaÃ§Ã£o de OtimizaÃ§Ã£o de Dados:**
    *   3.1. ğŸ”„ Revisar e ajustar otimizaÃ§Ã£o para anÃ¡lise descritiva. 
    *   3.2. ğŸ”„ Revisar e ajustar otimizaÃ§Ã£o para anÃ¡lise de correlaÃ§Ã£o. 
    *   3.3. ğŸ”„ Revisar e ajustar otimizaÃ§Ã£o para anÃ¡lise de causalidade. 
4.  **DefiniÃ§Ã£o do Processo de SeleÃ§Ã£o de VariÃ¡veis e Pares para AnÃ¡lise:**
    *   4.1. âœ… Estabelecer critÃ©rios para selecionar as mÃ©tricas de interesse (ex: CPU, memÃ³ria, latÃªncia). 
    *   4.2. âœ… Definir como os pares de tenants serÃ£o selecionados para anÃ¡lises comparativas (inter-tenant). 

# SequÃªncia Recomendada para o Desenvolvimento do Pipeline

## 1. EstruturaÃ§Ã£o Inicial e OrganizaÃ§Ã£o do Projeto

1. **DefiniÃ§Ã£o e CriaÃ§Ã£o da Estrutura de DiretÃ³rios:**
    - `data/raw/` â€” Dados brutos extraÃ­dos (ex: CSVs originais).
    - `data/processed/` â€” DataFrames processados (long/wide) em Parquet/CSV.
    - `outputs/plots/` â€” GrÃ¡ficos gerados por fase, experimento, round.
    - `outputs/tables/` â€” Tabelas e resumos exportados.
    - `notebooks/` â€” Jupyter Notebooks para exploraÃ§Ã£o e validaÃ§Ã£o.
    - `config/` â€” Arquivos de configuraÃ§Ã£o (YAML, JSON, etc).
    - `logs/` â€” Logs de execuÃ§Ã£o e validaÃ§Ã£o.
    - `src/` â€” CÃ³digo-fonte do pipeline (mÃ³dulos de ingestÃ£o, anÃ¡lise, visualizaÃ§Ã£o, etc).

## 2. Desenvolvimento Incremental do Pipeline

### 2.1. Funcionalidades Fundamentais

1. **ConfiguraÃ§Ã£o Centralizada:**
    - Criar arquivo de configuraÃ§Ã£o (ex: `config.yaml`) para caminhos, mÃ©tricas, parÃ¢metros globais.
2. **IngestÃ£o e ValidaÃ§Ã£o de Dados:**
    - Implementar mÃ³dulo/funÃ§Ã£o para navegar na estrutura de diretÃ³rios, carregar CSVs, validar e padronizar colunas/tipos.
    - Gerar logs de inconsistÃªncias e erros.
    - Consolidar tudo em um DataFrame long padronizado.
3. **PersistÃªncia de DataFrames:**
    - Implementar funÃ§Ãµes utilitÃ¡rias para salvar/carregar DataFrames long (e wide, se necessÃ¡rio) em Parquet/CSV.
    - Organizar arquivos por experimento, round e fase.
4. **Testes UnitÃ¡rios BÃ¡sicos:**
    - Testar ingestÃ£o, validaÃ§Ã£o e persistÃªncia.

### 2.2. SegmentaÃ§Ã£o e ExportaÃ§Ã£o

1. **FunÃ§Ãµes de SegmentaÃ§Ã£o:**
    - Permitir filtragem do DataFrame long por fase, tenant, mÃ©trica, etc.
2. **GeraÃ§Ã£o de DataFrames Wide sob Demanda:**
    - Implementar funÃ§Ã£o para converter longâ†’wide para anÃ¡lises especÃ­ficas.
3. **ExportaÃ§Ã£o de Subdatasets:**
    - Exportar subconjuntos relevantes para uso em notebooks ou outras ferramentas.

### 2.3. AnÃ¡lise Descritiva

1. **MÃ³dulo Descritivo:**
    - Calcular estatÃ­sticas bÃ¡sicas (mÃ©dia, desvio padrÃ£o, skewness, kurtosis) por sÃ©rie temporal.
    - Gerar plots simples (sÃ©ries temporais, histogramas, ACF).
    - Exportar tabelas resumo.
2. **Testes UnitÃ¡rios:**
    - Testar cÃ¡lculos e geraÃ§Ã£o de plots/tabelas.

### 2.4. MÃ³dulos AvanÃ§ados

1. **CorrelaÃ§Ã£o e CovariÃ¢ncia:**
    - Implementar cÃ¡lculos e visualizaÃ§Ãµes de correlaÃ§Ã£o/covariÃ¢ncia entre tenants/mÃ©tricas.
2. **Causalidade:**
    - Implementar testes de Granger e Transfer Entropy, visualizaÃ§Ãµes e tabelas.
3. **ComparaÃ§Ã£o entre Fases:**
    - LÃ³gica para comparar resultados entre baseline, ataque e recuperaÃ§Ã£o.
4. **Janelas MÃ³veis (Opcional):**
    - AdaptaÃ§Ã£o dos mÃ³dulos para anÃ¡lises com janelas mÃ³veis.

### 2.5. ConsolidaÃ§Ã£o, RelatÃ³rios e IteraÃ§Ã£o

1. **AgregaÃ§Ã£o de Insights:**
    - Combinar resultados dos mÃ³dulos para formar narrativa coesa.
2. **Tabela Final Comparativa:**
    - Gerar ranking e mÃ©tricas de influÃªncia inter-tenant.
3. **DocumentaÃ§Ã£o e Justificativas:**
    - Registrar parÃ¢metros, decisÃµes e mÃ©todos.
4. **ExecuÃ§Ã£o, Debugging e IteraÃ§Ã£o:**
    - Rodar pipeline completo, refinar e iterar conforme resultados.

## Fase 2: ImplementaÃ§Ã£o Detalhada dos MÃ³dulos de AnÃ¡lise

Cada mÃ³dulo seguirÃ¡ a arquitetura `BaseModule`, `BaseAnalyzer`, `BaseVisualizer`.

**2.1. MÃ³dulo de AnÃ¡lise Descritiva (em `src/analysis_descriptive.py`)**
    *   2.1.1. **Estrutura do MÃ³dulo:**
        *   âœ… Implementar funÃ§Ãµes de anÃ¡lise descritiva.
        *   âœ… Implementar funÃ§Ãµes de visualizaÃ§Ã£o.
    *   2.1.2. **CÃ¡lculos de EstatÃ­sticas Descritivas:** 
        *   âœ… Implementar funÃ§Ã£o para calcular estatÃ­sticas descritivas (mÃ©dia, desvio padrÃ£o, etc.) por sÃ©rie temporal (tenant, mÃ©trica, fase).
    *   2.1.3. **VisualizaÃ§Ãµes:** 
        *   âœ… Implementar funÃ§Ã£o para gerar plots de sÃ©ries temporais individuais. 
        *   âœ… Implementar funÃ§Ã£o para gerar plots de autocorrelaÃ§Ã£o (ACF) para cada mÃ©trica/tenant. 
    *   2.1.4. **Tabelas de Resultados:** 
        *   âœ… Implementar funÃ§Ã£o para gerar tabela resumo das estatÃ­sticas descritivas.
    *   2.1.5. **Testes UnitÃ¡rios:** 
        *   ğŸ”„ Implementados arquivos bÃ¡sicos de teste `test_analysis_descriptive.py`.
        *   ğŸ”„ Expandir cobertura de testes para casos edge.

**2.2. MÃ³dulo de AnÃ¡lise de CorrelaÃ§Ã£o e CovariÃ¢ncia (em `src/analysis_correlation.py`)**
    *   2.2.1. **Estrutura do MÃ³dulo:**
        *   âœ… Implementar funÃ§Ãµes de anÃ¡lise de correlaÃ§Ã£o.
        *   âœ… Implementar funÃ§Ãµes de visualizaÃ§Ã£o para correlaÃ§Ã£o.
    *   2.2.2. **CÃ¡lculos de CorrelaÃ§Ã£o (por fase experimental):**
        *   âœ… Implementar funÃ§Ã£o para calcular matrizes de correlaÃ§Ã£o (Pearson, Kendall, Spearman) entre mÃ©tricas de tenants distintos.
        *   âœ… Implementar funÃ§Ã£o para calcular matriz de covariÃ¢ncia (com dados padronizados).
        *   ğŸ”„ Implementar funÃ§Ã£o para calcular CorrelaÃ§Ã£o Cruzada com Defasagem (CCF) entre pares de sÃ©ries.
    *   2.2.3. **VisualizaÃ§Ãµes (por fase experimental):**
        *   âœ… Implementar funÃ§Ã£o para gerar heatmaps das matrizes de correlaÃ§Ã£o.
        *   âœ… Implementar funÃ§Ã£o para gerar heatmap da matriz de covariÃ¢ncia padronizada.
        *   ğŸ”„ Implementar funÃ§Ã£o para gerar grÃ¡ficos de CCF.
        *   ğŸ”„ Implementar funÃ§Ã£o para gerar lag plots.
    *   2.2.4. **Tabelas de Resultados:**
        *   âœ… Implementar funÃ§Ã£o para gerar tabelas das matrizes de correlaÃ§Ã£o e covariÃ¢ncia.
    *   2.2.5. **Testes UnitÃ¡rios:**
        *   ğŸ”„ Implementados arquivos bÃ¡sicos de teste `test_analysis_correlation.py`.
        *   ğŸ”„ Expandir cobertura de testes para casos edge.

**2.3. MÃ³dulo de AnÃ¡lise de Causalidade (em `src/analysis_causality.py`)**
    *   2.3.1. **Estrutura do MÃ³dulo (ReconstruÃ§Ã£o/CriaÃ§Ã£o):**
        *   âœ… Implementar funÃ§Ãµes para anÃ¡lise de causalidade abrangendo Granger e Transfer Entropy.
        *   âœ… Implementar funÃ§Ãµes de visualizaÃ§Ã£o para causalidade.
        *   âœ… IntegraÃ§Ã£o com outras funcionalidades do pipeline.
    *   2.3.2. **ImplementaÃ§Ã£o da AnÃ¡lise de Causalidade de Granger:**
        *   âœ… Implementar funÃ§Ã£o para aplicar testes de Causalidade de Granger para pares de sÃ©ries temporais.
        *   âœ… Integrar lÃ³gica para determinar `max_lags` (pode usar CCF do mÃ³dulo de correlaÃ§Ã£o ou critÃ©rios como AIC/BIC).
        *   âœ… Assegurar a coleta e o armazenamento adequado dos p-values e estatÃ­sticas do teste.
    *   2.3.3. **ImplementaÃ§Ã£o da AnÃ¡lise de Transfer Entropy:**
        *   ğŸ”„ Selecionar e integrar a biblioteca Python para Transfer Entropy (ex: `pyinform`, ou outra). Adicionar ao `requirements.txt`.
        *   ğŸ”„ Implementar funÃ§Ã£o para calcular Transfer Entropy para pares de sÃ©ries temporais.
        *   ğŸ”„ Assegurar a coleta e o armazenamento adequado dos valores de TE.
    *   2.3.4. **ImplementaÃ§Ã£o das VisualizaÃ§Ãµes:**
        *   âœ… Implementar funÃ§Ã£o para gerar plots dos resultados da Causalidade de Granger (ex: heatmap de p-values).
        *   ğŸ”„ Implementar funÃ§Ã£o para gerar plots dos resultados da Transfer Entropy (ex: heatmap de valores TE).
        *   âœ… Implementar funÃ§Ã£o para gerar visualizaÃ§Ã£o em grafo (usando NetworkX) para ilustrar relaÃ§Ãµes de influÃªncia.
        *   ğŸ”„ Garantir que a legenda dos grafos multi-mÃ©trica seja contextual e automÃ¡tica: priorizar p-valor (Granger real) se disponÃ­vel, senÃ£o TE, para mÃ¡xima clareza interpretativa.
        *   âœ… Outputs organizados e reprodutÃ­veis, com legendas e tÃ­tulos informativos.
    *   2.3.5. **GeraÃ§Ã£o de Tabelas de Resultados:**
        *   âœ… Implementar funÃ§Ã£o para criar tabela consolidada de scores de causalidade (p-values Granger).
        *   ğŸ”„ Implementar funÃ§Ã£o para criar uma matriz de influÃªncia cruzada resumida com scores de TE.
    *   2.3.6. **Testes UnitÃ¡rios e IntegraÃ§Ã£o:**
        *   ğŸ”„ Implementados arquivos bÃ¡sicos de teste `test_analysis_causality.py`.
        *   âŒ Falta testar funÃ§Ãµes de cÃ¡lculo de TE com dados sintÃ©ticos ou subconjuntos.
        *   ğŸ”„ Testar geraÃ§Ã£o de plots e tabelas para TE.

## Fase 3: ConsolidaÃ§Ã£o, InterpretaÃ§Ã£o e GeraÃ§Ã£o de RelatÃ³rios

1.  **Desenvolvimento da Metodologia de AgregaÃ§Ã£o de Insights:**
    *   3.1.1. âŒ Definir como os resultados das anÃ¡lises descritiva, de correlaÃ§Ã£o/covariÃ¢ncia e de causalidade serÃ£o combinados para formar uma narrativa coesa.
    *   3.1.2. âŒ Estabelecer critÃ©rios para identificar o "tenant barulhento" e quantificar sua influÃªncia.
2.  **ImplementaÃ§Ã£o da GeraÃ§Ã£o da Tabela Final de Comparativo Inter-Tenant:**
    *   3.2.1. âŒ Projetar a estrutura da tabela final, incluindo as mÃ©tricas de influÃªncia e ranking.
    *   3.2.2. âŒ Implementar a lÃ³gica para popular esta tabela, utilizando os resultados armazenados pelos Analyzers.
3.  **DocumentaÃ§Ã£o Detalhada das Escolhas MetodolÃ³gicas:**
    *   3.3.1. ğŸ”„ Registrar todos os parÃ¢metros utilizados (ex: `max_lags` para Granger, limiares de significÃ¢ncia, janelas de CCF).
    *   3.3.2. âŒ Justificar as escolhas de bibliotecas e mÃ©todos.
4.  **AnÃ¡lise Comparativa dos Resultados Entre Fases Experimentais:**
    *   3.4.1. âŒ Implementar lÃ³gica para comparar os resultados (correlaÃ§Ãµes, causalidade, etc.) entre as fases de baseline, ataque e recuperaÃ§Ã£o.
    *   3.4.2. âŒ Preparar visualizaÃ§Ãµes que destaquem essas mudanÃ§as.
5.  **AvaliaÃ§Ã£o e ImplementaÃ§Ã£o (Opcional) de AnÃ¡lises com Janelas MÃ³veis:**
    *   3.5.1. âŒ Se decidido, adaptar os mÃ³dulos de CorrelaÃ§Ã£o e Causalidade para operar com janelas mÃ³veis.
    *   3.5.2. âŒ Definir o tamanho da janela e o passo (step).
    *   3.5.3. âŒ Implementar visualizaÃ§Ãµes para os resultados de janelas mÃ³veis (ex: evoluÃ§Ã£o da correlaÃ§Ã£o/causalidade ao longo do tempo).
    *   3.5.4. âŒ Realizar testes especÃ­ficos para as funcionalidades de janelas mÃ³veis.

## Fase 4: ExecuÃ§Ã£o, Debugging e IteraÃ§Ã£o

1.  **ConfiguraÃ§Ã£o do Script Principal de AnÃ¡lise:**
    *   4.1.1. âœ… Garantir que o script (`main.py`) possa carregar os dados, instanciar os mÃ³dulos de anÃ¡lise e executar as anÃ¡lises em sequÃªncia.
    *   4.1.2. âœ… Implementar a lÃ³gica para salvar todos os outputs (plots, tabelas) de forma organizada.
2.  **ExecuÃ§Ã£o com Dados de DemonstraÃ§Ã£o (`demo-data`):**
    *   4.2.1. âœ… Rodar o pipeline completo com os dados de demonstraÃ§Ã£o.
    *   4.2.2. ğŸ”„ Verificar a corretude dos resultados parciais e finais.
3.  **Debugging e Refinamento dos MÃ³dulos:**
    *   4.3.1. ğŸ”„ Corrigir bugs identificados durante a execuÃ§Ã£o.
    *   4.3.2. ğŸ”„ Refinar parÃ¢metros e lÃ³gicas com base nos resultados observados.
4.  **AnÃ¡lise dos Resultados Iniciais e IteraÃ§Ã£o:**
    *   4.4.1. ğŸ”„ Interpretar os primeiros resultados completos.
    *   4.4.2. ğŸ”„ Com base na interpretaÃ§Ã£o, decidir sobre ajustes nos mÃ©todos, parÃ¢metros ou visualizaÃ§Ãµes.
    *   4.4.3. ğŸ”„ Repetir etapas de execuÃ§Ã£o e anÃ¡lise conforme necessÃ¡rio.

## ObservaÃ§Ãµes e Filosofia da AnÃ¡lise Inter-Tenant

- A identificaÃ§Ã£o de tenants que causam contenÃ§Ã£o de recursos ou degradaÃ§Ã£o serÃ¡ feita exclusivamente de forma data-driven, a partir dos resultados das tÃ©cnicas estatÃ­sticas e de causalidade implementadas (correlaÃ§Ã£o, causalidade, influÃªncia cruzada, etc.).
- NÃ£o hÃ¡ prÃ©-julgamento sobre quem Ã© o "tenant barulhento" ou malicioso: a descoberta serÃ¡ imparcial e baseada em evidÃªncias extraÃ­das dos dados.
- A ausÃªncia de determinados tenants em certas fases (baseline, ataque, recuperaÃ§Ã£o) Ã© esperada e deve ser tratada naturalmente pelo pipeline, sem gerar erro ou viÃ©s. Todas as anÃ¡lises devem considerar apenas os tenants presentes em cada contexto/fase.
- O pipeline deve ser robusto para lidar com a presenÃ§a/ausÃªncia de tenants e arquivos de mÃ©tricas em cada fase, e as funÃ§Ãµes de ingestÃ£o devem registrar (logar) essas ausÃªncias para rastreabilidade.

## SugestÃ£o para o Desenvolvimento do Pipeline

- Desenvolva o pipeline de forma incremental, comeÃ§ando pela ingestÃ£o e validaÃ§Ã£o dos dados, garantindo que o DataFrame long seja corretamente consolidado mesmo com ausÃªncias de tenants/fases.
- Implemente funÃ§Ãµes utilitÃ¡rias para:
    - Listar todos os tenants presentes em cada fase/round/experimento.
    - Registrar ausÃªncias de tenants ou mÃ©tricas esperadas (logging).
    - Gerar DataFrames segmentados por fase, tenant, mÃ©trica, etc.
- Priorize a modularidade: separe claramente ingestÃ£o, transformaÃ§Ã£o, anÃ¡lise e visualizaÃ§Ã£o.
- Implemente testes unitÃ¡rios para garantir que a ingestÃ£o lida corretamente com casos de ausÃªncia de dados.
- Considere criar um notebook de exploraÃ§Ã£o inicial para validar a consolidaÃ§Ã£o dos dados e a robustez do pipeline antes de avanÃ§ar para anÃ¡lises mais complexas.

## Estrutura de Dados de Entrada (Alinhada ao Experimento Original)

- Os dados de entrada devem ser organizados conforme exportaÃ§Ã£o do experimento original, seguindo a estrutura de diretÃ³rios encontrada em `demo-data/`.
- Cada experimento pode conter um ou mÃºltiplos rounds (ex: `demo-experiment-1-round/`, `demo-experiment-3-rounds/`).
- Dentro de cada round (`round-1/`, `round-2/`, etc.), existem trÃªs fases sequenciais: `1 - Baseline/`, `2 - Attack/`, `3 - Recovery/`.
- Dentro de cada fase, os subdiretÃ³rios representam os tenants (ex: `tenant-a/`, `tenant-b/`, ...), alÃ©m de possÃ­veis diretÃ³rios auxiliares (ex: `ingress-nginx/`, `active/`, etc.).
- Cada diretÃ³rio de tenant contÃ©m arquivos CSV de mÃ©tricas, cada um com duas colunas: `timestamp,value`.
- O pipeline deve:
    - Navegar recursivamente por todos os experimentos, rounds e fases.
    - Identificar corretamente o experimento, round, fase e tenant para cada arquivo de mÃ©trica.
    - Ignorar diretÃ³rios que nÃ£o seguem o padrÃ£o de tenant (ex: `ingress-nginx/`, `active/`, etc.), conforme critÃ©rios definidos no contexto do projeto.
    - Consolidar todos os dados em um DataFrame long padronizado, adicionando as colunas: `timestamp`, `metric_value`, `metric_name`, `tenant_id`, `experimental_phase`, `round_id`, `experiment_id`.
    - Garantir a consistÃªncia dos tipos e valores categÃ³ricos durante a ingestÃ£o.
- Essa lÃ³gica deve ser implementada no mÃ³dulo central de ingestÃ£o de dados, garantindo flexibilidade para diferentes estruturas de experimentos e rounds.

## Lacunas e Oportunidades de Melhoria (Adicionado em Junho/2025)

ApÃ³s anÃ¡lise da implementaÃ§Ã£o atual e comparaÃ§Ã£o com o plano original, foram identificadas as seguintes lacunas e oportunidades de melhoria:

1. **ImplementaÃ§Ã£o do Transfer Entropy**:
   - âœ… Estrutura base implementada no mÃ³dulo `analysis_causality.py`
   - ğŸ”„ A aplicaÃ§Ã£o do Transfer Entropy estÃ¡ em andamento, conforme evidenciado pelo arquivo `debug_te_attack.out` 
   - âŒ Falta integrar plenamente a biblioteca para cÃ¡lculos de TE (ex: `pyinform`) com documentaÃ§Ã£o adequada
   - âŒ Necessidade de refinamento da visualizaÃ§Ã£o contextual dos grafos de causalidade

2. **Completude dos Testes**:
   - ğŸ”„ Arquivos de teste criados (`test_analysis_causality.py`, `test_analysis_correlation.py`, etc.)
   - âŒ Cobertura de testes insuficiente para garantir robustez do pipeline
   - âŒ Falta testes para casos extremos (ausÃªncia de dados, inconsistÃªncias)

3. **AnÃ¡lises Comparativas entre Fases**:
   - âœ… Pipeline gera visualizaÃ§Ãµes separadas por fase experimental
   - âŒ Falta implementaÃ§Ã£o da lÃ³gica para comparar resultados entre fases
   - âŒ AusÃªncia de visualizaÃ§Ãµes especÃ­ficas para comparaÃ§Ã£o de baseline/ataque/recuperaÃ§Ã£o

4. **DocumentaÃ§Ã£o das Escolhas MetodolÃ³gicas**:
   - ğŸ”„ Estrutura bÃ¡sica de arquivos Markdown criada
   - âŒ Falta registro detalhado de parÃ¢metros estatÃ­sticos utilizados
   - âŒ AusÃªncia de justificativas para escolhas metodolÃ³gicas

5. **RelatÃ³rios e ConsolidaÃ§Ã£o de Insights**:
   - âŒ Falta implementaÃ§Ã£o da metodologia de agregaÃ§Ã£o de insights
   - âŒ AusÃªncia de tabela final comparativa inter-tenant
   - âŒ Necessidade de estruturar relatÃ³rios automatizados

6. **Janelas MÃ³veis**:
   - âŒ Fase avanÃ§ada nÃ£o iniciada
   - âŒ AdaptaÃ§Ã£o para anÃ¡lises temporais dinÃ¢micas

7. **DependÃªncias e IntegraÃ§Ã£o**:
   - âŒ `NetworkX` nÃ£o estÃ¡ no `requirements.txt` mas Ã© usado para visualizaÃ§Ãµes em grafo
   - âŒ Biblioteca para Transfer Entropy nÃ£o especificada no `requirements.txt`

## Prioridades para PrÃ³ximos Passos (Junho/2025)

As seguintes prioridades foram identificadas para concluir o projeto com sucesso:

### Prioridade Alta (Imediata) âœ…
1. **Completar ImplementaÃ§Ã£o do Transfer Entropy** âœ…:
   - âœ… Finalizar integraÃ§Ã£o da biblioteca de TE
   - âœ… Garantir armazenamento adequado dos valores
   - âœ… Completar testes unitÃ¡rios especÃ­ficos para TE

2. **Atualizar `requirements.txt`** âœ…:
   - âœ… Adicionar `networkx` e biblioteca para TE (ex: `pyinform`)
   - âœ… Especificar versÃµes compatÃ­veis

3. **Consolidar Testes UnitÃ¡rios CrÃ­ticos** âœ…:
   - âœ… Focar em testes para ingestÃ£o de dados, causalidade e exportaÃ§Ã£o
   - âœ… Garantir cobertura para casos edge de ausÃªncia de dados

### Prioridade MÃ©dia (PrÃ³ximas 2-3 semanas) âœ…
1. **Implementar ComparaÃ§Ã£o entre Fases Experimentais** âœ…:
   - âœ… Desenvolver lÃ³gica para comparar mÃ©tricas entre baseline/ataque/recovery
   - âœ… Criar visualizaÃ§Ãµes especÃ­ficas para destacar mudanÃ§as

2. **Desenvolver Metodologia de AgregaÃ§Ã£o de Insights** âœ…:
   - âœ… Definir e implementar critÃ©rios para identificaÃ§Ã£o de "tenant barulhento"
   - âœ… Estruturar tabela final comparativa

3. **Documentar Escolhas MetodolÃ³gicas** âœ…:
   - âœ… Registrar parÃ¢metros utilizados (ex: `max_lags`, thresholds)
   - âœ… Justificar escolhas de bibliotecas e mÃ©todos

### Prioridade Baixa (ApÃ³s concluir anteriores) ğŸ”„
1. **AnÃ¡lises com Janelas MÃ³veis** âœ…:
   - âœ… Adaptar mÃ³dulos para anÃ¡lise temporal dinÃ¢mica
   - âœ… Implementar visualizaÃ§Ãµes especÃ­ficas
   - âœ… Testar e validar a execuÃ§Ã£o completa do pipeline com janelas mÃ³veis

2. **Refinamentos EstÃ©ticos e Usabilidade** ğŸ”„:
   - âœ… Melhorar formataÃ§Ã£o de grÃ¡ficos (estilo tableau-colorblind10)
   - ğŸ”„ Adicionar opÃ§Ãµes de personalizaÃ§Ã£o de visualizaÃ§Ãµes
   - âœ… Aprimorar mensagens de log e feedback

3. **DocumentaÃ§Ã£o para UsuÃ¡rios Finais** ğŸ”„:
   - ğŸ”„ Tutorial de uso do pipeline
   - ğŸ”„ Guia de interpretaÃ§Ã£o dos resultados

