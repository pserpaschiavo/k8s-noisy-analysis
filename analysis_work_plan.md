# Plano de Trabalho para AnÃ¡lise de SÃ©ries Temporais Multi-Tenant

O objetivo Ã© investigar a co-variaÃ§Ã£o, relaÃ§Ãµes causais e flutuaÃ§Ãµes temporais das mÃ©tricas entre diferentes tenants e fases experimentais (baseline, ataque, recuperaÃ§Ã£o), utilizando ferramentas estatÃ­sticas bÃ¡sicas, interpretÃ¡veis e confiÃ¡veis.

## Status do Projeto (Atualizado em Junho/2025)

- âœ… **ConcluÃ­do**: Estrutura principal do projeto implementada, ingestÃ£o de dados, segmentaÃ§Ã£o, persistÃªncia, componentes de anÃ¡lise descritiva, correlaÃ§Ã£o e causalidade bÃ¡sicos, agregaÃ§Ã£o de insights, anÃ¡lise multi-round.
- ğŸ”„ **Em andamento**: Refinamento do mÃ³dulo de Causalidade com Transfer Entropy, testes unitÃ¡rios completos, anÃ¡lises com janelas mÃ³veis, documentaÃ§Ã£o detalhada.
- âŒ **Pendente**: RelatÃ³rios comparativos entre fases experimentais, integraÃ§Ã£o completa de todos os componentes, documentaÃ§Ã£o para usuÃ¡rios finais.

## Diretrizes Gerais para o Desenvolvimento do Pipeline

- O DataFrame consolidado em formato "long" deve ser a Ãºnica fonte de verdade para todas as anÃ¡lises. Todas as transformaÃ§Ãµes e segmentaÃ§Ãµes devem partir dele.
- Todas as funÃ§Ãµes de carregamento, transformaÃ§Ã£o e exportaÃ§Ã£o de dados devem ser modulares, testÃ¡veis e possuir logging detalhado de etapas e erros.
- O pipeline deve ser desenvolvido de forma incremental: comece com um subconjunto pequeno de dados/mÃ©tricas, garanta testes e outputs corretos, depois expanda.
- O cÃ³digo deve ser escrito em inglÃªs (nomes, docstrings, comentÃ¡rios). DocumentaÃ§Ã£o geral pode ser em portuguÃªs.
- Toda lÃ³gica de ingestÃ£o, validaÃ§Ã£o e transformaÃ§Ã£o de dados deve ser separada da lÃ³gica de anÃ¡lise e visualizaÃ§Ã£o.
- Recomenda-se a criaÃ§Ã£o de um mÃ³dulo central de ingestÃ£o de dados (ex: `data_ingestion.py`) responsÃ¡vel por:
    - Navegar na estrutura de diretÃ³rios.
    - Carregar arquivos CSV.
    - Validar e padronizar colunas e tipos.
    - Gerar logs de inconsistÃªncias e erros.
    - Retornar o DataFrame "long" padronizado.
- Implementar testes unitÃ¡rios para cada etapa crÃ­tica (carregamento, transformaÃ§Ã£o, anÃ¡lise, visualizaÃ§Ã£o).
- Utilizar um arquivo de configuraÃ§Ã£o central (ex: `config.yaml` ou `.py`) para caminhos, mÃ©tricas, parÃ¢metros de anÃ¡lise e exportaÃ§Ã£o.
- Outputs (plots, tabelas, arquivos) devem ser versionados e organizados por experimento, round e fase.
- Documentar todas as decisÃµes metodolÃ³gicas e parÃ¢metros relevantes em arquivos Markdown.

## Diretrizes para EstruturaÃ§Ã£o e PersistÃªncia de DataFrames

- O DataFrame consolidado em formato "long" Ã© o padrÃ£o e fonte Ãºnica de verdade para todo o pipeline. Todas as operaÃ§Ãµes de ingestÃ£o, validaÃ§Ã£o, limpeza e transformaÃ§Ã£o devem resultar nesse formato.
- Subdatasets no formato "wide" podem ser gerados sob demanda, a partir do DataFrame long, para anÃ¡lises especÃ­ficas (correlaÃ§Ã£o, causalidade, visualizaÃ§Ãµes comparativas), mas nunca devem substituir o long como fonte principal.
- Recomenda-se fortemente a persistÃªncia dos DataFrames processados (long e, se necessÃ¡rio, wide) em formatos eficientes e portÃ¡veis (Parquet preferencialmente, ou CSV/Feather), organizados por experimento, round e fase. Isso facilita reuso, integraÃ§Ã£o com notebooks (Jupyter) e compartilhamento com outros times ou ferramentas.
- O pipeline deve prover funÃ§Ãµes utilitÃ¡rias para salvar e carregar datasets processados, garantindo reprodutibilidade e agilidade no desenvolvimento.

## Fase 1: PreparaÃ§Ã£o e EstratÃ©gia de Dados

1.  **DefiniÃ§Ã£o da Estrutura dos Dados de Entrada:**
    *   1.1. âœ… Confirmar e documentar as colunas essenciais no DataFrame de entrada (ex: `timestamp`, `tenant_id`, `metric_name`, `metric_value`, `experimental_phase`). 
    *   1.2. âœ… Validar os tipos de dados e a consistÃªncia dos identificadores (tenants, mÃ©tricas, fases). 

2.  **EstratÃ©gia de Carregamento, Formatos de DataFrame e SegmentaÃ§Ã£o de Dados:**
    *   2.1. âœ… Implementar ou refinar a lÃ³gica para carregar os dados brutos e consolidÃ¡-los em um DataFrame principal em **formato "long"**. 
        *   Este DataFrame conterÃ¡ colunas como: `timestamp`, `metric_value`, `metric_name`, `tenant_id`, `experimental_phase`, `round_id`, `experiment_id`. 
    *   2.2. âœ… Desenvolver funÃ§Ãµes para segmentar o DataFrame principal (formato "long") por: 
        *   Fase experimental (Baseline, Ataque, RecuperaÃ§Ã£o).
        *   Tenant individual.
        *   MÃ©trica especÃ­fica.
        *   CombinaÃ§Ãµes destes (ex: dados de uma mÃ©trica especÃ­fica para um tenant em uma fase).
    *   2.3. âœ… **EstratÃ©gia para DataFrames em formato \"wide\":**
        *   SerÃ£o gerados em memÃ³ria, dinamicamente, a partir do DataFrame \"long\", conforme a necessidade de cada mÃ³dulo de anÃ¡lise (ex: para cÃ¡lculo de correlaÃ§Ãµes ou causalidade entre mÃºltiplas sÃ©ries temporais).
        *   Estes DataFrames \\\"wide\\\" tambÃ©m serÃ£o considerados para exportaÃ§Ã£o, permitindo anÃ¡lises futuras ou o uso por parsers especÃ­ficos.
        *   âœ… **Implementar `get_wide_format_for_analysis` para transformar dados longos em largos para uma mÃ©trica, fase e round especÃ­ficos. 
    *   2.4. âœ… **ExportaÃ§Ã£o dos DataFrames Processados:**
        *   Implementar a funcionalidade para exportar o DataFrame consolidado em formato "long" (apÃ³s carregamento e prÃ©-processamento inicial) para um formato de arquivo eficiente (ex: Parquet). 
            *   Objetivo: otimizar o desempenho em anÃ¡lises subsequentes e facilitar a interoperabilidade com outras ferramentas ou processos.
        *   Implementar a funcionalidade para exportar os DataFrames em formato "wide" gerados para formatos de arquivo eficientes (ex: Parquet ou CSV, a ser definido). 
            *   Objetivo: permitir anÃ¡lises futuras ou o uso por parsers especÃ­ficos que possam necessitar deste formato.

3.  **ConfiguraÃ§Ã£o e AplicaÃ§Ã£o de OtimizaÃ§Ã£o de Dados:**
    *   3.1. âœ… Revisar e ajustar otimizaÃ§Ã£o para anÃ¡lise descritiva. 
    *   3.2. âœ… Revisar e ajustar otimizaÃ§Ã£o para anÃ¡lise de correlaÃ§Ã£o. 
    *   3.3. âœ… Revisar e ajustar otimizaÃ§Ã£o para anÃ¡lise de causalidade. 
4.  **DefiniÃ§Ã£o do Processo de SeleÃ§Ã£o de VariÃ¡veis e Pares para AnÃ¡lise:**
    *   4.1. âœ… Estabelecer critÃ©rios para selecionar as mÃ©tricas de interesse (ex: CPU, memÃ³ria, latÃªncia). 
    *   4.2. âœ… Definir como os pares de tenants serÃ£o selecionados para anÃ¡lises comparativas (inter-tenant). 

## Fase 2: ImplementaÃ§Ã£o Detalhada dos MÃ³dulos de AnÃ¡lise

Cada mÃ³dulo seguirÃ¡ a arquitetura `BaseModule`, `BaseAnalyzer`, `BaseVisualizer`.

**2.1. MÃ³dulo de AnÃ¡lise Descritiva (em `src/analysis_descriptive.py`)**
    *   2.1.1. **Estrutura do MÃ³dulo:**
        *   âœ… Implementar funÃ§Ãµes de anÃ¡lise descritiva.
        *   âœ… Implementar funÃ§Ãµes de visualizaÃ§Ã£o.
    *   2.1.2. **CÃ¡lculos de EstatÃ­sticas Descritivas:** 
        *   âœ… Implementar funÃ§Ã£o para calcular estatÃ­sticas descritivas (mÃ©dia, desvio padrÃ£o, etc.) por sÃ©rie temporal (tenant, mÃ©trica, fase).
    *   2.1.3. **VisualizaÃ§Ãµes:** 
        *   âœ… Implementar funÃ§Ã£o para gerar plots de sÃ©ries temporais individuais. 
        *   âœ… Implementar funÃ§Ã£o para gerar plots de autocorrelaÃ§Ã£o (ACF) para cada mÃ©trica/tenant. 
    *   2.1.4. **Tabelas de Resultados:** 
        *   âœ… Implementar funÃ§Ã£o para gerar tabela resumo das estatÃ­sticas descritivas.
    *   2.1.5. **Testes UnitÃ¡rios:** 
        *   ğŸ”„ Implementados arquivos bÃ¡sicos de teste `test_analysis_descriptive.py`.
        *   ğŸ”„ Expandir cobertura de testes para casos edge.

**2.2. MÃ³dulo de AnÃ¡lise de CorrelaÃ§Ã£o e CovariÃ¢ncia (em `src/analysis_correlation.py`)**
    *   2.2.1. **Estrutura do MÃ³dulo:**
        *   âœ… Implementar funÃ§Ãµes de anÃ¡lise de correlaÃ§Ã£o.
        *   âœ… Implementar funÃ§Ãµes de visualizaÃ§Ã£o para correlaÃ§Ã£o.
    *   2.2.2. **CÃ¡lculos de CorrelaÃ§Ã£o (por fase experimental):**
        *   âœ… Implementar funÃ§Ã£o para calcular matrizes de correlaÃ§Ã£o (Pearson, Kendall, Spearman) entre mÃ©tricas de tenants distintos.
        *   âœ… Implementar funÃ§Ã£o para calcular matriz de covariÃ¢ncia (com dados padronizados).
        *   âœ… Implementar funÃ§Ã£o para calcular CorrelaÃ§Ã£o Cruzada com Defasagem (CCF) entre pares de sÃ©ries.
    *   2.2.3. **VisualizaÃ§Ãµes (por fase experimental):**
        *   âœ… Implementar funÃ§Ã£o para gerar heatmaps das matrizes de correlaÃ§Ã£o.
        *   âœ… Implementar funÃ§Ã£o para gerar heatmap da matriz de covariÃ¢ncia padronizada.
        *   âœ… Implementar funÃ§Ã£o para gerar grÃ¡ficos de CCF.
        *   âœ… Implementar funÃ§Ã£o para gerar lag plots.
    *   2.2.4. **Tabelas de Resultados:**
        *   âœ… Implementar funÃ§Ã£o para gerar tabelas das matrizes de correlaÃ§Ã£o e covariÃ¢ncia.
    *   2.2.5. **Testes UnitÃ¡rios:**
        *   ğŸ”„ Implementados arquivos bÃ¡sicos de teste `test_analysis_correlation.py`.
        *   ğŸ”„ Expandir cobertura de testes para casos edge.

**2.3. MÃ³dulo de AnÃ¡lise de Causalidade (em `src/analysis_causality.py`)**
    *   2.3.1. **Estrutura do MÃ³dulo (ReconstruÃ§Ã£o/CriaÃ§Ã£o):**
        *   âœ… Implementar funÃ§Ãµes para anÃ¡lise de causalidade abrangendo Granger e Transfer Entropy.
        *   âœ… Implementar funÃ§Ãµes de visualizaÃ§Ã£o para causalidade.
        *   âœ… IntegraÃ§Ã£o com outras funcionalidades do pipeline.
    *   2.3.2. **ImplementaÃ§Ã£o da AnÃ¡lise de Causalidade de Granger:**
        *   âœ… Implementar funÃ§Ã£o para aplicar testes de Causalidade de Granger para pares de sÃ©ries temporais.
        *   âœ… Integrar lÃ³gica para determinar `max_lags` (pode usar CCF do mÃ³dulo de correlaÃ§Ã£o ou critÃ©rios como AIC/BIC).
        *   âœ… Assegurar a coleta e o armazenamento adequado dos p-values e estatÃ­sticas do teste.
    *   2.3.3. **ImplementaÃ§Ã£o da AnÃ¡lise de Transfer Entropy:**
        *   âœ… Selecionar e integrar a biblioteca Python para Transfer Entropy (ex: `pyinform`, ou outra). Adicionar ao `requirements.txt`.
        *   âœ… Implementar funÃ§Ã£o para calcular Transfer Entropy para pares de sÃ©ries temporais.
        *   âœ… Assegurar a coleta e o armazenamento adequado dos valores de TE.
    *   2.3.4. **ImplementaÃ§Ã£o das VisualizaÃ§Ãµes:**
        *   âœ… Implementar funÃ§Ã£o para gerar plots dos resultados da Causalidade de Granger (ex: heatmap de p-values).
        *   âœ… Implementar funÃ§Ã£o para gerar plots dos resultados da Transfer Entropy (ex: heatmap de valores TE).
        *   âœ… Implementar funÃ§Ã£o para gerar visualizaÃ§Ã£o em grafo (usando NetworkX) para ilustrar relaÃ§Ãµes de influÃªncia.
        *   âœ… Garantir que a legenda dos grafos multi-mÃ©trica seja contextual e automÃ¡tica: priorizar p-valor (Granger real) se disponÃ­vel, senÃ£o TE, para mÃ¡xima clareza interpretativa.
        *   âœ… Outputs organizados e reprodutÃ­veis, com legendas e tÃ­tulos informativos.
    *   2.3.5. **GeraÃ§Ã£o de Tabelas de Resultados:**
        *   âœ… Implementar funÃ§Ã£o para criar tabela consolidada de scores de causalidade (p-values Granger).
        *   âœ… Implementar funÃ§Ã£o para criar uma matriz de influÃªncia cruzada resumida com scores de TE.
    *   2.3.6. **Testes UnitÃ¡rios e IntegraÃ§Ã£o:**
        *   ğŸ”„ Implementados arquivos bÃ¡sicos de teste `test_analysis_causality.py`.
        *   âŒ Falta testar funÃ§Ãµes de cÃ¡lculo de TE com dados sintÃ©ticos ou subconjuntos.
        *   ğŸ”„ Testar geraÃ§Ã£o de plots e tabelas para TE.

## Fase 3: ConsolidaÃ§Ã£o, InterpretaÃ§Ã£o e GeraÃ§Ã£o de RelatÃ³rios

1.  **Desenvolvimento da Metodologia de AgregaÃ§Ã£o de Insights:**
    *   3.1.1. âœ… Definir como os resultados das anÃ¡lises descritiva, de correlaÃ§Ã£o/covariÃ¢ncia e de causalidade serÃ£o combinados para formar uma narrativa coesa.
    *   3.1.2. âœ… Estabelecer critÃ©rios para identificar o "tenant barulhento" e quantificar sua influÃªncia.
2.  **ImplementaÃ§Ã£o da GeraÃ§Ã£o da Tabela Final de Comparativo Inter-Tenant:**
    *   3.2.1. âœ… Projetar a estrutura da tabela final, incluindo as mÃ©tricas de influÃªncia e ranking.
    *   3.2.2. âœ… Implementar a lÃ³gica para popular esta tabela, utilizando os resultados armazenados pelos Analyzers.
3.  **DocumentaÃ§Ã£o Detalhada das Escolhas MetodolÃ³gicas:**
    *   3.3.1. ğŸ”„ Registrar todos os parÃ¢metros utilizados (ex: `max_lags` para Granger, limiares de significÃ¢ncia, janelas de CCF).
    *   3.3.2. âŒ Justificar as escolhas de bibliotecas e mÃ©todos.
4.  **AnÃ¡lise Comparativa dos Resultados Entre Fases Experimentais:**
    *   3.4.1. âŒ Implementar lÃ³gica para comparar os resultados (correlaÃ§Ãµes, causalidade, etc.) entre as fases de baseline, ataque e recuperaÃ§Ã£o.
    *   3.4.2. âŒ Preparar visualizaÃ§Ãµes que destaquem essas mudanÃ§as.
5.  **AvaliaÃ§Ã£o e ImplementaÃ§Ã£o (Opcional) de AnÃ¡lises com Janelas MÃ³veis:**
    *   3.5.1. âŒ Se decidido, adaptar os mÃ³dulos de CorrelaÃ§Ã£o e Causalidade para operar com janelas mÃ³veis.
    *   3.5.2. âŒ Definir o tamanho da janela e o passo (step).
    *   3.5.3. âŒ Implementar visualizaÃ§Ãµes para os resultados de janelas mÃ³veis (ex: evoluÃ§Ã£o da correlaÃ§Ã£o/causalidade ao longo do tempo).
    *   3.5.4. âŒ Realizar testes especÃ­ficos para as funcionalidades de janelas mÃ³veis.
6.  **AnÃ¡lise Consolidada para Experimentos Multi-Round:**
    *   3.6.1. ğŸ”„ Implementar metodologia de anÃ¡lise de consistÃªncia entre rounds para identificar padrÃµes persistentes vs. pontuais.
    *   3.6.2. ğŸ”„ Desenvolver anÃ¡lise de robustez de causalidade para distinguir relaÃ§Ãµes causais robustas de correlaÃ§Ãµes espÃºrias.
    *   3.6.3. ğŸ”„ Criar sistema de anÃ¡lise de divergÃªncia de comportamento para identificar rounds anÃ´malos.
    *   3.6.4. ğŸ”„ Implementar agregaÃ§Ã£o de consenso para produzir veredictos consolidados sobre o comportamento do sistema.
    *   3.6.5. ğŸ”„ Desenvolver visualizaÃ§Ãµes de consistÃªncia entre rounds (grÃ¡ficos com intervalos de confianÃ§a, heatmaps, dendrogramas).

## Fase 4: ExecuÃ§Ã£o, Debugging e IteraÃ§Ã£o

1.  **ConfiguraÃ§Ã£o do Script Principal de AnÃ¡lise:**
    *   4.1.1. âœ… Garantir que o script (`main.py`) possa carregar os dados, instanciar os mÃ³dulos de anÃ¡lise e executar as anÃ¡lises em sequÃªncia.
    *   4.1.2. âœ… Implementar a lÃ³gica para salvar todos os outputs (plots, tabelas) de forma organizada.
2.  **ExecuÃ§Ã£o com Dados de DemonstraÃ§Ã£o (`demo-data`):**
    *   4.2.1. âœ… Rodar o pipeline completo com os dados de demonstraÃ§Ã£o.
    *   4.2.2. ğŸ”„ Verificar a corretude dos resultados parciais e finais.
3.  **Debugging e Refinamento dos MÃ³dulos:**
    *   4.3.1. ğŸ”„ Corrigir bugs identificados durante a execuÃ§Ã£o.
    *   4.3.2. ğŸ”„ Refinar parÃ¢metros e lÃ³gicas com base nos resultados observados.
4.  **AnÃ¡lise dos Resultados Iniciais e IteraÃ§Ã£o:**
    *   4.4.1. ğŸ”„ Interpretar os primeiros resultados completos.
    *   4.4.2. ğŸ”„ Com base na interpretaÃ§Ã£o, decidir sobre ajustes nos mÃ©todos, parÃ¢metros ou visualizaÃ§Ãµes.
    *   4.4.3. ğŸ”„ Repetir etapas de execuÃ§Ã£o e anÃ¡lise conforme necessÃ¡rio.

## ObservaÃ§Ãµes e Filosofia da AnÃ¡lise Inter-Tenant

- A identificaÃ§Ã£o de tenants que causam contenÃ§Ã£o de recursos ou degradaÃ§Ã£o serÃ¡ feita exclusivamente de forma data-driven, a partir dos resultados das tÃ©cnicas estatÃ­sticas e de causalidade implementadas (correlaÃ§Ã£o, causalidade, influÃªncia cruzada, etc.).
- NÃ£o hÃ¡ prÃ©-julgamento sobre quem Ã© o "tenant barulhento" ou malicioso: a descoberta serÃ¡ imparcial e baseada em evidÃªncias extraÃ­das dos dados.
- A ausÃªncia de determinados tenants em certas fases (baseline, ataque, recuperaÃ§Ã£o) Ã© esperada e deve ser tratada naturalmente pelo pipeline, sem gerar erro ou viÃ©s. Todas as anÃ¡lises devem considerar apenas os tenants presentes em cada contexto/fase.
- O pipeline deve ser robusto para lidar com a presenÃ§a/ausÃªncia de tenants e arquivos de mÃ©tricas em cada fase, e as funÃ§Ãµes de ingestÃ£o devem registrar (logar) essas ausÃªncias para rastreabilidade.

## SugestÃ£o para o Desenvolvimento do Pipeline

- Desenvolva o pipeline de forma incremental, comeÃ§ando pela ingestÃ£o e validaÃ§Ã£o dos dados, garantindo que o DataFrame long seja corretamente consolidado mesmo com ausÃªncias de tenants/fases.
- Implemente funÃ§Ãµes utilitÃ¡rias para:
    - Listar todos os tenants presentes em cada fase/round/experimento.
    - Registrar ausÃªncias de tenants ou mÃ©tricas esperadas (logging).
    - Gerar DataFrames segmentados por fase, tenant, mÃ©trica, etc.
- Priorize a modularidade: separe claramente ingestÃ£o, transformaÃ§Ã£o, anÃ¡lise e visualizaÃ§Ã£o.
- Implemente testes unitÃ¡rios para garantir que a ingestÃ£o lida corretamente com casos de ausÃªncia de dados.
- Considere criar um notebook de exploraÃ§Ã£o inicial para validar a consolidaÃ§Ã£o dos dados e a robustez do pipeline antes de avanÃ§ar para anÃ¡lises mais complexas.

## Estrutura de Dados de Entrada (Alinhada ao Experimento Original)

- Os dados de entrada devem ser organizados conforme exportaÃ§Ã£o do experimento original, seguindo a estrutura de diretÃ³rios encontrada em `demo-data/`.
- Cada experimento pode conter um ou mÃºltiplos rounds (ex: `demo-experiment-1-round/`, `demo-experiment-3-rounds/`).
- Dentro de cada round (`round-1/`, `round-2/`, etc.), existem trÃªs fases sequenciais: `1 - Baseline/`, `2 - Attack/`, `3 - Recovery/`.
- Dentro de cada fase, os subdiretÃ³rios representam os tenants (ex: `tenant-a/`, `tenant-b/`, ...), alÃ©m de possÃ­veis diretÃ³rios auxiliares (ex: `ingress-nginx/`, `active/`, etc.).
- Cada diretÃ³rio de tenant contÃ©m arquivos CSV de mÃ©tricas, cada um com duas colunas: `timestamp,value`.
- O pipeline deve:
    - Navegar recursivamente por todos os experimentos, rounds e fases.
    - Identificar corretamente o experimento, round, fase e tenant para cada arquivo de mÃ©trica.
    - Ignorar diretÃ³rios que nÃ£o seguem o padrÃ£o de tenant (ex: `ingress-nginx/`, `active/`, etc.), conforme critÃ©rios definidos no contexto do projeto.
    - Consolidar todos os dados em um DataFrame long padronizado, adicionando as colunas: `timestamp`, `metric_value`, `metric_name`, `tenant_id`, `experimental_phase`, `round_id`, `experiment_id`.
    - Garantir a consistÃªncia dos tipos e valores categÃ³ricos durante a ingestÃ£o.
- Essa lÃ³gica deve ser implementada no mÃ³dulo central de ingestÃ£o de dados, garantindo flexibilidade para diferentes estruturas de experimentos e rounds.

## Lacunas e Oportunidades de Melhoria (Adicionado em Junho/2025)

ApÃ³s anÃ¡lise da implementaÃ§Ã£o atual e comparaÃ§Ã£o com o plano original, foram identificadas as seguintes lacunas e oportunidades de melhoria:

1. **ImplementaÃ§Ã£o do Transfer Entropy**:
   - âœ… Estrutura base implementada no mÃ³dulo `analysis_causality.py`
   - âŒ Necessidade de refinamento da visualizaÃ§Ã£o contextual dos grafos de causalidade

2. **Completude dos Testes**:
   - ğŸ”„ Arquivos de teste criados (`test_analysis_causality.py`, `test_analysis_correlation.py`, etc.)
   - âŒ Falta testes para casos extremos (ausÃªncia de dados, inconsistÃªncias)

3. **AnÃ¡lises Comparativas entre Fases**:
   - âœ… Pipeline gera visualizaÃ§Ãµes separadas por fase experimental
   - âŒ AusÃªncia de visualizaÃ§Ãµes especÃ­ficas para comparaÃ§Ã£o de baseline/ataque/recuperaÃ§Ã£o

4. **DocumentaÃ§Ã£o das Escolhas MetodolÃ³gicas**:
   - ğŸ”„ Estrutura bÃ¡sica de arquivos Markdown criada
   - âŒ AusÃªncia de justificativas para escolhas metodolÃ³gicas

5. **RelatÃ³rios e ConsolidaÃ§Ã£o de Insights**:
   - âœ… ImplementaÃ§Ã£o da metodologia de agregaÃ§Ã£o de insights
   - âœ… EstruturaÃ§Ã£o de relatÃ³rios automatizados

6. **Janelas MÃ³veis**:
   - âœ… MÃ³dulo implementado em `analysis_sliding_window.py` com funcionalidades completas
   - âœ… DisponÃ­vel via pipeline dedicado (`pipeline_with_sliding_window.py`)
   - âŒ NÃ£o executado no Ãºltimo teste do pipeline, visualizaÃ§Ãµes ausentes

7. **AnÃ¡lise Consolidada para Experimentos Multi-Round**:
   - âœ… ImplementaÃ§Ã£o de metodologias especÃ­ficas para anÃ¡lise entre rounds
   - âœ… AvaliaÃ§Ã£o de consistÃªncia entre diferentes execuÃ§Ãµes do experimento
   - âœ… MÃ©tricas de robustez para relaÃ§Ãµes causais identificadas
   - âŒ VisualizaÃ§Ãµes implementadas mas nÃ£o geradas na Ãºltima execuÃ§Ã£o

8. **DependÃªncias e IntegraÃ§Ã£o**:
   - âœ… `NetworkX` adicionado ao `requirements.txt` para visualizaÃ§Ãµes em grafo
   - âœ… Biblioteca `pyinform` para Transfer Entropy especificada no `requirements.txt`
   
9. **VisualizaÃ§Ãµes Ausentes/Incompletas**:
   - âŒ Plots de correlaÃ§Ã£o nÃ£o gerados (apenas covariÃ¢ncia estÃ¡ disponÃ­vel)
   - âŒ VisualizaÃ§Ãµes de sÃ©ries temporais combinadas de todas as fases nÃ£o geradas
   - âŒ Plots de detecÃ§Ã£o de anomalias implementados mas nÃ£o executados
   - âŒ VisualizaÃ§Ãµes de janelas deslizantes nÃ£o geradas

10. **Arquitetura do Pipeline**:
    - âŒ MÃºltiplas implementaÃ§Ãµes de pipeline (`pipeline.py`, `pipeline_new.py`, `pipeline_with_sliding_window.py`)
    - âŒ Falta de sistema unificado para configuraÃ§Ã£o e execuÃ§Ã£o
    - âŒ AusÃªncia de mecanismos de cache para evitar recÃ¡lculos desnecessÃ¡rios

## Prioridades para PrÃ³ximos Passos (Junho/2025 - Atualizado)

As seguintes prioridades foram identificadas para concluir o projeto com sucesso:

### Prioridade Alta (Imediata)
1. **Gerar VisualizaÃ§Ãµes Faltantes** âŒ:
   - âŒ Executar pipeline com janelas deslizantes para gerar anÃ¡lises de correlaÃ§Ã£o ao longo do tempo
   - âŒ Corrigir geraÃ§Ã£o de plots de correlaÃ§Ã£o (atualmente apenas covariÃ¢ncia Ã© gerada)
   - âŒ Verificar e corrigir execuÃ§Ã£o de plots de sÃ©ries temporais combinadas de todas as fases
   - âŒ Integrar detecÃ§Ã£o de anomalias ao fluxo principal do pipeline

2. **Executar AnÃ¡lise Multi-Round Completa** âŒ:
   - âŒ Verificar e corrigir integraÃ§Ã£o do mÃ³dulo `analysis_multi_round.py`
   - âŒ Garantir geraÃ§Ã£o de visualizaÃ§Ãµes de consistÃªncia e robustez entre rounds
   - âŒ Documentar resultados e insights gerados por esta anÃ¡lise

3. **CorreÃ§Ãµes CrÃ­ticas no Pipeline** âœ…âŒ:
   - âœ… Desenvolver script utilitÃ¡rio para verificaÃ§Ã£o da geraÃ§Ã£o de todas as visualizaÃ§Ãµes esperadas (`src/run_unified_pipeline.py`)
   - âŒ Corrigir chamadas para funÃ§Ãµes de visualizaÃ§Ã£o ausentes no fluxo principal
   - âŒ Garantir que todas as dependÃªncias estÃ£o sendo instaladas corretamente

### Prioridade MÃ©dia (Semanas 2-3 de Junho/2025)
1. **ConsolidaÃ§Ã£o da Arquitetura do Pipeline** âŒ:
   - âŒ Unificar os mÃºltiplos arquivos de pipeline em uma implementaÃ§Ã£o modular baseada em plugins
   - âŒ Implementar sistema de configuraÃ§Ã£o centralizado com validaÃ§Ã£o
   - âŒ Desenvolver CLI unificada para controle granular da execuÃ§Ã£o

2. **DocumentaÃ§Ã£o TÃ©cnica** âŒ:
   - âŒ Documentar detalhadamente todas as visualizaÃ§Ãµes geradas pelo sistema
   - âŒ Criar guia tÃ©cnico sobre como adicionar novos tipos de anÃ¡lise ao pipeline
   - âŒ Documentar configuraÃ§Ãµes e parÃ¢metros disponÃ­veis

3. **RefatoraÃ§Ã£o de CÃ³digo** âŒ:
   - âŒ Padronizar interface dos diferentes mÃ³dulos de anÃ¡lise
   - âŒ Melhorar sistema de logging para facilitar depuraÃ§Ã£o
   - âŒ Remover cÃ³digo duplicado entre as diferentes implementaÃ§Ãµes do pipeline

### Prioridade Baixa (Julho-Agosto/2025)
1. **OtimizaÃ§Ãµes de Desempenho** âŒ:
   - âŒ Implementar sistema de cache para resultados intermediÃ¡rios
   - âŒ Adicionar suporte para paralelizaÃ§Ã£o em estÃ¡gios computacionalmente intensivos
   - âŒ Otimizar uso de memÃ³ria para conjuntos de dados grandes

2. **Extensibilidade e Interface** âŒ:
   - âŒ Desenvolver sistema de plugins para facilitar adiÃ§Ã£o de novas anÃ¡lises
   - âŒ Considerar implementaÃ§Ã£o de interface web simples para visualizaÃ§Ã£o de resultados
   - âŒ Criar mecanismos para exportaÃ§Ã£o de resultados em diferentes formatos

3. **Testes e CI/CD** âŒ:
   - âŒ Implementar testes unitÃ¡rios e de integraÃ§Ã£o
   - âŒ Configurar pipeline de CI/CD para validaÃ§Ã£o automÃ¡tica
   - âŒ Desenvolver casos de teste com diferentes configuraÃ§Ãµes de experimentos
   - âœ… Estruturar tabela final comparativa
   - âœ… Implementar visualizaÃ§Ãµes comparativas inter-tenant

3. **Documentar Escolhas MetodolÃ³gicas** âœ…:
   - âœ… Registrar parÃ¢metros utilizados (ex: `max_lags`, thresholds)
   - âœ… Justificar escolhas de bibliotecas e mÃ©todos

### Prioridade Baixa (ApÃ³s concluir anteriores) ğŸ”„
1. **AnÃ¡lises com Janelas MÃ³veis** âœ…:
   - âœ… Adaptar mÃ³dulos para anÃ¡lise temporal dinÃ¢mica
   - âœ… Testar e validar a execuÃ§Ã£o completa do pipeline com janelas mÃ³veis

2. **AnÃ¡lise Consolidada para Experimentos Multi-Round** ğŸ”„:
   - ğŸ”„ Implementar anÃ¡lise de consistÃªncia entre rounds
   - ğŸ”„ Desenvolver metodologia de robustez para causalidade
   - ğŸ”„ Criar sistema de agregaÃ§Ã£o de consenso entre rounds
   - ğŸ”„ Implementar visualizaÃ§Ãµes especÃ­ficas para comparaÃ§Ã£o entre rounds

3. **Refinamentos EstÃ©ticos e Usabilidade** ğŸ”„:
   - âœ… Melhorar formataÃ§Ã£o de grÃ¡ficos (estilo tableau-colorblind10)
   - âœ… Aprimorar mensagens de log e feedback

4. **DocumentaÃ§Ã£o para UsuÃ¡rios Finais** ğŸ”„:
   - ğŸ”„ Tutorial de uso do pipeline
   - ğŸ”„ Guia de interpretaÃ§Ã£o dos resultados

## OtimizaÃ§Ãµes do Pipeline e CorreÃ§Ãµes de VisualizaÃ§Ãµes (Adicionado em Junho/2025)

Com base na anÃ¡lise do estado atual da implementaÃ§Ã£o e no levantamento de plots nÃ£o gerados ou incompletos, identificamos as seguintes oportunidades de melhoria organizadas em fases progressivas:

### Fase 1: CorreÃ§Ã£o e IntegraÃ§Ã£o de VisualizaÃ§Ãµes Existentes (Prioridade Alta)

1. **ExecuÃ§Ã£o de VisualizaÃ§Ãµes Implementadas mas NÃ£o Geradas:**
   - âŒ Executar o pipeline com janelas deslizantes para gerar plots de correlaÃ§Ã£o ao longo do tempo
   - âŒ Garantir a geraÃ§Ã£o de plots de correlaÃ§Ã£o ausentes (apenas correlaÃ§Ã£o, jÃ¡ que covariÃ¢ncia estÃ¡ sendo gerada)
   - âŒ Executar mÃ³dulo de anÃ¡lise multi-round para gerar visualizaÃ§Ãµes de consistÃªncia entre rounds
   - âŒ Verificar ambiente de execuÃ§Ã£o para garantir que as dependÃªncias para Transfer Entropy estÃ£o disponÃ­veis

2. **CorreÃ§Ã£o de Problemas na GeraÃ§Ã£o de VisualizaÃ§Ãµes:**
   - âŒ Investigar e corrigir problemas na geraÃ§Ã£o de plots de sÃ©ries temporais combinadas de todas as fases
   - âŒ Adicionar chamadas para funÃ§Ãµes de detecÃ§Ã£o e visualizaÃ§Ã£o de anomalias no pipeline principal

### Fase 2: UnificaÃ§Ã£o e ModularizaÃ§Ã£o do Pipeline (Prioridade MÃ©dia)

1. **ConsolidaÃ§Ã£o dos MÃºltiplos Arquivos de Pipeline:**
   - âŒ Criar um framework de pipeline unificado que substitua os mÃºltiplos arquivos atuais (`pipeline.py`, `pipeline_new.py`, `pipeline_with_sliding_window.py`)
   - âŒ Implementar sistema de estÃ¡gios de pipeline como plugins carregÃ¡veis baseados em configuraÃ§Ã£o
   - âŒ Garantir compatibilidade com o pipeline existente durante a transiÃ§Ã£o

2. **CentralizaÃ§Ã£o de ConfiguraÃ§Ãµes:**
   - âŒ Criar um sistema de configuraÃ§Ã£o central baseado em YAML mais abrangente
   - âŒ Parametrizar todos os limiares, janelas e opÃ§Ãµes atualmente hardcoded no cÃ³digo
   - âŒ Adicionar documentaÃ§Ã£o inline para todos os parÃ¢metros configurÃ¡veis

3. **Interface de Linha de Comando (CLI) Unificada:**
   - âŒ Desenvolver CLI integrada para controlar todos os aspectos da execuÃ§Ã£o do pipeline
   - âŒ Implementar opÃ§Ãµes de execuÃ§Ã£o especÃ­ficas (apenas descritiva, apenas correlaÃ§Ã£o, etc.)
   - âŒ Adicionar suporte para execuÃ§Ã£o de estÃ¡gios especÃ­ficos ou combinaÃ§Ãµes de estÃ¡gios

### Fase 3: OtimizaÃ§Ãµes de Desempenho e Usabilidade (Prioridade Baixa)

1. **Sistema de Cache Inteligente:**
   - âŒ Implementar sistema de cache baseado em hash para evitar recÃ¡lculos desnecessÃ¡rios
   - âŒ Adicionar invalidaÃ§Ã£o seletiva de cache para recomputar apenas o necessÃ¡rio
   - âŒ Persistir resultados intermediÃ¡rios em formatos eficientes

2. **ParalelizaÃ§Ã£o de AnÃ¡lises Independentes:**
   - âŒ Identificar operaÃ§Ãµes paralelizÃ¡veis (anÃ¡lises entre diferentes mÃ©tricas, rounds, etc.)
   - âŒ Implementar paralelizaÃ§Ã£o com multiprocessing ou threading onde aplicÃ¡vel
   - âŒ Adicionar controle de concorrÃªncia e dependÃªncias entre tarefas do pipeline

3. **Interface Web Simples (Opcional):**
   - âŒ Criar interface web bÃ¡sica para visualizar resultados e configurar execuÃ§Ãµes
   - âŒ Implementar dashboard para monitoramento de execuÃ§Ãµes longas
   - âŒ Adicionar capacidade de salvar e compartilhar configuraÃ§Ãµes

### Plano de ImplementaÃ§Ã£o Progressivo

Para garantir um progresso contÃ­nuo e tangÃ­vel, recomendamos a seguinte abordagem:

1. **Sprint 1 (1 semana):**
   - Focar na Fase 1 para garantir que todas as visualizaÃ§Ãµes implementadas estÃ£o funcionando corretamente
   - Executar `python -m src.pipeline_with_sliding_window` para gerar os plots de janelas deslizantes
   - Corrigir problemas imediatos de geraÃ§Ã£o de plots
   
2. **Sprint 2 (2 semanas):**
   - Iniciar a consolidaÃ§Ã£o do pipeline conforme a Fase 2
   - Desenvolver o novo framework de estÃ¡gios como plugins
   - Implementar configuraÃ§Ã£o central baseada em YAML
   
3. **Sprint 3 (2 semanas):**
   - Finalizar a transiÃ§Ã£o para o pipeline unificado
   - Implementar CLI integrada
   - Testar e validar com diferentes configuraÃ§Ãµes
   
4. **Sprint 4 (conforme disponibilidade):**
   - Implementar otimizaÃ§Ãµes da Fase 3
   - Focar em sistemas de cache e paralelizaÃ§Ã£o
   - Considerar interface web se o tempo permitir

Este plano equilibra a necessidade de correÃ§Ãµes imediatas com melhorias arquiteturais de longo prazo, garantindo que o sistema continue funcionando enquanto Ã© progressivamente aprimorado.

## OtimizaÃ§Ãµes do Pipeline e CorreÃ§Ãµes de VisualizaÃ§Ãµes (Junho/2025)

Com base no levantamento realizado em 03/06/2025, identificamos uma sÃ©rie de visualizaÃ§Ãµes que estÃ£o implementadas no cÃ³digo mas nÃ£o estÃ£o sendo geradas na Ãºltima execuÃ§Ã£o do pipeline. TambÃ©m foram identificadas oportunidades de otimizaÃ§Ã£o da arquitetura do pipeline para tornÃ¡-lo mais modular, eficiente e fÃ¡cil de manter.

### VisualizaÃ§Ãµes Implementadas vs. Geradas

| Tipo de VisualizaÃ§Ã£o | Status | LocalizaÃ§Ã£o da ImplementaÃ§Ã£o | Problema Identificado |
|----------------------|--------|------------------------------|------------------------|
| Plots de correlaÃ§Ã£o | âŒ NÃ£o Gerado | `analysis_correlation.py` | Apenas visualizaÃ§Ãµes de covariÃ¢ncia estÃ£o sendo geradas |
| Plots de janela deslizante | âŒ NÃ£o Gerado | `analysis_sliding_window.py` | MÃ³dulo implementado, mas pipeline dedicado nÃ£o executado |
| VisualizaÃ§Ã£o de sÃ©ries temporais combinadas | âŒ NÃ£o Gerado | `analysis_descriptive.py` | FunÃ§Ã£o implementada mas nÃ£o chamada no pipeline principal |
| Plots de detecÃ§Ã£o de anomalias | âŒ NÃ£o Gerado | `analysis_descriptive.py` | FunÃ§Ã£o implementada mas nÃ£o integrada ao pipeline |
| VisualizaÃ§Ãµes de anÃ¡lise multi-round | âŒ NÃ£o Gerado | `analysis_multi_round.py` | EstÃ¡gio incluÃ­do no pipeline com janelas deslizantes, mas nÃ£o no principal |

### Plano de OtimizaÃ§Ã£o do Pipeline

#### Fase 1: CorreÃ§Ã£o Imediata das VisualizaÃ§Ãµes (Junho/2025 - Semana 1)

1. **ExecuÃ§Ã£o do Pipeline Unificado**:
   - Um script unificado foi desenvolvido em `src/run_unified_pipeline.py` para executar todas as anÃ¡lises
   - Executar: `python -m src.run_unified_pipeline --config config/pipeline_config.yaml`
   - O script verifica automaticamente quais visualizaÃ§Ãµes foram geradas e quais estÃ£o faltando
   - Para desativar anÃ¡lises especÃ­ficas: `--no-sliding-window` ou `--no-multi-round`

2. **CorreÃ§Ã£o dos Plots de CorrelaÃ§Ã£o**:
   - Modificar o estÃ¡gio `CorrelationAnalysisStage` para chamar tanto `plot_correlation_heatmap` quanto `plot_covariance_heatmap`
   - Verificar se as visualizaÃ§Ãµes de correlaÃ§Ã£o estÃ£o sendo geradas corretamente
   - Garantir que o diretÃ³rio de saÃ­da existe e tem permissÃµes adequadas

3. **IntegraÃ§Ã£o da DetecÃ§Ã£o de Anomalias**:
   - Modificar `DescriptiveAnalysisStage` para chamar as funÃ§Ãµes de detecÃ§Ã£o de anomalias
   - Criar diretÃ³rio especÃ­fico para salvar os plots de anomalias

#### Fase 2: ConsolidaÃ§Ã£o da Arquitetura (Junho/2025 - Semanas 2-3)

1. **UnificaÃ§Ã£o dos Arquivos de Pipeline**:
   - Consolidar `pipeline.py`, `pipeline_new.py` e `pipeline_with_sliding_window.py` em um Ãºnico arquivo
   - Implementar sistema de plugins para diferentes estÃ¡gios do pipeline
   - Criar configuraÃ§Ã£o baseada em YAML para ativar/desativar mÃ³dulos especÃ­ficos

2. **Sistema de ConfiguraÃ§Ã£o Centralizado**:
   - Refatorar `parse_config.py` para um sistema mais robusto e extensÃ­vel
   - Implementar validaÃ§Ã£o de configuraÃ§Ã£o com schemas
   - Documentar todas as opÃ§Ãµes de configuraÃ§Ã£o disponÃ­veis

3. **CLI Unificada**:
   - Desenvolver uma interface de linha de comando unificada usando `argparse` ou `click`
   - Oferecer opÃ§Ãµes para executar apenas partes especÃ­ficas do pipeline
   - Implementar flags para controle de verbosidade e depuraÃ§Ã£o

#### Fase 3: OtimizaÃ§Ãµes de Desempenho (Julho/2025)

1. **Sistema de Cache**:
   - Implementar sistema de cache para resultados intermediÃ¡rios do pipeline
   - Usar hashes de configuraÃ§Ã£o como chaves de cache
   - Adicionar opÃ§Ã£o para forÃ§ar recÃ¡lculo ignorando o cache

2. **ParalelizaÃ§Ã£o de Processamento**:
   - Identificar estÃ¡gios independentes que podem ser executados em paralelo
   - Implementar processamento multiprocesso para anÃ¡lises intensivas
   - Adicionar controle de concorrÃªncia para evitar uso excessivo de recursos

3. **OtimizaÃ§Ã£o de MemÃ³ria**:
   - Implementar streaming de dados para processamento de grandes conjuntos
   - Utilizar formatos de arquivo mais eficientes para persistÃªncia
   - Implementar liberaÃ§Ã£o estratÃ©gica de memÃ³ria durante o processamento

#### Fase 4: Extensibilidade e Manutenibilidade (Agosto/2025)

1. **DocumentaÃ§Ã£o Aprimorada**:
   - Gerar documentaÃ§Ã£o automÃ¡tica usando Sphinx
   - Adicionar exemplos de uso para cada mÃ³dulo e funÃ§Ã£o
   - Criar tutoriais para casos de uso comuns

2. **Testes AutomÃ¡ticos**:
   - Implementar testes unitÃ¡rios para componentes crÃ­ticos
   - Adicionar testes de integraÃ§Ã£o para o pipeline completo
   - Configurar CI/CD para execuÃ§Ã£o automÃ¡tica de testes

3. **MÃ©tricas de Qualidade**:
   - Implementar coleta de mÃ©tricas de desempenho do pipeline
   - Adicionar logging estruturado para anÃ¡lise e depuraÃ§Ã£o
   - Criar dashboards para visualizaÃ§Ã£o de mÃ©tricas de qualidade e desempenho

