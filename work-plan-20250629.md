Objetivo:
    Consolidar os resultados estatísticos obtidos por round em uma análise robusta por métrica × fase × tenant, permitindo generalização e visualização dos efeitos com confiança.

🚦 Etapa 0 – Ponto de partida (o que você já tem)
Recurso	Status
Dados organizados por round	✅
Análise descritiva por métrica/fase	✅
Correlações, causalidade e plots	✅
Comparações intra-round (fase vs fase)	✅

    💡 Você já tem todos os dados fragmentados — agora o trabalho é integrar com estratégia.

🧩 Etapa 1 – Padronização e Coleta de Resultados
✅ Ação:

    Criar um extrator unificado que recolha os outputs por round:

        Cohen's d  ✅

        p-valor  ✅

        Eta-squared (se estiver usando)  ✅

        Correlação intra-fase  ✅

        Causalidade (Granger/TE)  ✅

    📋 Estado atual de implementação:
        - Parcialmente implementado em src/analysis_multi_round.py
        - Função _load_causality_matrices() já carrega matrizes de causalidade ✅
        - Extrator para estatísticas de Cohen's d e p-valores em src/effect_size.py ✅
        - Implementado extrator de correlações intra-fase em src/phase_correlation.py ✅

    🔄 Próximo passo:
        - Função extract_effect_sizes() para coletar Cohen's d e p-valores ✅
        - Funções para extrair Eta-squared ✅
        - Implementar extract_phase_correlations() para coletar correlações por fase ✅
        - Estruturar dados em formato padrão para facilitar agregações ✅
        
    💻 Detalhes técnicos:
        - Implementar em src/analysis_multi_round.py uma função extract_effect_sizes(context, rounds, metrics, phases, tenants) ✅
          * DataFrame com colunas: round_id, metric_name, experimental_phase, tenant_id, baseline_phase, effect_size, p_value, eta_squared ✅
        - Utilizar a biblioteca statsmodels para calcular o Cohen's d e Eta-squared ✅
        - Implementar extract_phase_correlations() para coletar correlações por fase ✅
          * DataFrame com colunas: round_id, metric_name, experimental_phase, tenant_pair, correlation, method, sample_size ✅
        - Armazenar resultados em formato padronizado para facilitar agregações posteriores ✅
        
    🔍 Sugestões de melhoria:
        - Implementar cache de resultados para evitar recálculos ✅
        - Adicionar opção para paralelizar a extração usando multiprocessing ✅
        - Implementar verificação de qualidade dos dados estatísticos extraídos ✅

🧠 Etapa 2 – Agregação Estatística
✅ Ação:

    Para cada métrica × fase × tenant:

        Calcular:

            Média do efeito  ✅

            Desvio padrão  ✅

            IC95%  ✅

            p-valor combinado (Fisher ou Stouffer)  ✅

            Score de estabilidade (ex: coeficiente de variação)  ✅

    📋 Estado atual de implementação:
        - analyze_round_consistency() calcula coeficiente de variação (CV) ✅
        - Função test_friedmanchisquare para análise estatística ✅
        - Implementada função aggregate_effect_sizes() que calcula média e desvio padrão ✅
        - Adicionados critérios de confiabilidade (alta/média/baixa) ✅
        - Implementado cálculo de IC95% usando bootstrapping ✅
        - Implementados métodos de combinação de p-valores (Fisher/Stouffer) ✅

    🔄 Próximo passo:
        - Teste das implementações de IC95% e combinação de p-valores ✅
        - Melhorar os scores de estabilidade adicionais além do CV ✅
        
    💻 Detalhes técnicos:
        - Função aggregate_effect_sizes() em src/effect_aggregation.py: ✅
          * Agrupa por metric_name, experimental_phase, tenant_id ✅
          * Calcula média e desvio padrão para o tamanho de efeito entre os rounds ✅
          * Implementação do IC95% usando bootstrapping concluída e testada ✅
          * Implementados métodos de meta-análise para combinação de p-valores: ✅
            - Método de Fisher: χ² = -2 * Σ log(p_i) ✅
            - Método de Stouffer: Z = Σz_i / √n onde z_i = Φ⁻¹(1-p_i) ✅
        - Implementada função para calcular categoria de confiabilidade dos resultados ✅
        
    🔍 Sugestões de melhoria:
        - Adicionar detecção automática de outliers em rounds específicos ❌
        - Implementar visualização de forest plots para meta-análise ❌
        - Adicionar cálculo de poder estatístico e tamanho de amostra necessário ❌

📊 Etapa 3 – Visualização Consolidada
✅ Ação:

    Geração de:

        Heatmaps de tamanho de efeito médio  ✅

        Boxplots de variabilidade por round  ✅

        Error bars com IC95%  ✅

        Gráficos de dispersão: efeito × p-valor × variabilidade  ✅

        Visualização de correlações intra-fase  ✅

    📋 Estado atual de implementação:
        - Função generate_all_enhanced_consolidated_boxplots() implementada ✅
        - Criada a estrutura inicial das funções de visualização em src/visualization/effect_plots.py ✅
        - Implementação completa do generate_effect_size_heatmap() ✅
        - Implementação completa do plot_effect_error_bars() ✅
        - Implementação completa do plot_effect_scatter() ✅
        - Implementadas visualizações para correlações intra-fase ✅

    🔄 Próximo passo:
        - Finalizar implementação de heatmap para tamanho de efeito médio ✅
        - Refinar visualização de error bars com IC95% ✅
        - Completar função para gráficos de dispersão multidimensionais ✅
        - Integração completa das visualizações para correlações intra-fase ✅
        
    💻 Detalhes técnicos:
        - Completas em src/visualization/effect_plots.py as funções: ✅
          * generate_effect_size_heatmap(aggregated_effects_df, output_dir, cmap='RdBu_r') ✅
          * plot_effect_error_bars() para visualizar intervalos de confiança ✅
          * plot_effect_scatter() para gráficos de dispersão multivariados ✅
          * generate_effect_forest_plot() para visualização estilo meta-análise ✅
        - Desenvolver funções para visualização de correlações intra-fase: ✅
          * plot_correlation_network() para visualizar redes de correlação entre tenants ✅
          * plot_correlation_heatmap() para correlações intra-fase ✅
          * plot_correlation_stability() para visualizar estabilidade entre rounds ✅
        
    🔍 Sugestões de melhoria:
        - Adicionar interatividade usando Plotly para exploração de dados ❌
        - Implementar exportação automática para formatos de publicação (SVG, PDF) ❌
        - Adicionar geração de relatórios visuais em formato HTML ou dashboard ❌

🔬 Etapa 4 - Interpretação e Validação (Adicional)
✅ Ação:

    Implementar:

        Análise de robustez dos achados estatísticos  ✅

        Testes de sensibilidade para confirmar limites de significância  ✅

        Resumos automatizados dos achados principais  ✅

    📋 Estado atual de implementação:
        - Implementada função generate_automated_insights() ✅
        - Implementada geração de resumos para tamanhos de efeito ✅
        - Implementada análise de estabilidade para correlações intra-fase ✅
        - Implementados testes de robustez e sensibilidade para tamanhos de efeito ✅
        - Implementada função generate_markdown_report() para exportar insights ✅

    🔄 Próximo passo:
        - Implementada análise leave-one-out para robustez de tamanhos de efeito ✅
        - Implementados testes de sensibilidade variando limiares de significância ✅
        - Integrar resumos de correlações intra-fase aos relatórios ✅
        - Implementada geração automática de insights e recomendações ✅
        
    💻 Detalhes técnicos:
        - Implementada a função perform_robustness_analysis em src/robustness_analysis.py: ✅
          * perform_robustness_analysis(effect_sizes_df) que: ✅
            - Realiza análise leave-one-out para detectar dependência de rounds específicos ✅
            - Calcula a estabilidade das conclusões variando limiares de significância ✅
            - Quantifica a incerteza usando métodos estatísticos ✅
        - Expandida a função analyze_correlation_stability() já implementada para incluir: ✅
          * Detecção de padrões de correlação consistentes entre rounds ✅
        - Implementada generate_automated_insights() para criar resumos automáticos de: ✅
          * Efeitos consistentes entre rounds ✅
          * Anomalias e exceções detectadas ✅
          * Recomendações baseadas em evidência ✅
        - Implementada generate_markdown_report() para exportar insights formatados ✅
        
    🔍 Sugestões de melhoria para versões futuras:
        - Implementar modelo de linguagem para geração de insights em linguagem natural ❌
        - Adicionar classificação de confiabilidade aos resultados (alta/média/baixa) ✅
        - Implementar rank de relevância dos achados para destacar os mais importantes ❌
        - Adicionar detecção automática de outliers entre rounds ❌
        - Expandir análises de relação entre correlações e tamanhos de efeito ❌

📝 Etapa 5 - Integração com Pipeline Principal (Adicional)
✅ Ação:

    Garantir:

        Integração fluida com o pipeline existente  ✅

        Opções de configuração via YAML  ✅

        Documentação detalhada das novas funcionalidades  ⏳ Em andamento

    📋 Estado atual de implementação:
        - MultiRoundAnalysisStage já existe e está completamente integrado ✅ 
        - run_multi_round_analysis.py já funciona como ponto de entrada ✅
        - Opções de configuração específicas para as novas análises adicionadas ✅
        - Integração de todas as funções de análise e visualização concluídas ✅
        - Integração dos resumos automatizados e insights concluída ✅
        - Documentação inicial criada ✅ mas precisa ser ampliada ⏳

    🔄 Próximo passo:
        - Expandir opções no arquivo de configuração YAML ✅
        - Documentar novas funcionalidades ✅
        - Criar exemplos de uso ⏳
        
    💻 Detalhes técnicos:
        - Atualizar o config/pipeline_config_sfi2.yaml para incluir: ✅
          * Opções de configuração para análise multi-round ✅
            ```yaml
            multi_round_analysis:
              effect_size:
                methods: ["cohen_d", "eta_squared"]
              meta_analysis:
                p_value_combination: "fisher"  # ou "stouffer"
                confidence_level: 0.95
              visualization:
                heatmap_colormap: "RdBu_r"
                show_significance_markers: true
            ```
          * Opções para controle de paralelização e cache ✅
        - Atualizar documentação no README.md com: ⏳
          * Descrição das novas funcionalidades ✅
          * Exemplos de comando para executar a análise ✅
          * Interpretação dos resultados e outputs ⏳
        
    🔍 Sugestões de melhoria:
        - Adicionar testes unitários para as novas funcionalidades ❌
        - Implementar logging detalhado para todas as etapas ✅
        - Criar interface de linha de comando mais robusta com validação de parâmetros ❌
        - Implementar cache inteligente para evitar reprocessamento de dados ✅

⚡ Plano de Priorização Atualizado:
    1. Implementar extract_effect_sizes() (Etapa 1) ✅ CONCLUÍDO
    2. Implementar extract_phase_correlations() (Etapa 1) ✅ CONCLUÍDO
    3. Implementar aggregate_effect_sizes() (Etapa 2) ✅ CONCLUÍDO
    4. Finalizar IC95% e combinação de p-valores (Etapa 2) ✅ CONCLUÍDO
    5. Completar implementação do generate_effect_size_heatmap() (Etapa 3) ✅ CONCLUÍDO 
    6. Implementar visualização de error bars e scatter plots (Etapa 3) ✅ CONCLUÍDO
    7. Desenvolver análises de robustez para tamanhos de efeito (Etapa 4) ✅ CONCLUÍDO
    8. Implementar visualizações para correlações intra-fase (Etapa 3) ✅ CONCLUÍDO
    9. Melhorar resumos automáticos e insights (Etapa 4) ✅ CONCLUÍDO 
    10. Completar documentação e exemplos (Etapa 5) ⏳ EM ANDAMENTO