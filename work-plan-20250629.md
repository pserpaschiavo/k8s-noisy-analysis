Objetivo:
    Consolidar os resultados estatísticos obtidos por round em uma análise robusta por métrica × fase × tenant, permitindo generalização e visualização dos efeitos com confiança.

🚦 Etapa 0 – Ponto de partida (o que você já tem)
Recurso	Status
Dados organizados por round	✅
Análise descritiva por métrica/fase	✅
Correlações, causalidade e plots	✅
Comparações intra-round (fase vs fase)	✅

    💡 Você já tem todos os dados fragmentados — agora o trabalho é integrar com estratégia.

🧩 Etapa 1 – Padronização e Coleta de Resultados
✅ Ação:

    Criar um extrator unificado que recolha os outputs por round:

        Cohen's d  ✅

        p-valor  ✅

        Eta-squared (se estiver usando)  ✅

        Correlação intra-fase  ⏳ Em andamento

        Causalidade (Granger/TE)  ✅

    📋 Estado atual de implementação:
        - Parcialmente implementado em src/analysis_multi_round.py
        - Função _load_causality_matrices() já carrega matrizes de causalidade ✅
        - Extrator para estatísticas de Cohen's d e p-valores em src/effect_size.py ✅
        - Falta implementar coleta de correlações intra-fase de forma unificada ⏳

    🔄 Próximo passo:
        - Função extract_effect_sizes() para coletar Cohen's d e p-valores ✅
        - Funções para extrair Eta-squared ✅
        - Estruturar dados em formato padrão para facilitar agregações ✅
        
    💻 Detalhes técnicos:
        - Implementar em src/analysis_multi_round.py uma função extract_effect_sizes(context, rounds, metrics, phases, tenants) ✅
          * DataFrame com colunas: round_id, metric_name, experimental_phase, tenant_id, baseline_phase, effect_size, p_value, eta_squared ✅
        - Utilizar a biblioteca statsmodels para calcular o Cohen's d e Eta-squared ✅
        - Implementar extract_phase_correlations() para coletar correlações por fase ⏳
        - Armazenar resultados em formato padronizado para facilitar agregações posteriores ✅
        
    🔍 Sugestões de melhoria:
        - Implementar cache de resultados para evitar recálculos ✅
        - Adicionar opção para paralelizar a extração usando multiprocessing ✅
        - Implementar verificação de qualidade dos dados estatísticos extraídos ✅

🧠 Etapa 2 – Agregação Estatística
✅ Ação:

    Para cada métrica × fase × tenant:

        Calcular:

            Média do efeito  ⏳ Em andamento

            Desvio padrão  ⏳ Em andamento

            IC95%  ❌ Não implementado

            p-valor combinado (Fisher ou Stouffer)  ❌ Não implementado

            Score de estabilidade (ex: coeficiente de variação)  ✅

    📋 Estado atual de implementação:
        - analyze_round_consistency() calcula coeficiente de variação (CV) ✅
        - Função test_friedmanchisquare para análise estatística ✅
        - Falta implementar cálculo de IC95% para efeitos ❌
        - Falta implementar métodos de combinação de p-valores (Fisher/Stouffer) ❌

    🔄 Próximo passo:
        - Implementar função aggregate_effect_sizes() para calcular média, desvio padrão, IC95% ⏳ Em andamento
        - Adicionar métodos para p-valor combinado (Fisher e Stouffer) ❌
        - Calcular scores de estabilidade adicionais além do CV ⏳
        
    💻 Detalhes técnicos:
        - Implementar em src/analysis_multi_round.py a função aggregate_effect_sizes(effect_sizes_df) que:
          * Agrupa por metric_name, experimental_phase, tenant_id ⏳
          * Calcula média e desvio padrão para o tamanho de efeito entre os rounds ⏳
          * Calcula IC95% usando bootstrapping ou estatística t ❌
          * Implementa métodos de meta-análise para combinação de p-valores: ❌
            - Método de Fisher: χ² = -2 * Σ log(p_i) ❌
            - Método de Stouffer: Z = Σz_i / √n onde z_i = Φ⁻¹(1-p_i) ❌
        - Implementar metrics_stability_score() para calcular métricas adicionais de estabilidade ⏳
        
    🔍 Sugestões de melhoria:
        - Adicionar detecção automática de outliers em rounds específicos ❌
        - Implementar visualização de forest plots para meta-análise ❌
        - Adicionar cálculo de poder estatístico e tamanho de amostra necessário ❌

📊 Etapa 3 – Visualização Consolidada
✅ Ação:

    Geração de:

        Heatmaps de tamanho de efeito médio  ❌ Não implementado

        Boxplots de variabilidade por round  ⏳ Em andamento

        Error bars com IC95%  ❌ Não implementado

        Gráficos de dispersão: efeito × p-valor × variabilidade  ❌ Não implementado

    📋 Estado atual de implementação:
        - Função generate_consolidated_heatmap() existe mas precisa ser adaptada ⏳
        - Função generate_all_enhanced_consolidated_boxplots() parcialmente implementada ⏳
        - Falta implementar gráficos de error bars com IC95% ❌
        - Falta implementar gráficos de dispersão para relação efeito × p-valor × variabilidade ❌

    🔄 Próximo passo:
        - Adaptar heatmap para visualizar tamanho de efeito médio ❌
        - Implementar visualização de error bars com IC95% ❌
        - Criar função para gráficos de dispersão multidimensionais ❌
        
    💻 Detalhes técnicos:
        - Atualizar em src/visualization/advanced_plots.py a função para gerar heatmaps: ❌
          * generate_effect_size_heatmap(aggregated_effects_df, output_dir, cmap='RdBu_r') ❌
          * Utilizar matplotlib/seaborn para gerar heatmaps com células coloridas por tamanho de efeito ❌
          * Adicionar anotações para p-valores significativos (asteriscos) ❌
        - Implementar plot_effect_error_bars() para visualizar intervalos de confiança ❌
        - Criar função plot_effect_scatter() para gráficos de dispersão multivariados ❌
        - Implementar função generate_effect_forest_plot() para visualização estilo meta-análise ❌
        
    🔍 Sugestões de melhoria:
        - Adicionar interatividade usando Plotly para exploração de dados ❌
        - Implementar exportação automática para formatos de publicação (SVG, PDF) ❌
        - Adicionar geração de relatórios visuais em formato HTML ou dashboard ❌

🔬 Etapa 4 - Interpretação e Validação (Adicional)
✅ Ação:

    Implementar:

        Análise de robustez dos achados estatísticos  ❌ Não implementado

        Testes de sensibilidade para confirmar limites de significância  ❌ Não implementado

        Resumos automatizados dos achados principais  ⏳ Em andamento

    📋 Estado atual de implementação:
        - Parcial na função generate_multi_round_report() ⏳
        - Faltam testes de robustez e sensibilidade ❌
        - Resumos automatizados estão incompletos ⏳

    🔄 Próximo passo:
        - Adicionar métricas de robustez estatística ❌
        - Implementar testes de sensibilidade ❌
        - Melhorar a geração automática de insights ⏳
        
    💻 Detalhes técnicos:
        - Implementar em src/analysis_multi_round.py funções para análise de robustez: ❌
          * perform_robustness_analysis(aggregated_effects_df) que: ❌
            - Realiza análise leave-one-out para detectar dependência de rounds específicos ❌
            - Calcula a estabilidade das conclusões variando limiares de significância ❌
            - Quantifica a incerteza usando métodos bayesianos ou bootstrap ❌
        - Implementar generate_automated_insights() para criar resumos automáticos de: ❌
          * Efeitos consistentes entre rounds ❌
          * Anomalias e exceções detectadas ❌
          * Recomendações baseadas em evidência ❌
        
    🔍 Sugestões de melhoria:
        - Implementar modelo de linguagem para geração de insights em linguagem natural ❌
        - Adicionar classificação de confiabilidade aos resultados (alta/média/baixa) ✅
        - Implementar rank de relevância dos achados para destacar os mais importantes ❌

📝 Etapa 5 - Integração com Pipeline Principal (Adicional)
✅ Ação:

    Garantir:

        Integração fluida com o pipeline existente  ⏳ Em andamento

        Opções de configuração via YAML  ✅

        Documentação detalhada das novas funcionalidades  ⏳ Em andamento

    📋 Estado atual de implementação:
        - MultiRoundAnalysisStage já existe e está integrado ✅
        - run_multi_round_analysis.py já funciona como ponto de entrada ✅
        - Opções de configuração específicas para as novas análises adicionadas ✅
        - Documentação inicial criada ✅ mas precisa ser ampliada ⏳

    🔄 Próximo passo:
        - Expandir opções no arquivo de configuração YAML ✅
        - Documentar novas funcionalidades ✅
        - Criar exemplos de uso ⏳
        
    💻 Detalhes técnicos:
        - Atualizar o config/pipeline_config_sfi2.yaml para incluir: ✅
          * Opções de configuração para análise multi-round ✅
            ```yaml
            multi_round_analysis:
              effect_size:
                methods: ["cohen_d", "eta_squared"]
              meta_analysis:
                p_value_combination: "fisher"  # ou "stouffer"
                confidence_level: 0.95
              visualization:
                heatmap_colormap: "RdBu_r"
                show_significance_markers: true
            ```
          * Opções para controle de paralelização e cache ✅
        - Atualizar documentação no README.md com: ⏳
          * Descrição das novas funcionalidades ✅
          * Exemplos de comando para executar a análise ✅
          * Interpretação dos resultados e outputs ⏳
        
    🔍 Sugestões de melhoria:
        - Adicionar testes unitários para as novas funcionalidades ❌
        - Implementar logging detalhado para todas as etapas ✅
        - Criar interface de linha de comando mais robusta com validação de parâmetros ❌
        - Implementar cache inteligente para evitar reprocessamento de dados ✅

⚡ Plano de Priorização:
    1. Implementar extract_effect_sizes() (Etapa 1) ✅ CONCLUÍDO
    2. Implementar aggregate_effect_sizes() (Etapa 2) ⏳ EM ANDAMENTO
    3. Atualizar o heatmap e implementar error bars (Etapa 3) ❌ A IMPLEMENTAR 
    4. Adicionar opções ao arquivo de configuração YAML (Etapa 5) ✅ CONCLUÍDO
    5. Desenvolver análises de robustez (Etapa 4) ❌ A IMPLEMENTAR
    6. Melhorar visualizações e relatórios (Etapas 3 e 4) ❌ A IMPLEMENTAR
    7. Documentar novas funcionalidades (Etapa 5) ⏳ EM ANDAMENTO