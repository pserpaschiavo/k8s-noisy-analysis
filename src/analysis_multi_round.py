#!/usr/bin/env python3
"""
Module: analysis_multi_round.py
Description: M√≥dulo para an√°lise de experimentos com m√∫ltiplos rounds.

Este m√≥dulo implementa metodologias para an√°lise de consist√™ncia entre rounds,
avalia√ß√£o de robustez causal, an√°lise de diverg√™ncia comportamental e
agrega√ß√£o de consenso para experimentos com m√∫ltiplos rounds.
"""

import os
import logging
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import networkx as nx  # Adicionando importa√ß√£o do NetworkX
from typing import Dict, List, Tuple, Any, Optional, Union
from scipy import stats
from scipy.spatial import distance
from sklearn.cluster import AgglomerativeClustering
from sklearn.metrics import silhouette_score
from datetime import datetime

from src.pipeline_stage import PipelineStage
from src.visualization.plots import (
    generate_consolidated_heatmap,
    generate_all_enhanced_consolidated_boxplots
)
from src.visualization.advanced_plots import generate_all_consolidated_timeseries

# Configura√ß√£o de logging e estilo
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger("analysis_multi_round")
plt.style.use('tableau-colorblind10')

class MultiRoundAnalysisStage(PipelineStage):
    """
    Est√°gio do pipeline para an√°lise de experimentos com m√∫ltiplos rounds.
    Implementa as funcionalidades descritas na se√ß√£o 3.6 do plano de trabalho.
    """
    
    def __init__(self, output_dir: Optional[str] = None):
        super().__init__(
            name="Multi-Round Analysis", 
            description="An√°lise de consist√™ncia e robustez entre m√∫ltiplos rounds de experimento"
        )
        self.output_dir = output_dir
        # Adicionando um logger espec√≠fico para esta classe para melhor rastreabilidade
        self.logger = logging.getLogger(self.__class__.__name__)

    def _execute_implementation(self, context: Dict[str, Any]) -> Dict[str, Any]:
        """
        Implementation of the abstract method from PipelineStage.
        Bridges to the existing run method by extracting config from context.
        """
        # Extract config from context - pipeline stages should include their config
        config = context.get('config', {})
        return self.run(context, config)

    def run(self, context: Dict[str, Any], config: Dict[str, Any]) -> Dict[str, Any]:
        """
        Executa a an√°lise multi-round, combinando consist√™ncia de m√©tricas,
        robustez causal e an√°lise de diverg√™ncia.
        """
        self.logger.info("Iniciando a an√°lise multi-round completa...")

        if 'error' in context:
            self.logger.error(f"Erro em est√°gio anterior: {context['error']}")
            return context

        df_long = context.get('df_long')
        if df_long is None:
            self.logger.warning("DataFrame principal (df_long) n√£o encontrado no contexto.")
            context['error'] = "DataFrame principal n√£o dispon√≠vel para an√°lise multi-round"
            return context

        rounds = config.get('selected_rounds', sorted(df_long['round_id'].unique()))
        if len(rounds) <= 1:
            self.logger.info("Apenas um round encontrado ou selecionado. Pulando an√°lise multi-round.")
            context['multi_round_analysis'] = {
                'status': 'skipped',
                'reason': 'O dataset cont√©m apenas um round de experimento ou apenas um foi selecionado.'
            }
            return context

        # Configura√ß√£o do diret√≥rio de sa√≠da
        base_output_dir = self.output_dir or context.get('output_dir')
        if not base_output_dir:
            experiment_id = context.get('experiment_id', 'unknown_experiment')
            base_output_dir = os.path.join(os.getcwd(), 'outputs', experiment_id)
            self.logger.warning(f"Diret√≥rio de sa√≠da n√£o especificado. Usando fallback: {base_output_dir}")

        output_dir = os.path.join(base_output_dir, 'multi_round_analysis')
        os.makedirs(output_dir, exist_ok=True)
        self.logger.info(f"Diret√≥rio de sa√≠da para an√°lise multi-round: {output_dir}")
        
        # Atualiza o output_dir da inst√¢ncia para que outros m√©todos o utilizem
        self.output_dir = output_dir

        metrics = context.get('selected_metrics', sorted(df_long['metric_name'].unique()))
        tenants = context.get('selected_tenants', sorted(df_long['tenant_id'].unique()))
        
        df_filtered = df_long[df_long['round_id'].isin(rounds)]

        try:
            results = {}

            # 1. An√°lise de consist√™ncia de causalidade (Jaccard/Spearman)
            self.logger.info("Analisando a consist√™ncia da estrutura causal (Jaccard/Spearman)...")
            causality_data = self._load_causality_matrices(context, rounds)
            te_matrices_by_round = causality_data.get('te_matrices_by_round', {})
            granger_matrices_by_round = causality_data.get('granger_matrices_by_round', {})
            
            # Reformatar dados para o m√©todo de an√°lise de consist√™ncia
            causality_matrices_reformatted = {}
            for r in rounds:
                if r in te_matrices_by_round or r in granger_matrices_by_round:
                     causality_matrices_reformatted[r] = {
                         'te_matrices': te_matrices_by_round.get(r, {}),
                         'granger_matrices': granger_matrices_by_round.get(r, {})
                     }

            if causality_matrices_reformatted:
                graph_consistency_results = self.analyze_causality_consistency(causality_matrices_reformatted)
                results['graph_consistency'] = graph_consistency_results
                self.generate_consistency_visualizations(graph_consistency_results)
            else:
                self.logger.warning("Nenhuma matriz de causalidade carregada. Pulando an√°lise de consist√™ncia da estrutura causal.")
                results['graph_consistency'] = {}


            # 2. An√°lise de consist√™ncia de m√©tricas (CV/Friedman)
            self.logger.info("Analisando a consist√™ncia dos valores das m√©tricas (CV/Friedman)...")
            results['metric_consistency'] = analyze_round_consistency(
                df_long=df_filtered, metrics=metrics, tenants=tenants, output_dir=output_dir
            )

            # 3. An√°lise de robustez de causalidade (CV sobre TE)
            if te_matrices_by_round:
                self.logger.info("Analisando a robustez da for√ßa causal (CV sobre TE)...")
                causality_robustness = analyze_causality_robustness(
                    te_matrices_by_round=te_matrices_by_round,
                    granger_matrices_by_round=granger_matrices_by_round,
                    output_dir=output_dir
                )
                results['causality_robustness'] = causality_robustness

                if 'robust_causal_relationships' in causality_robustness:
                    robust_graphs = {}
                    for metric in causality_robustness.get('metrics_with_consistent_causality', []):
                        graph_path = generate_robust_causality_graph(
                            robust_relationships=causality_robustness['robust_causal_relationships'],
                            output_dir=output_dir, metric=metric
                        )
                        if graph_path:
                            robust_graphs[metric] = graph_path
                    if robust_graphs:
                        results['robust_causality_graphs'] = robust_graphs
            else:
                self.logger.warning("Matrizes de Transfer Entropy n√£o dispon√≠veis. Pulando an√°lise de robustez causal.")

            # 4. An√°lise de diverg√™ncia comportamental (KL-Divergence)
            self.logger.info("Analisando a diverg√™ncia comportamental entre rounds (KL-Divergence)...")
            results['behavioral_divergence'] = analyze_behavioral_divergence(
                df_long=df_filtered, metrics=metrics, tenants=tenants, output_dir=output_dir
            )

            # 5. Agrega√ß√£o de consenso
            if te_matrices_by_round:
                self.logger.info("Agregando um consenso entre os rounds...")
                results['consensus'] = aggregate_round_consensus(
                    df_long=df_filtered,
                    te_matrices_by_round=te_matrices_by_round,
                    consistency_results=results.get('metric_consistency', {}),
                    output_dir=output_dir
                )
            else:
                 self.logger.warning("Matrizes de Transfer Entropy n√£o dispon√≠veis. Pulando agrega√ß√£o de consenso.")

            # 6. Visualiza√ß√µes consolidadas
            self.logger.info("Gerando visualiza√ß√µes consolidadas...")
            # Removido o antigo `generate_round_consistency_visualizations`
            # As visualiza√ß√µes agora s√£o geradas por tipo.

            # 6.1 Boxplots Consolidados (Aprimorado v2.1)
            self.logger.info("Gerando boxplots consolidados (violin) para todas as m√©tricas...")
            try:
                boxplot_dir = os.path.join(output_dir, "boxplots")
                os.makedirs(boxplot_dir, exist_ok=True)
                boxplot_paths = generate_all_enhanced_consolidated_boxplots(
                    df_long=df_filtered,
                    output_dir=boxplot_dir
                )
                results['consolidated_boxplots'] = boxplot_paths
                self.logger.info(f"‚úÖ Boxplots consolidados gerados: {len(boxplot_paths)} arquivos")
            except Exception as e:
                self.logger.error(f"Erro ao gerar boxplots consolidados: {e}")
                results['consolidated_boxplots'] = {}

            # 6.2 Time Series Consolidados (v2.0)
            self.logger.info("Gerando time series consolidados para todas as m√©tricas...")
            try:
                timeseries_dir = os.path.join(output_dir, "timeseries")
                os.makedirs(timeseries_dir, exist_ok=True)
                timeseries_paths = generate_all_consolidated_timeseries(
                    df_long=df_filtered,
                    output_dir=timeseries_dir, # Diret√≥rio espec√≠fico
                    rounds=rounds,
                    tenants=tenants,
                    normalize_time=True,
                    add_confidence_bands=True
                )
                results['consolidated_timeseries'] = timeseries_paths
                self.logger.info(f"‚úÖ Time series consolidados gerados: {len(timeseries_paths)} m√©tricas")
            except Exception as e:
                self.logger.error(f"Erro ao gerar time series consolidados: {e}")
                results['consolidated_timeseries'] = {}

            # 7. Gerar relat√≥rio consolidado
            self.logger.info("Gerando relat√≥rio consolidado da an√°lise multi-round...")
            self.generate_multi_round_report(results) # Passando todos os resultados

            context['multi_round_analysis'] = results
            context['multi_round_analysis_dir'] = output_dir
            self.logger.info(f"An√°lise multi-round conclu√≠da com sucesso. Resultados em {output_dir}")

        except Exception as e:
            self.logger.error(f"Erro fatal durante a an√°lise multi-round: {str(e)}", exc_info=True)
            context['error'] = f"Erro na an√°lise multi-round: {str(e)}"

        return context

    def analyze_causality_consistency(self, causality_matrices: Dict[str, Any]) -> Dict[str, Any]:
        """
        Analisa a consist√™ncia das matrizes de causalidade entre os rounds.
        Calcula a similaridade de Jaccard para as rela√ß√µes causais (Granger)
        e a correla√ß√£o de Spearman para a for√ßa da causalidade (TE).
        """
        self.logger.info("Analisando a consist√™ncia da causalidade entre os rounds...")
        
        consistency_results = {
            "granger_jaccard": pd.DataFrame(),
            "te_spearman": pd.DataFrame()
        }
        
        rounds = list(causality_matrices.keys())
        if len(rounds) < 2:
            self.logger.warning("S√£o necess√°rios pelo menos dois rounds para a an√°lise de consist√™ncia.")
            return consistency_results

        # Extrai as matrizes de Granger e TE
        granger_matrices_by_round = {r: v.get('granger_matrices', {}) for r, v in causality_matrices.items()}
        te_matrices_by_round = {r: v.get('te_matrices', {}) for r, v in causality_matrices.items()}

        metrics = list(granger_matrices_by_round[rounds[0]].keys())
        
        jaccard_scores = []
        spearman_scores = []

        for metric in metrics:
            for i in range(len(rounds)):
                for j in range(i + 1, len(rounds)):
                    round1, round2 = rounds[i], rounds[j]
                    
                    # Consist√™ncia para Causalidade de Granger (Jaccard)
                    g1 = granger_matrices_by_round.get(round1, {}).get(metric)
                    g2 = granger_matrices_by_round.get(round2, {}).get(metric)
                    
                    if g1 is not None and g2 is not None:
                        # Binariza a matriz com base no p-valor < 0.05
                        g1_bin = (g1 < 0.05).values.flatten()
                        g2_bin = (g2 < 0.05).values.flatten()
                        
                        jaccard_sim = 1 - distance.jaccard(g1_bin, g2_bin)
                        jaccard_scores.append((metric, f"{round1}-{round2}", jaccard_sim))

                    # Consist√™ncia para Entropia de Transfer√™ncia (Spearman)
                    te1 = te_matrices_by_round.get(round1, {}).get(metric)
                    te2 = te_matrices_by_round.get(round2, {}).get(metric)

                    if te1 is not None and te2 is not None:
                        rho, _ = stats.spearmanr(te1.values.flatten(), te2.values.flatten())
                        spearman_scores.append((metric, f"{round1}-{round2}", rho))

        if jaccard_scores:
            df_jaccard = pd.DataFrame(jaccard_scores, columns=['Metric', 'Round Pair', 'Jaccard Similarity'])
            consistency_results['granger_jaccard'] = df_jaccard.pivot(index='Metric', columns='Round Pair', values='Jaccard Similarity')

        if spearman_scores:
            df_spearman = pd.DataFrame(spearman_scores, columns=['Metric', 'Round Pair', 'Spearman Correlation'])
            consistency_results['te_spearman'] = df_spearman.pivot(index='Metric', columns='Round Pair', values='Spearman Correlation')
            
        self.logger.info("An√°lise de consist√™ncia de causalidade conclu√≠da.")
        self.logger.debug(f"Resultados de Jaccard (Granger):\n{consistency_results['granger_jaccard']}")
        self.logger.debug(f"Resultados de Spearman (TE):\n{consistency_results['te_spearman']}")

        return consistency_results

    def generate_consistency_visualizations(self, consistency_results: Dict[str, Any]):
        """
        Gera visualiza√ß√µes para os resultados da an√°lise de consist√™ncia.
        Cria heatmaps para a similaridade de Jaccard (Granger) e correla√ß√£o de Spearman (TE).
        """
        self.logger.info("Gerando visualiza√ß√µes de consist√™ncia...")
        
        if not self.output_dir:
            self.logger.warning("Diret√≥rio de sa√≠da n√£o configurado. As visualiza√ß√µes n√£o ser√£o salvas.")
            return

        # Visualiza√ß√£o para Jaccard (Granger)
        df_jaccard = consistency_results.get('granger_jaccard')
        if df_jaccard is not None and not df_jaccard.empty:
            output_path = generate_consolidated_heatmap(
                aggregated_matrix=df_jaccard,
                output_dir=self.output_dir,
                title="Consist√™ncia da Causalidade de Granger (Similaridade de Jaccard)",
                filename="granger_consistency_heatmap.png"
            )
            if output_path:
                self.logger.info(f"Heatmap de consist√™ncia de Granger salvo em: {output_path}")

        # Visualiza√ß√£o para Spearman (TE)
        df_spearman = consistency_results.get('te_spearman')
        if df_spearman is not None and not df_spearman.empty:
            output_path = generate_consolidated_heatmap(
                aggregated_matrix=df_spearman,
                output_dir=self.output_dir,
                title="Consist√™ncia da For√ßa Causal (Correla√ß√£o de Spearman para TE)",
                filename="te_consistency_heatmap.png"
            )
            if output_path:
                self.logger.info(f"Heatmap de consist√™ncia de TE salvo em: {output_path}")

    def generate_multi_round_report(self, all_results: Dict[str, Any]):
        """
        Gera um relat√≥rio markdown consolidado com todos os resultados da an√°lise multi-round.
        """
        self.logger.info("Gerando relat√≥rio multi-round consolidado...")
        if not self.output_dir:
            self.logger.warning("Diret√≥rio de sa√≠da n√£o configurado. O relat√≥rio n√£o ser√° salvo.")
            return

        report_path = os.path.join(self.output_dir, "multi_round_analysis_report.md")
        
        with open(report_path, "w") as f:
            f.write("# Relat√≥rio Consolidado de An√°lise Multi-Round\n\n")
            f.write(f"Relat√≥rio gerado em: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n\n")
            f.write("Este relat√≥rio apresenta uma an√°lise compreensiva de m√∫ltiplos rounds de um experimento, avaliando a consist√™ncia, robustez e diverg√™ncias comportamentais para fornecer um veredito consolidado sobre os resultados.\n\n")

            # --- Se√ß√£o 1: Consist√™ncia da Estrutura Causal (Jaccard/Spearman) ---
            f.write("## 1. Consist√™ncia da Estrutura Causal\n\n")
            f.write("Avalia a consist√™ncia das rela√ß√µes causais identificadas entre os rounds.\n\n")
            
            graph_consistency = all_results.get('graph_consistency', {})
            df_jaccard = graph_consistency.get('granger_jaccard')
            if df_jaccard is not None and not df_jaccard.empty:
                f.write("### 1.1. Causalidade de Granger (Similaridade de Jaccard)\n")
                f.write("A tabela a seguir mostra a similaridade de Jaccard entre os conjuntos de rela√ß√µes causais (p < 0.05) para cada par de rounds. Valores mais pr√≥ximos de 1 indicam maior consist√™ncia na ESTRUTURA do grafo causal.\n\n")
                f.write(df_jaccard.to_markdown())
                f.write("\n\n![Heatmap de Consist√™ncia de Granger](./granger_consistency_heatmap.png)\n\n")

            df_spearman = graph_consistency.get('te_spearman')
            if df_spearman is not None and not df_spearman.empty:
                f.write("### 1.2. For√ßa Causal - Transfer Entropy (Correla√ß√£o de Spearman)\n")
                f.write("A tabela a seguir mostra a correla√ß√£o de Spearman entre as matrizes de Transfer√™ncia de Entropia (TE). Esta m√©trica avalia a consist√™ncia na FOR√áA da causalidade. Valores pr√≥ximos de 1 indicam uma forte correla√ß√£o positiva na for√ßa causal entre os rounds.\n\n")
                f.write(df_spearman.to_markdown())
                f.write("\n\n![Heatmap de Consist√™ncia de TE](./te_consistency_heatmap.png)\n\n")

            # --- Se√ß√£o 2: Robustez Causal e Grafos Robustos ---
            f.write("## 2. Robustez das Rela√ß√µes Causais\n\n")
            causality_robustness = all_results.get('causality_robustness', {})
            if causality_robustness:
                 f.write("An√°lise da robustez das rela√ß√µes causais individuais com base na sua consist√™ncia (baixo Coeficiente de Varia√ß√£o) atrav√©s dos rounds.\n\n")
                 f.write("### Rela√ß√µes Causais Robustas (Consenso)\n")
                 f.write("Rela√ß√µes que aparecem consistentemente com for√ßa similar em m√∫ltiplos rounds.\n\n")
                 # Link para o CSV
                 f.write("Para uma lista detalhada, veja o arquivo `robust_causal_relationships.csv`.\n\n")
                 
                 robust_graphs = all_results.get('robust_causality_graphs', {})
                 if robust_graphs:
                     f.write("### Grafos de Causalidade Robustos\n")
                     f.write("Grafos mostrando apenas as rela√ß√µes causais mais robustas para m√©tricas selecionadas.\n\n")
                     for metric, path in robust_graphs.items():
                         f.write(f"**M√©trica: {metric}**\n")
                         f.write(f"![Grafo Robusto para {metric}](./{os.path.basename(path)})\n\n")
            else:
                f.write("An√°lise de robustez causal n√£o foi executada ou n√£o produziu resultados.\n\n")


            # --- Se√ß√£o 3: Consist√™ncia de M√©tricas (CV) ---
            f.write("## 3. Consist√™ncia dos Valores de M√©tricas\n\n")
            f.write("An√°lise da estabilidade dos valores das m√©tricas atrav√©s dos rounds, utilizando o Coeficiente de Varia√ß√£o (CV). Baixo CV indica alta consist√™ncia.\n\n")
            f.write("![Heatmap de CV por Tenant e M√©trica](./cv_heatmap_by_tenant_metric.png)\n\n")
            f.write("Para dados detalhados, veja `round_consistency_cv.csv`.\n\n")

            # --- Se√ß√£o 4: Diverg√™ncia Comportamental ---
            f.write("## 4. An√°lise de Diverg√™ncia Comportamental\n\n")
            f.write("Identifica rounds com comportamento an√¥malo e mede a estabilidade do comportamento dos tenants atrav√©s dos rounds usando a Diverg√™ncia de Kullback-Leibler.\n\n")
            f.write("Para dados detalhados, veja `tenant_stability_scores.csv`.\n\n")

            # --- Se√ß√£o 4.1: Boxplots Consolidados (Aprimorado v2.1) ---
            f.write("## 4.1. Boxplots Consolidados (Violin Plots)\n\n")
            f.write("**üÜï Visualiza√ß√µes aprimoradas** que mostram a distribui√ß√£o de cada m√©trica por fase experimental, agregando dados de todos os rounds. Os violin plots oferecem uma vis√£o mais rica da densidade dos dados em compara√ß√£o com os boxplots tradicionais.\n\n")
            
            consolidated_boxplots = all_results.get('consolidated_boxplots', {})
            if consolidated_boxplots:
                f.write("### Boxplots por M√©trica\n")
                f.write("Para cada m√©trica, s√£o gerados dois gr√°ficos:\n")
                f.write("- **Valores Brutos**: Mostra a distribui√ß√£o real dos dados.\n")
                f.write("- **Valores Normalizados**: Normaliza os dados pela m√©dia da fase 'Baseline' de cada tenant, permitindo uma compara√ß√£o justa do *impacto relativo* das fases de stress.\n\n")
                
                # Organizar por m√©trica para apresentar lado a lado
                metrics_boxplot = sorted(list(set([k.replace('_raw', '').replace('_normalized', '') for k in consolidated_boxplots.keys()])))
                
                for metric in metrics_boxplot:
                    metric_display = metric.replace("_", " ").title()
                    f.write(f"#### {metric_display}\n")
                    
                    raw_path = consolidated_boxplots.get(f"{metric}_raw")
                    norm_path = consolidated_boxplots.get(f"{metric}_normalized")
                    
                    if raw_path:
                        f.write(f"![Boxplot {metric_display}](./boxplots/{os.path.basename(raw_path)})\n")
                    if norm_path:
                        f.write(f"![Boxplot Normalizado {metric_display}](./boxplots/{os.path.basename(norm_path)})\n")
                    f.write("\n")

            else:
                f.write("Boxplots consolidados n√£o foram gerados nesta execu√ß√£o.\n\n")

            # --- Se√ß√£o 4.2: Time Series Consolidados (v2.0) ---
            f.write("## 4.2. Time Series Consolidados\n\n")
            f.write("**Visualiza√ß√µes avan√ßadas** que agregam a evolu√ß√£o temporal de todas as m√©tricas atrav√©s dos rounds, facilitando a identifica√ß√£o de padr√µes, tend√™ncias e diverg√™ncias comportamentais.\n\n")
            
            consolidated_timeseries = all_results.get('consolidated_timeseries', {})
            if consolidated_timeseries:
                f.write("### Time Series por M√©trica\n")
                f.write("Cada visualiza√ß√£o inclui:\n")
                f.write("- **Evolu√ß√£o por Round**: Tend√™ncias agregadas entre todos os tenants\n")
                f.write("- **Evolu√ß√£o por Tenant**: Comportamento individual de cada tenant em todos os rounds\n")
                f.write("- **Tend√™ncias Suavizadas**: M√©dias m√≥veis para identificar padr√µes de longo prazo\n")
                f.write("- **Distribui√ß√µes por Fase**: Boxplots comparando fases experimentais\n\n")
                
                for metric, path in consolidated_timeseries.items():
                    metric_display = metric.replace("_", " ").title()
                    f.write(f"#### {metric_display}\n")
                    f.write(f"![Time Series Consolidado - {metric_display}](./timeseries/{os.path.basename(path)})\n\n")
                    
                f.write("**Interpreta√ß√£o**: \n")
                f.write("- **Converg√™ncia entre rounds** indica comportamento reproduz√≠vel\n")
                f.write("- **Diverg√™ncias significativas** podem indicar efeitos de noisy neighbors\n")
                f.write("- **Padr√µes temporais consistentes** sugerem rela√ß√µes causais est√°veis\n\n")
            else:
                f.write("Time series consolidados n√£o foram gerados nesta execu√ß√£o.\n\n")


            # --- Se√ß√£o 5: Veredictos de Consenso ---
            f.write("## 5. Veredictos de Consenso\n\n")
            consensus = all_results.get('consensus', {})
            if consensus:
                f.write("Agrega√ß√£o dos resultados de todos os rounds para produzir um veredito final.\n\n")
                if consensus.get('noisy_tenants_consensus'):
                    f.write("### Tenants Barulhentos (Consenso)\n")
                    f.write("Tenants identificados como fontes de causalidade de forma consistente na maioria dos rounds. Veja `consensus_noisy_tenants.csv`.\n\n")
                if consensus.get('tenant_influence_ranking'):
                    f.write("### Ranking de Influ√™ncia de Tenants (Consenso)\n")
                    f.write("Ranking de tenants com base na sua influ√™ncia causal consolidada. Veja `tenant_influence_ranking.csv`.\n\n")
            else:
                f.write("An√°lise de consenso n√£o foi executada ou n√£o produziu resultados.\n\n")

            # --- Se√ß√£o de Sum√°rio ---
            f.write("## Sum√°rio Final\n\n")
            f.write("A an√°lise multi-round fornece insights sobre a estabilidade e reprodutibilidade dos resultados do experimento. Alta consist√™ncia sugere que as rela√ß√µes causais e comportamentos observados s√£o robustos. Baixa consist√™ncia pode indicar que o sistema exibe comportamento vari√°vel ou que os resultados s√£o sens√≠veis a condi√ß√µes iniciais, necessitando de investiga√ß√£o adicional.\n")

        self.logger.info(f"Relat√≥rio consolidado de an√°lise multi-round salvo em: {report_path}")

    def _load_causality_matrices(self, context: Dict[str, Any], rounds: List[str]) -> Dict[str, Any]:
        """
        Carrega as matrizes de causalidade (TE e Granger) para cada round.
        Primeiro, tenta carregar do contexto. Se n√£o encontrar, busca os arquivos CSV
        no diret√≥rio de sa√≠da do pipeline principal.
        """
        te_matrices_by_round = {}
        granger_matrices_by_round = {}
        
        # Prioriza o diret√≥rio de sa√≠da principal do contexto para maior robustez
        base_output_dir = context.get('output_dir')
        if not base_output_dir:
            # Fallback para o caso de o diret√≥rio do contexto n√£o estar dispon√≠vel
            base_output_dir = os.path.dirname(self.output_dir) if self.output_dir else None

        if not base_output_dir:
            self.logger.warning("N√£o foi poss√≠vel determinar o diret√≥rio base de sa√≠das. N√£o ser√° poss√≠vel carregar matrizes de causalidade.")
            return {}

        causality_output_dir = os.path.join(base_output_dir, 'causality')
        
        self.logger.info(f"Procurando matrizes de causalidade em: {causality_output_dir}")

        for round_id in rounds:
            # Tenta carregar do contexto primeiro
            te_key = f'te_matrices_round_{round_id}'
            granger_key = f'granger_matrices_round_{round_id}'
            
            if te_key in context and granger_key in context:
                te_matrices_by_round[round_id] = context[te_key]
                granger_matrices_by_round[round_id] = context[granger_key]
                self.logger.info(f"Matrizes de causalidade para o round '{round_id}' carregadas do contexto.")
                continue

            # Se n√£o estiver no contexto, carregar dos arquivos
            self.logger.info(f"Matrizes para o round '{round_id}' n√£o encontradas no contexto. Tentando carregar de arquivos...")
            round_causality_path = os.path.join(causality_output_dir, round_id)
            
            if not os.path.isdir(round_causality_path):
                self.logger.warning(f"Diret√≥rio de causalidade para o round '{round_id}' n√£o encontrado em '{round_causality_path}'.")
                continue

            te_matrices = {}
            granger_matrices = {}
            
            try:
                for file_name in os.listdir(round_causality_path):
                    if file_name.startswith('te_matrix_') and file_name.endswith('.csv'):
                        metric = file_name.replace('te_matrix_', '').replace('.csv', '')
                        file_path = os.path.join(round_causality_path, file_name)
                        te_matrices[metric] = pd.read_csv(file_path, index_col=0)
                    elif file_name.startswith('granger_matrix_') and file_name.endswith('.csv'):
                        metric = file_name.replace('granger_matrix_', '').replace('.csv', '')
                        file_path = os.path.join(round_causality_path, file_name)
                        granger_matrices[metric] = pd.read_csv(file_path, index_col=0)
            except Exception as e:
                self.logger.error(f"Erro ao carregar arquivos de matriz do diret√≥rio {round_causality_path}: {e}")

            if te_matrices:
                te_matrices_by_round[round_id] = te_matrices
                self.logger.info(f"  - {len(te_matrices)} matrizes de Transfer Entropy carregadas para o round '{round_id}'.")
            if granger_matrices:
                granger_matrices_by_round[round_id] = granger_matrices
                self.logger.info(f"  - {len(granger_matrices)} matrizes de Granger carregadas para o round '{round_id}'.")

        return {
            'te_matrices_by_round': te_matrices_by_round,
            'granger_matrices_by_round': granger_matrices_by_round
        }


def generate_robust_causality_graph(
    robust_relationships: Dict[str, Dict[Tuple[str, str], Dict[str, float]]],
    output_dir: str,
    metric: str
) -> Optional[str]:
    """
    Gera um grafo de causalidade robusto para uma m√©trica espec√≠fica.

    Args:
        robust_relationships: Dicion√°rio com as rela√ß√µes causais robustas.
        output_dir: Diret√≥rio para salvar o grafo.
        metric: M√©trica para a qual o grafo ser√° gerado.

    Returns:
        Caminho do arquivo de imagem do grafo gerado ou None se n√£o houver dados.
    """
    if not robust_relationships.get(metric):
        logger.warning(f"N√£o h√° rela√ß√µes causais robustas para a m√©trica '{metric}'. O grafo n√£o ser√° gerado.")
        return None

    G = nx.DiGraph()
    
    # Adicionar arestas com pesos, ignorando NaNs, para garantir que os dados s√£o num√©ricos
    for (source, target), data in robust_relationships[metric].items():
        weight = data.get('mean_te')
        if weight is not None and pd.notna(weight):
            G.add_edge(source, target, weight=float(weight))

    if not G.nodes():
        logger.warning(f"O grafo para a m√©trica '{metric}' n√£o possui n√≥s. A visualiza√ß√£o ser√° pulada.")
        return None

    plt.figure(figsize=(14, 10))
    pos = nx.spring_layout(G, k=0.9, iterations=50)

    # Desenhar n√≥s com tamanho proporcional ao out-degree (influ√™ncia).
    node_sizes = [int(500 + 1000 * G.out_degree(n)) for n in G.nodes()]
    nx.draw_networkx_nodes(G, pos, node_size=node_sizes, node_color='skyblue', alpha=0.8) # type: ignore

    # Desenhar arestas com espessura proporcional √† for√ßa da causalidade (peso).
    edge_weights = [float(G[u][v]['weight']) for u, v in G.edges()]
    
    if edge_weights:
        # Normalizar pesos para uma faixa de espessura visualmente agrad√°vel (e.g., 1 a 10).
        min_w = min(edge_weights)
        max_w = max(edge_weights)
        
        edge_widths = []
        if max_w > min_w:
            edge_widths = [1.0 + 9.0 * (w - min_w) / (max_w - min_w) for w in edge_weights]
        else:
            # Todos os pesos s√£o iguais, usar uma espessura m√©dia.
            edge_widths = [5.0] * len(edge_weights)
            
        nx.draw_networkx_edges(G, pos, width=edge_widths, alpha=0.6, edge_color='gray', arrowsize=20) # type: ignore
